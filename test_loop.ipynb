{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 10:51:15.412399: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-31 10:51:15.443747: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-31 10:51:15.444229: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-31 10:51:16.364155: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: HNRNPK_K562_200.h5\n",
      "(4008, 200, 9) (4008, 1)\n",
      "Input shape adjusted:\n",
      "(4008, 200, 4)\n",
      "(1146, 200, 4)\n",
      "(572, 200, 4)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 10:51:17.965289: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 10ms/step - loss: 0.3306 - auroc: 0.9352 - aupr: 0.9321 - binary_accuracy: 0.8543 - val_loss: 0.1614 - val_auroc: 0.9853 - val_aupr: 0.9841 - val_binary_accuracy: 0.9406\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.1580 - auroc: 0.9832 - aupr: 0.9814 - binary_accuracy: 0.9426 - val_loss: 0.1891 - val_auroc: 0.9899 - val_aupr: 0.9897 - val_binary_accuracy: 0.9248\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.1451 - auroc: 0.9859 - aupr: 0.9858 - binary_accuracy: 0.9469 - val_loss: 0.1441 - val_auroc: 0.9923 - val_aupr: 0.9924 - val_binary_accuracy: 0.9406\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.1208 - auroc: 0.9903 - aupr: 0.9889 - binary_accuracy: 0.9571 - val_loss: 0.1326 - val_auroc: 0.9929 - val_aupr: 0.9930 - val_binary_accuracy: 0.9458\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.1076 - auroc: 0.9921 - aupr: 0.9910 - binary_accuracy: 0.9611 - val_loss: 0.1140 - val_auroc: 0.9931 - val_aupr: 0.9931 - val_binary_accuracy: 0.9510\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0908 - auroc: 0.9942 - aupr: 0.9937 - binary_accuracy: 0.9668 - val_loss: 0.1215 - val_auroc: 0.9936 - val_aupr: 0.9936 - val_binary_accuracy: 0.9406\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0853 - auroc: 0.9954 - aupr: 0.9954 - binary_accuracy: 0.9668 - val_loss: 0.1088 - val_auroc: 0.9936 - val_aupr: 0.9936 - val_binary_accuracy: 0.9545\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0847 - auroc: 0.9952 - aupr: 0.9944 - binary_accuracy: 0.9671 - val_loss: 0.1047 - val_auroc: 0.9937 - val_aupr: 0.9938 - val_binary_accuracy: 0.9598\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0648 - auroc: 0.9970 - aupr: 0.9967 - binary_accuracy: 0.9773 - val_loss: 0.1121 - val_auroc: 0.9937 - val_aupr: 0.9937 - val_binary_accuracy: 0.9528\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0510 - auroc: 0.9983 - aupr: 0.9979 - binary_accuracy: 0.9840 - val_loss: 0.1318 - val_auroc: 0.9923 - val_aupr: 0.9902 - val_binary_accuracy: 0.9458\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0421 - auroc: 0.9987 - aupr: 0.9984 - binary_accuracy: 0.9870 - val_loss: 0.1091 - val_auroc: 0.9942 - val_aupr: 0.9941 - val_binary_accuracy: 0.9563\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0335 - auroc: 0.9993 - aupr: 0.9993 - binary_accuracy: 0.9893 - val_loss: 0.1382 - val_auroc: 0.9908 - val_aupr: 0.9866 - val_binary_accuracy: 0.9423\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0370 - auroc: 0.9993 - aupr: 0.9992 - binary_accuracy: 0.9850 - val_loss: 0.1280 - val_auroc: 0.9905 - val_aupr: 0.9889 - val_binary_accuracy: 0.9668\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2432 - auroc: 0.9770 - aupr: 0.9749 - binary_accuracy: 0.9311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pgarcia/.conda/envs/tf_2/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 1s 11ms/step - loss: 0.4940 - auroc: 0.8473 - aupr: 0.8380 - binary_accuracy: 0.7715 - val_loss: 0.2856 - val_auroc: 0.9787 - val_aupr: 0.9747 - val_binary_accuracy: 0.8986\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.1885 - auroc: 0.9767 - aupr: 0.9718 - binary_accuracy: 0.9331 - val_loss: 0.1559 - val_auroc: 0.9861 - val_aupr: 0.9849 - val_binary_accuracy: 0.9388\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.1538 - auroc: 0.9845 - aupr: 0.9823 - binary_accuracy: 0.9454 - val_loss: 0.1359 - val_auroc: 0.9893 - val_aupr: 0.9886 - val_binary_accuracy: 0.9423\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.1335 - auroc: 0.9877 - aupr: 0.9861 - binary_accuracy: 0.9501 - val_loss: 0.1390 - val_auroc: 0.9910 - val_aupr: 0.9904 - val_binary_accuracy: 0.9493\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.1246 - auroc: 0.9897 - aupr: 0.9886 - binary_accuracy: 0.9548 - val_loss: 0.1418 - val_auroc: 0.9916 - val_aupr: 0.9912 - val_binary_accuracy: 0.9510\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.1134 - auroc: 0.9910 - aupr: 0.9898 - binary_accuracy: 0.9596 - val_loss: 0.1184 - val_auroc: 0.9922 - val_aupr: 0.9918 - val_binary_accuracy: 0.9441\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.1138 - auroc: 0.9915 - aupr: 0.9905 - binary_accuracy: 0.9568 - val_loss: 0.1143 - val_auroc: 0.9924 - val_aupr: 0.9922 - val_binary_accuracy: 0.9510\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0954 - auroc: 0.9938 - aupr: 0.9935 - binary_accuracy: 0.9661 - val_loss: 0.1178 - val_auroc: 0.9928 - val_aupr: 0.9926 - val_binary_accuracy: 0.9476\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0946 - auroc: 0.9940 - aupr: 0.9931 - binary_accuracy: 0.9641 - val_loss: 0.1697 - val_auroc: 0.9903 - val_aupr: 0.9907 - val_binary_accuracy: 0.9336\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.1160 - auroc: 0.9910 - aupr: 0.9898 - binary_accuracy: 0.9591 - val_loss: 0.1338 - val_auroc: 0.9924 - val_aupr: 0.9921 - val_binary_accuracy: 0.9441\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0879 - auroc: 0.9946 - aupr: 0.9934 - binary_accuracy: 0.9683 - val_loss: 0.1170 - val_auroc: 0.9928 - val_aupr: 0.9926 - val_binary_accuracy: 0.9528\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0706 - auroc: 0.9966 - aupr: 0.9959 - binary_accuracy: 0.9743 - val_loss: 0.1225 - val_auroc: 0.9923 - val_aupr: 0.9921 - val_binary_accuracy: 0.9528\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2018 - auroc: 0.9783 - aupr: 0.9760 - binary_accuracy: 0.9337\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 1s 11ms/step - loss: 0.2820 - auroc: 0.9525 - aupr: 0.9494 - binary_accuracy: 0.8837 - val_loss: 0.1535 - val_auroc: 0.9858 - val_aupr: 0.9848 - val_binary_accuracy: 0.9388\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.1618 - auroc: 0.9836 - aupr: 0.9828 - binary_accuracy: 0.9354 - val_loss: 0.1552 - val_auroc: 0.9885 - val_aupr: 0.9875 - val_binary_accuracy: 0.9336\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1436 - auroc: 0.9863 - aupr: 0.9845 - binary_accuracy: 0.9471 - val_loss: 0.1212 - val_auroc: 0.9917 - val_aupr: 0.9910 - val_binary_accuracy: 0.9441\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1481 - auroc: 0.9854 - aupr: 0.9842 - binary_accuracy: 0.9471 - val_loss: 0.1272 - val_auroc: 0.9900 - val_aupr: 0.9895 - val_binary_accuracy: 0.9458\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1094 - auroc: 0.9919 - aupr: 0.9915 - binary_accuracy: 0.9623 - val_loss: 0.1254 - val_auroc: 0.9896 - val_aupr: 0.9907 - val_binary_accuracy: 0.9476\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1054 - auroc: 0.9925 - aupr: 0.9927 - binary_accuracy: 0.9623 - val_loss: 0.2456 - val_auroc: 0.9940 - val_aupr: 0.9938 - val_binary_accuracy: 0.8934\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1039 - auroc: 0.9922 - aupr: 0.9915 - binary_accuracy: 0.9628 - val_loss: 0.1048 - val_auroc: 0.9942 - val_aupr: 0.9940 - val_binary_accuracy: 0.9545\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0763 - auroc: 0.9953 - aupr: 0.9942 - binary_accuracy: 0.9748 - val_loss: 0.2176 - val_auroc: 0.9882 - val_aupr: 0.9892 - val_binary_accuracy: 0.9108\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0903 - auroc: 0.9943 - aupr: 0.9934 - binary_accuracy: 0.9706 - val_loss: 0.1462 - val_auroc: 0.9925 - val_aupr: 0.9880 - val_binary_accuracy: 0.9423\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0614 - auroc: 0.9975 - aupr: 0.9976 - binary_accuracy: 0.9770 - val_loss: 0.1610 - val_auroc: 0.9916 - val_aupr: 0.9891 - val_binary_accuracy: 0.9458\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0747 - auroc: 0.9955 - aupr: 0.9938 - binary_accuracy: 0.9733 - val_loss: 0.2358 - val_auroc: 0.9784 - val_aupr: 0.9605 - val_binary_accuracy: 0.9336\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0547 - auroc: 0.9978 - aupr: 0.9977 - binary_accuracy: 0.9800 - val_loss: 0.1487 - val_auroc: 0.9883 - val_aupr: 0.9900 - val_binary_accuracy: 0.9493\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2297 - auroc: 0.9806 - aupr: 0.9798 - binary_accuracy: 0.9346\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.8841 - auroc: 0.5286 - aupr: 0.5189 - binary_accuracy: 0.5322 - val_loss: 0.6487 - val_auroc: 0.9274 - val_aupr: 0.9243 - val_binary_accuracy: 0.8374\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.3834 - auroc: 0.9149 - aupr: 0.9049 - binary_accuracy: 0.8381 - val_loss: 0.2064 - val_auroc: 0.9754 - val_aupr: 0.9740 - val_binary_accuracy: 0.9143\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1870 - auroc: 0.9783 - aupr: 0.9759 - binary_accuracy: 0.9311 - val_loss: 0.3203 - val_auroc: 0.9828 - val_aupr: 0.9767 - val_binary_accuracy: 0.8584\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1915 - auroc: 0.9773 - aupr: 0.9740 - binary_accuracy: 0.9269 - val_loss: 0.1907 - val_auroc: 0.9868 - val_aupr: 0.9833 - val_binary_accuracy: 0.9161\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1631 - auroc: 0.9828 - aupr: 0.9813 - binary_accuracy: 0.9426 - val_loss: 0.1565 - val_auroc: 0.9885 - val_aupr: 0.9878 - val_binary_accuracy: 0.9266\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1481 - auroc: 0.9859 - aupr: 0.9841 - binary_accuracy: 0.9456 - val_loss: 0.1366 - val_auroc: 0.9894 - val_aupr: 0.9888 - val_binary_accuracy: 0.9388\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1517 - auroc: 0.9852 - aupr: 0.9839 - binary_accuracy: 0.9449 - val_loss: 0.1330 - val_auroc: 0.9899 - val_aupr: 0.9892 - val_binary_accuracy: 0.9441\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1489 - auroc: 0.9857 - aupr: 0.9839 - binary_accuracy: 0.9464 - val_loss: 0.1323 - val_auroc: 0.9897 - val_aupr: 0.9888 - val_binary_accuracy: 0.9423\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1382 - auroc: 0.9877 - aupr: 0.9862 - binary_accuracy: 0.9494 - val_loss: 0.1278 - val_auroc: 0.9916 - val_aupr: 0.9910 - val_binary_accuracy: 0.9493\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1375 - auroc: 0.9877 - aupr: 0.9869 - binary_accuracy: 0.9461 - val_loss: 0.1364 - val_auroc: 0.9908 - val_aupr: 0.9881 - val_binary_accuracy: 0.9476\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1294 - auroc: 0.9889 - aupr: 0.9873 - binary_accuracy: 0.9518 - val_loss: 0.1194 - val_auroc: 0.9927 - val_aupr: 0.9923 - val_binary_accuracy: 0.9510\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1245 - auroc: 0.9896 - aupr: 0.9883 - binary_accuracy: 0.9521 - val_loss: 0.1266 - val_auroc: 0.9911 - val_aupr: 0.9910 - val_binary_accuracy: 0.9493\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1332 - auroc: 0.9887 - aupr: 0.9879 - binary_accuracy: 0.9491 - val_loss: 0.2133 - val_auroc: 0.9929 - val_aupr: 0.9929 - val_binary_accuracy: 0.9038\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1472 - auroc: 0.9865 - aupr: 0.9848 - binary_accuracy: 0.9484 - val_loss: 0.1336 - val_auroc: 0.9909 - val_aupr: 0.9885 - val_binary_accuracy: 0.9528\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1250 - auroc: 0.9900 - aupr: 0.9886 - binary_accuracy: 0.9538 - val_loss: 0.1192 - val_auroc: 0.9929 - val_aupr: 0.9928 - val_binary_accuracy: 0.9441\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1251 - auroc: 0.9899 - aupr: 0.9895 - binary_accuracy: 0.9543 - val_loss: 0.1159 - val_auroc: 0.9926 - val_aupr: 0.9924 - val_binary_accuracy: 0.9545\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1025 - auroc: 0.9930 - aupr: 0.9922 - binary_accuracy: 0.9623 - val_loss: 0.1094 - val_auroc: 0.9934 - val_aupr: 0.9934 - val_binary_accuracy: 0.9510\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1139 - auroc: 0.9916 - aupr: 0.9902 - binary_accuracy: 0.9558 - val_loss: 0.1653 - val_auroc: 0.9938 - val_aupr: 0.9938 - val_binary_accuracy: 0.9266\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1092 - auroc: 0.9922 - aupr: 0.9916 - binary_accuracy: 0.9603 - val_loss: 0.1247 - val_auroc: 0.9927 - val_aupr: 0.9928 - val_binary_accuracy: 0.9528\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1009 - auroc: 0.9925 - aupr: 0.9910 - binary_accuracy: 0.9661 - val_loss: 0.1373 - val_auroc: 0.9929 - val_aupr: 0.9928 - val_binary_accuracy: 0.9423\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0899 - auroc: 0.9942 - aupr: 0.9929 - binary_accuracy: 0.9701 - val_loss: 0.1130 - val_auroc: 0.9935 - val_aupr: 0.9936 - val_binary_accuracy: 0.9580\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0858 - auroc: 0.9949 - aupr: 0.9942 - binary_accuracy: 0.9666 - val_loss: 0.1078 - val_auroc: 0.9943 - val_aupr: 0.9943 - val_binary_accuracy: 0.9545\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0831 - auroc: 0.9949 - aupr: 0.9941 - binary_accuracy: 0.9678 - val_loss: 0.1041 - val_auroc: 0.9939 - val_aupr: 0.9939 - val_binary_accuracy: 0.9563\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.0752 - auroc: 0.9960 - aupr: 0.9959 - binary_accuracy: 0.9708 - val_loss: 0.1138 - val_auroc: 0.9940 - val_aupr: 0.9940 - val_binary_accuracy: 0.9528\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0771 - auroc: 0.9961 - aupr: 0.9958 - binary_accuracy: 0.9726 - val_loss: 0.1568 - val_auroc: 0.9918 - val_aupr: 0.9897 - val_binary_accuracy: 0.9406\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0700 - auroc: 0.9965 - aupr: 0.9963 - binary_accuracy: 0.9718 - val_loss: 0.1374 - val_auroc: 0.9920 - val_aupr: 0.9897 - val_binary_accuracy: 0.9510\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0694 - auroc: 0.9964 - aupr: 0.9955 - binary_accuracy: 0.9741 - val_loss: 0.1224 - val_auroc: 0.9933 - val_aupr: 0.9931 - val_binary_accuracy: 0.9493\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0714 - auroc: 0.9964 - aupr: 0.9959 - binary_accuracy: 0.9733 - val_loss: 0.1080 - val_auroc: 0.9946 - val_aupr: 0.9946 - val_binary_accuracy: 0.9563\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1962 - auroc: 0.9804 - aupr: 0.9716 - binary_accuracy: 0.9433\n",
      "Processing: PTBP1_K562_200.h5\n",
      "(11328, 200, 9) (11328, 1)\n",
      "Input shape adjusted:\n",
      "(11328, 200, 4)\n",
      "(3237, 200, 4)\n",
      "(1619, 200, 4)\n",
      "Epoch 1/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.3213 - auroc: 0.9363 - aupr: 0.9476 - binary_accuracy: 0.8724 - val_loss: 0.2485 - val_auroc: 0.9605 - val_aupr: 0.9716 - val_binary_accuracy: 0.9061\n",
      "Epoch 2/100\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.2061 - auroc: 0.9686 - aupr: 0.9748 - binary_accuracy: 0.9246 - val_loss: 0.1979 - val_auroc: 0.9699 - val_aupr: 0.9773 - val_binary_accuracy: 0.9191\n",
      "Epoch 3/100\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.1811 - auroc: 0.9762 - aupr: 0.9800 - binary_accuracy: 0.9312 - val_loss: 0.1852 - val_auroc: 0.9738 - val_aupr: 0.9800 - val_binary_accuracy: 0.9296\n",
      "Epoch 4/100\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.1602 - auroc: 0.9814 - aupr: 0.9842 - binary_accuracy: 0.9388 - val_loss: 0.2032 - val_auroc: 0.9746 - val_aupr: 0.9795 - val_binary_accuracy: 0.9080\n",
      "Epoch 5/100\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.1531 - auroc: 0.9833 - aupr: 0.9858 - binary_accuracy: 0.9403 - val_loss: 0.1750 - val_auroc: 0.9774 - val_aupr: 0.9815 - val_binary_accuracy: 0.9284\n",
      "Epoch 6/100\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.1423 - auroc: 0.9857 - aupr: 0.9879 - binary_accuracy: 0.9456 - val_loss: 0.1894 - val_auroc: 0.9760 - val_aupr: 0.9792 - val_binary_accuracy: 0.9314\n",
      "Epoch 7/100\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.1403 - auroc: 0.9860 - aupr: 0.9875 - binary_accuracy: 0.9467 - val_loss: 0.1765 - val_auroc: 0.9776 - val_aupr: 0.9814 - val_binary_accuracy: 0.9321\n",
      "Epoch 8/100\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.1307 - auroc: 0.9879 - aupr: 0.9893 - binary_accuracy: 0.9504 - val_loss: 0.1898 - val_auroc: 0.9772 - val_aupr: 0.9804 - val_binary_accuracy: 0.9265\n",
      "Epoch 9/100\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.1183 - auroc: 0.9901 - aupr: 0.9913 - binary_accuracy: 0.9524 - val_loss: 0.1953 - val_auroc: 0.9767 - val_aupr: 0.9811 - val_binary_accuracy: 0.9308\n",
      "Epoch 10/100\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.1169 - auroc: 0.9903 - aupr: 0.9916 - binary_accuracy: 0.9552 - val_loss: 0.2484 - val_auroc: 0.9696 - val_aupr: 0.9759 - val_binary_accuracy: 0.9074\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2114 - auroc: 0.9766 - aupr: 0.9800 - binary_accuracy: 0.9150\n",
      "Epoch 1/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.3689 - auroc: 0.9113 - aupr: 0.9282 - binary_accuracy: 0.8460 - val_loss: 0.2868 - val_auroc: 0.9481 - val_aupr: 0.9609 - val_binary_accuracy: 0.8925\n",
      "Epoch 2/100\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.2210 - auroc: 0.9631 - aupr: 0.9707 - binary_accuracy: 0.9192 - val_loss: 0.2138 - val_auroc: 0.9660 - val_aupr: 0.9757 - val_binary_accuracy: 0.9209\n",
      "Epoch 3/100\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.1998 - auroc: 0.9710 - aupr: 0.9764 - binary_accuracy: 0.9251 - val_loss: 0.2331 - val_auroc: 0.9660 - val_aupr: 0.9724 - val_binary_accuracy: 0.9160\n",
      "Epoch 4/100\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.1880 - auroc: 0.9743 - aupr: 0.9789 - binary_accuracy: 0.9299 - val_loss: 0.2154 - val_auroc: 0.9695 - val_aupr: 0.9767 - val_binary_accuracy: 0.9191\n",
      "Epoch 5/100\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.1824 - auroc: 0.9764 - aupr: 0.9798 - binary_accuracy: 0.9310 - val_loss: 0.2356 - val_auroc: 0.9675 - val_aupr: 0.9731 - val_binary_accuracy: 0.9160\n",
      "Epoch 6/100\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.1686 - auroc: 0.9794 - aupr: 0.9823 - binary_accuracy: 0.9340 - val_loss: 0.2484 - val_auroc: 0.9690 - val_aupr: 0.9756 - val_binary_accuracy: 0.9166\n",
      "Epoch 7/100\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.1673 - auroc: 0.9800 - aupr: 0.9825 - binary_accuracy: 0.9340 - val_loss: 0.2166 - val_auroc: 0.9696 - val_aupr: 0.9741 - val_binary_accuracy: 0.9203\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.1721 - auroc: 0.9804 - aupr: 0.9825 - binary_accuracy: 0.9283\n",
      "Epoch 1/100\n",
      "114/114 [==============================] - 2s 10ms/step - loss: 0.2982 - auroc: 0.9406 - aupr: 0.9513 - binary_accuracy: 0.8747 - val_loss: 0.2110 - val_auroc: 0.9659 - val_aupr: 0.9744 - val_binary_accuracy: 0.9222\n",
      "Epoch 2/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.2111 - auroc: 0.9679 - aupr: 0.9737 - binary_accuracy: 0.9204 - val_loss: 0.2015 - val_auroc: 0.9689 - val_aupr: 0.9770 - val_binary_accuracy: 0.9284\n",
      "Epoch 3/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1962 - auroc: 0.9724 - aupr: 0.9766 - binary_accuracy: 0.9239 - val_loss: 0.2048 - val_auroc: 0.9722 - val_aupr: 0.9792 - val_binary_accuracy: 0.9302\n",
      "Epoch 4/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1845 - auroc: 0.9753 - aupr: 0.9796 - binary_accuracy: 0.9319 - val_loss: 0.1953 - val_auroc: 0.9723 - val_aupr: 0.9793 - val_binary_accuracy: 0.9321\n",
      "Epoch 5/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1652 - auroc: 0.9807 - aupr: 0.9833 - binary_accuracy: 0.9365 - val_loss: 0.1871 - val_auroc: 0.9741 - val_aupr: 0.9805 - val_binary_accuracy: 0.9302\n",
      "Epoch 6/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1563 - auroc: 0.9826 - aupr: 0.9851 - binary_accuracy: 0.9399 - val_loss: 0.2395 - val_auroc: 0.9738 - val_aupr: 0.9793 - val_binary_accuracy: 0.9111\n",
      "Epoch 7/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1492 - auroc: 0.9842 - aupr: 0.9868 - binary_accuracy: 0.9405 - val_loss: 0.1912 - val_auroc: 0.9757 - val_aupr: 0.9814 - val_binary_accuracy: 0.9333\n",
      "Epoch 8/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1400 - auroc: 0.9861 - aupr: 0.9878 - binary_accuracy: 0.9440 - val_loss: 0.2304 - val_auroc: 0.9682 - val_aupr: 0.9717 - val_binary_accuracy: 0.9185\n",
      "Epoch 9/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1230 - auroc: 0.9891 - aupr: 0.9905 - binary_accuracy: 0.9525 - val_loss: 0.2555 - val_auroc: 0.9680 - val_aupr: 0.9703 - val_binary_accuracy: 0.9129\n",
      "Epoch 10/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1305 - auroc: 0.9881 - aupr: 0.9894 - binary_accuracy: 0.9472 - val_loss: 0.2507 - val_auroc: 0.9701 - val_aupr: 0.9746 - val_binary_accuracy: 0.9290\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.2008 - auroc: 0.9782 - aupr: 0.9792 - binary_accuracy: 0.9305\n",
      "Epoch 1/100\n",
      "114/114 [==============================] - 2s 11ms/step - loss: 0.6318 - auroc: 0.7575 - aupr: 0.7582 - binary_accuracy: 0.6836 - val_loss: 0.3874 - val_auroc: 0.9371 - val_aupr: 0.9542 - val_binary_accuracy: 0.8481\n",
      "Epoch 2/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.2817 - auroc: 0.9414 - aupr: 0.9548 - binary_accuracy: 0.8946 - val_loss: 0.2670 - val_auroc: 0.9435 - val_aupr: 0.9594 - val_binary_accuracy: 0.8962\n",
      "Epoch 3/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.2519 - auroc: 0.9512 - aupr: 0.9628 - binary_accuracy: 0.9109 - val_loss: 0.2402 - val_auroc: 0.9558 - val_aupr: 0.9679 - val_binary_accuracy: 0.9123\n",
      "Epoch 4/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.2193 - auroc: 0.9651 - aupr: 0.9710 - binary_accuracy: 0.9198 - val_loss: 0.2206 - val_auroc: 0.9635 - val_aupr: 0.9745 - val_binary_accuracy: 0.9228\n",
      "Epoch 5/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.2043 - auroc: 0.9695 - aupr: 0.9751 - binary_accuracy: 0.9245 - val_loss: 0.2784 - val_auroc: 0.9612 - val_aupr: 0.9712 - val_binary_accuracy: 0.8894\n",
      "Epoch 6/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.2061 - auroc: 0.9696 - aupr: 0.9745 - binary_accuracy: 0.9236 - val_loss: 0.2251 - val_auroc: 0.9657 - val_aupr: 0.9752 - val_binary_accuracy: 0.9228\n",
      "Epoch 7/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1949 - auroc: 0.9726 - aupr: 0.9768 - binary_accuracy: 0.9288 - val_loss: 0.1975 - val_auroc: 0.9674 - val_aupr: 0.9752 - val_binary_accuracy: 0.9321\n",
      "Epoch 8/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1981 - auroc: 0.9716 - aupr: 0.9764 - binary_accuracy: 0.9259 - val_loss: 0.1981 - val_auroc: 0.9676 - val_aupr: 0.9757 - val_binary_accuracy: 0.9345\n",
      "Epoch 9/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1809 - auroc: 0.9759 - aupr: 0.9793 - binary_accuracy: 0.9344 - val_loss: 0.2651 - val_auroc: 0.9680 - val_aupr: 0.9758 - val_binary_accuracy: 0.9129\n",
      "Epoch 10/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1848 - auroc: 0.9747 - aupr: 0.9787 - binary_accuracy: 0.9309 - val_loss: 0.2173 - val_auroc: 0.9704 - val_aupr: 0.9780 - val_binary_accuracy: 0.9277\n",
      "Epoch 11/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1844 - auroc: 0.9756 - aupr: 0.9795 - binary_accuracy: 0.9292 - val_loss: 0.2028 - val_auroc: 0.9689 - val_aupr: 0.9760 - val_binary_accuracy: 0.9234\n",
      "Epoch 12/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1749 - auroc: 0.9781 - aupr: 0.9817 - binary_accuracy: 0.9340 - val_loss: 0.2084 - val_auroc: 0.9699 - val_aupr: 0.9771 - val_binary_accuracy: 0.9277\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.1835 - auroc: 0.9778 - aupr: 0.9816 - binary_accuracy: 0.9252\n",
      "Processing: PUM2_K562_200.h5\n",
      "(10147, 200, 9) (10147, 1)\n",
      "Input shape adjusted:\n",
      "(10147, 200, 4)\n",
      "(2900, 200, 4)\n",
      "(1449, 200, 4)\n",
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.5924 - auroc: 0.7436 - aupr: 0.7349 - binary_accuracy: 0.6727 - val_loss: 0.4312 - val_auroc: 0.8923 - val_aupr: 0.8859 - val_binary_accuracy: 0.8192\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3813 - auroc: 0.9104 - aupr: 0.9062 - binary_accuracy: 0.8330 - val_loss: 0.2777 - val_auroc: 0.9544 - val_aupr: 0.9529 - val_binary_accuracy: 0.8847\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2900 - auroc: 0.9485 - aupr: 0.9483 - binary_accuracy: 0.8840 - val_loss: 0.3214 - val_auroc: 0.9545 - val_aupr: 0.9513 - val_binary_accuracy: 0.8592\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2636 - auroc: 0.9573 - aupr: 0.9574 - binary_accuracy: 0.8952 - val_loss: 0.2578 - val_auroc: 0.9631 - val_aupr: 0.9608 - val_binary_accuracy: 0.8930\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2477 - auroc: 0.9623 - aupr: 0.9614 - binary_accuracy: 0.9011 - val_loss: 0.2832 - val_auroc: 0.9635 - val_aupr: 0.9614 - val_binary_accuracy: 0.8792\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2312 - auroc: 0.9669 - aupr: 0.9666 - binary_accuracy: 0.9107 - val_loss: 0.2688 - val_auroc: 0.9611 - val_aupr: 0.9598 - val_binary_accuracy: 0.8868\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2204 - auroc: 0.9700 - aupr: 0.9692 - binary_accuracy: 0.9170 - val_loss: 0.2694 - val_auroc: 0.9566 - val_aupr: 0.9554 - val_binary_accuracy: 0.8882\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2089 - auroc: 0.9732 - aupr: 0.9735 - binary_accuracy: 0.9172 - val_loss: 0.2584 - val_auroc: 0.9607 - val_aupr: 0.9603 - val_binary_accuracy: 0.8958\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1971 - auroc: 0.9761 - aupr: 0.9759 - binary_accuracy: 0.9267 - val_loss: 0.2680 - val_auroc: 0.9601 - val_aupr: 0.9598 - val_binary_accuracy: 0.8965\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.3026 - auroc: 0.9499 - aupr: 0.9514 - binary_accuracy: 0.8772\n",
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.6989 - auroc: 0.6349 - aupr: 0.6011 - binary_accuracy: 0.6012 - val_loss: 0.5607 - val_auroc: 0.7966 - val_aupr: 0.7811 - val_binary_accuracy: 0.7019\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5345 - auroc: 0.8057 - aupr: 0.7903 - binary_accuracy: 0.7278 - val_loss: 0.4273 - val_auroc: 0.9165 - val_aupr: 0.9095 - val_binary_accuracy: 0.8109\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3540 - auroc: 0.9235 - aupr: 0.9225 - binary_accuracy: 0.8469 - val_loss: 0.2950 - val_auroc: 0.9578 - val_aupr: 0.9574 - val_binary_accuracy: 0.8723\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2981 - auroc: 0.9458 - aupr: 0.9463 - binary_accuracy: 0.8744 - val_loss: 0.2951 - val_auroc: 0.9552 - val_aupr: 0.9568 - val_binary_accuracy: 0.8703\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2920 - auroc: 0.9481 - aupr: 0.9491 - binary_accuracy: 0.8785 - val_loss: 0.2594 - val_auroc: 0.9608 - val_aupr: 0.9604 - val_binary_accuracy: 0.9027\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2684 - auroc: 0.9564 - aupr: 0.9560 - binary_accuracy: 0.8934 - val_loss: 0.2544 - val_auroc: 0.9611 - val_aupr: 0.9610 - val_binary_accuracy: 0.8986\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2581 - auroc: 0.9596 - aupr: 0.9602 - binary_accuracy: 0.8944 - val_loss: 0.2511 - val_auroc: 0.9618 - val_aupr: 0.9614 - val_binary_accuracy: 0.8986\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2480 - auroc: 0.9629 - aupr: 0.9610 - binary_accuracy: 0.8986 - val_loss: 0.2633 - val_auroc: 0.9623 - val_aupr: 0.9619 - val_binary_accuracy: 0.8965\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2484 - auroc: 0.9625 - aupr: 0.9630 - binary_accuracy: 0.8991 - val_loss: 0.2548 - val_auroc: 0.9624 - val_aupr: 0.9614 - val_binary_accuracy: 0.8992\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2329 - auroc: 0.9673 - aupr: 0.9665 - binary_accuracy: 0.9065 - val_loss: 0.2692 - val_auroc: 0.9619 - val_aupr: 0.9614 - val_binary_accuracy: 0.8882\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2279 - auroc: 0.9686 - aupr: 0.9681 - binary_accuracy: 0.9082 - val_loss: 0.2777 - val_auroc: 0.9608 - val_aupr: 0.9613 - val_binary_accuracy: 0.8951\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2300 - auroc: 0.9681 - aupr: 0.9672 - binary_accuracy: 0.9072 - val_loss: 0.2608 - val_auroc: 0.9612 - val_aupr: 0.9616 - val_binary_accuracy: 0.8951\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.3142 - auroc: 0.9455 - aupr: 0.9474 - binary_accuracy: 0.8697\n",
      "Epoch 1/100\n",
      "102/102 [==============================] - 2s 10ms/step - loss: 0.6221 - auroc: 0.7043 - aupr: 0.6937 - binary_accuracy: 0.6346 - val_loss: 0.5179 - val_auroc: 0.8349 - val_aupr: 0.8334 - val_binary_accuracy: 0.7474\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.4747 - auroc: 0.8524 - aupr: 0.8480 - binary_accuracy: 0.7713 - val_loss: 0.3795 - val_auroc: 0.9209 - val_aupr: 0.9171 - val_binary_accuracy: 0.8316\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3745 - auroc: 0.9126 - aupr: 0.9135 - binary_accuracy: 0.8342 - val_loss: 0.4166 - val_auroc: 0.9335 - val_aupr: 0.9292 - val_binary_accuracy: 0.7902\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3512 - auroc: 0.9230 - aupr: 0.9269 - binary_accuracy: 0.8474 - val_loss: 0.3235 - val_auroc: 0.9380 - val_aupr: 0.9328 - val_binary_accuracy: 0.8675\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3221 - auroc: 0.9361 - aupr: 0.9383 - binary_accuracy: 0.8627 - val_loss: 0.3360 - val_auroc: 0.9369 - val_aupr: 0.9339 - val_binary_accuracy: 0.8578\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3141 - auroc: 0.9396 - aupr: 0.9401 - binary_accuracy: 0.8654 - val_loss: 0.3250 - val_auroc: 0.9377 - val_aupr: 0.9360 - val_binary_accuracy: 0.8620\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3044 - auroc: 0.9434 - aupr: 0.9442 - binary_accuracy: 0.8724 - val_loss: 0.3358 - val_auroc: 0.9419 - val_aupr: 0.9396 - val_binary_accuracy: 0.8502\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2861 - auroc: 0.9497 - aupr: 0.9502 - binary_accuracy: 0.8792 - val_loss: 0.3101 - val_auroc: 0.9417 - val_aupr: 0.9388 - val_binary_accuracy: 0.8668\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2846 - auroc: 0.9504 - aupr: 0.9512 - binary_accuracy: 0.8820 - val_loss: 0.3150 - val_auroc: 0.9421 - val_aupr: 0.9397 - val_binary_accuracy: 0.8716\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2729 - auroc: 0.9545 - aupr: 0.9551 - binary_accuracy: 0.8878 - val_loss: 0.3196 - val_auroc: 0.9406 - val_aupr: 0.9375 - val_binary_accuracy: 0.8654\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2592 - auroc: 0.9591 - aupr: 0.9578 - binary_accuracy: 0.8946 - val_loss: 0.3206 - val_auroc: 0.9379 - val_aupr: 0.9368 - val_binary_accuracy: 0.8592\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2479 - auroc: 0.9625 - aupr: 0.9624 - binary_accuracy: 0.8998 - val_loss: 0.3411 - val_auroc: 0.9315 - val_aupr: 0.9347 - val_binary_accuracy: 0.8530\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2498 - auroc: 0.9617 - aupr: 0.9626 - binary_accuracy: 0.8961 - val_loss: 0.3385 - val_auroc: 0.9408 - val_aupr: 0.9416 - val_binary_accuracy: 0.8585\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.3496 - auroc: 0.9367 - aupr: 0.9392 - binary_accuracy: 0.8590\n",
      "Epoch 1/100\n",
      "102/102 [==============================] - 2s 10ms/step - loss: 0.7863 - auroc: 0.5022 - aupr: 0.5029 - binary_accuracy: 0.5012 - val_loss: 0.6917 - val_auroc: 0.6220 - val_aupr: 0.6144 - val_binary_accuracy: 0.5535\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.6847 - auroc: 0.5688 - aupr: 0.5692 - binary_accuracy: 0.5454 - val_loss: 0.7210 - val_auroc: 0.7187 - val_aupr: 0.7055 - val_binary_accuracy: 0.5397\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.6233 - auroc: 0.7081 - aupr: 0.6814 - binary_accuracy: 0.6537 - val_loss: 0.5510 - val_auroc: 0.7893 - val_aupr: 0.7545 - val_binary_accuracy: 0.7184\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.5739 - auroc: 0.7633 - aupr: 0.7395 - binary_accuracy: 0.6921 - val_loss: 0.5109 - val_auroc: 0.8233 - val_aupr: 0.8026 - val_binary_accuracy: 0.7398\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.5205 - auroc: 0.8134 - aupr: 0.7959 - binary_accuracy: 0.7298 - val_loss: 0.4218 - val_auroc: 0.8936 - val_aupr: 0.8850 - val_binary_accuracy: 0.8130\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.4304 - auroc: 0.8838 - aupr: 0.8795 - binary_accuracy: 0.8003 - val_loss: 0.3345 - val_auroc: 0.9394 - val_aupr: 0.9366 - val_binary_accuracy: 0.8634\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3694 - auroc: 0.9153 - aupr: 0.9175 - binary_accuracy: 0.8415 - val_loss: 0.3499 - val_auroc: 0.9424 - val_aupr: 0.9372 - val_binary_accuracy: 0.8392\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3566 - auroc: 0.9211 - aupr: 0.9239 - binary_accuracy: 0.8441 - val_loss: 0.2995 - val_auroc: 0.9495 - val_aupr: 0.9464 - val_binary_accuracy: 0.8737\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3363 - auroc: 0.9296 - aupr: 0.9325 - binary_accuracy: 0.8511 - val_loss: 0.3008 - val_auroc: 0.9475 - val_aupr: 0.9462 - val_binary_accuracy: 0.8744\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3404 - auroc: 0.9286 - aupr: 0.9306 - binary_accuracy: 0.8505 - val_loss: 0.2929 - val_auroc: 0.9506 - val_aupr: 0.9479 - val_binary_accuracy: 0.8744\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3164 - auroc: 0.9384 - aupr: 0.9396 - binary_accuracy: 0.8652 - val_loss: 0.2971 - val_auroc: 0.9544 - val_aupr: 0.9492 - val_binary_accuracy: 0.8854\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3125 - auroc: 0.9396 - aupr: 0.9428 - binary_accuracy: 0.8678 - val_loss: 0.2816 - val_auroc: 0.9527 - val_aupr: 0.9479 - val_binary_accuracy: 0.8875\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.3065 - auroc: 0.9419 - aupr: 0.9448 - binary_accuracy: 0.8684 - val_loss: 0.2858 - val_auroc: 0.9539 - val_aupr: 0.9525 - val_binary_accuracy: 0.8903\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.3007 - auroc: 0.9443 - aupr: 0.9465 - binary_accuracy: 0.8690 - val_loss: 0.2776 - val_auroc: 0.9536 - val_aupr: 0.9498 - val_binary_accuracy: 0.8854\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.2945 - auroc: 0.9470 - aupr: 0.9486 - binary_accuracy: 0.8746 - val_loss: 0.3218 - val_auroc: 0.9520 - val_aupr: 0.9531 - val_binary_accuracy: 0.8654\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2916 - auroc: 0.9481 - aupr: 0.9494 - binary_accuracy: 0.8765 - val_loss: 0.2810 - val_auroc: 0.9524 - val_aupr: 0.9490 - val_binary_accuracy: 0.8820\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2730 - auroc: 0.9545 - aupr: 0.9555 - binary_accuracy: 0.8817 - val_loss: 0.3297 - val_auroc: 0.9514 - val_aupr: 0.9490 - val_binary_accuracy: 0.8640\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.2639 - auroc: 0.9571 - aupr: 0.9586 - binary_accuracy: 0.8893 - val_loss: 0.3185 - val_auroc: 0.9525 - val_aupr: 0.9503 - val_binary_accuracy: 0.8682\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2528 - auroc: 0.9610 - aupr: 0.9622 - binary_accuracy: 0.8952 - val_loss: 0.3274 - val_auroc: 0.9486 - val_aupr: 0.9475 - val_binary_accuracy: 0.8661\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.3258 - auroc: 0.9474 - aupr: 0.9512 - binary_accuracy: 0.8641\n",
      "Processing: QKI_K562_200.h5\n",
      "(4786, 200, 9) (4786, 1)\n",
      "Input shape adjusted:\n",
      "(4786, 200, 4)\n",
      "(1368, 200, 4)\n",
      "(684, 200, 4)\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 8ms/step - loss: 0.4876 - auroc: 0.8488 - aupr: 0.8340 - binary_accuracy: 0.7697 - val_loss: 0.3900 - val_auroc: 0.9086 - val_aupr: 0.9180 - val_binary_accuracy: 0.8304\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.3252 - auroc: 0.9361 - aupr: 0.9355 - binary_accuracy: 0.8684 - val_loss: 0.3003 - val_auroc: 0.9444 - val_aupr: 0.9522 - val_binary_accuracy: 0.8801\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.2329 - auroc: 0.9667 - aupr: 0.9682 - binary_accuracy: 0.9139 - val_loss: 0.2133 - val_auroc: 0.9732 - val_aupr: 0.9771 - val_binary_accuracy: 0.9313\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1868 - auroc: 0.9779 - aupr: 0.9786 - binary_accuracy: 0.9329 - val_loss: 0.1801 - val_auroc: 0.9825 - val_aupr: 0.9863 - val_binary_accuracy: 0.9327\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1303 - auroc: 0.9875 - aupr: 0.9892 - binary_accuracy: 0.9578 - val_loss: 0.1431 - val_auroc: 0.9889 - val_aupr: 0.9912 - val_binary_accuracy: 0.9488\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0999 - auroc: 0.9923 - aupr: 0.9931 - binary_accuracy: 0.9687 - val_loss: 0.1130 - val_auroc: 0.9903 - val_aupr: 0.9901 - val_binary_accuracy: 0.9605\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0925 - auroc: 0.9938 - aupr: 0.9941 - binary_accuracy: 0.9693 - val_loss: 0.1079 - val_auroc: 0.9919 - val_aupr: 0.9936 - val_binary_accuracy: 0.9605\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0859 - auroc: 0.9946 - aupr: 0.9949 - binary_accuracy: 0.9714 - val_loss: 0.1808 - val_auroc: 0.9868 - val_aupr: 0.9909 - val_binary_accuracy: 0.9415\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0610 - auroc: 0.9970 - aupr: 0.9974 - binary_accuracy: 0.9802 - val_loss: 0.1367 - val_auroc: 0.9871 - val_aupr: 0.9907 - val_binary_accuracy: 0.9605\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0527 - auroc: 0.9977 - aupr: 0.9977 - binary_accuracy: 0.9831 - val_loss: 0.1265 - val_auroc: 0.9879 - val_aupr: 0.9889 - val_binary_accuracy: 0.9532\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0431 - auroc: 0.9985 - aupr: 0.9984 - binary_accuracy: 0.9860 - val_loss: 0.1416 - val_auroc: 0.9849 - val_aupr: 0.9858 - val_binary_accuracy: 0.9561\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0357 - auroc: 0.9990 - aupr: 0.9992 - binary_accuracy: 0.9910 - val_loss: 0.1460 - val_auroc: 0.9855 - val_aupr: 0.9881 - val_binary_accuracy: 0.9532\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1673 - auroc: 0.9838 - aupr: 0.9864 - binary_accuracy: 0.9583\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 8ms/step - loss: 0.6209 - auroc: 0.7379 - aupr: 0.6910 - binary_accuracy: 0.6830 - val_loss: 0.4430 - val_auroc: 0.8780 - val_aupr: 0.8797 - val_binary_accuracy: 0.7968\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.3900 - auroc: 0.9077 - aupr: 0.9064 - binary_accuracy: 0.8343 - val_loss: 0.3709 - val_auroc: 0.9351 - val_aupr: 0.9465 - val_binary_accuracy: 0.8538\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.2616 - auroc: 0.9577 - aupr: 0.9612 - binary_accuracy: 0.8982 - val_loss: 0.1869 - val_auroc: 0.9775 - val_aupr: 0.9832 - val_binary_accuracy: 0.9357\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1775 - auroc: 0.9790 - aupr: 0.9822 - binary_accuracy: 0.9367 - val_loss: 0.1355 - val_auroc: 0.9906 - val_aupr: 0.9925 - val_binary_accuracy: 0.9532\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1561 - auroc: 0.9831 - aupr: 0.9861 - binary_accuracy: 0.9476 - val_loss: 0.1021 - val_auroc: 0.9934 - val_aupr: 0.9948 - val_binary_accuracy: 0.9620\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1299 - auroc: 0.9870 - aupr: 0.9888 - binary_accuracy: 0.9576 - val_loss: 0.0960 - val_auroc: 0.9939 - val_aupr: 0.9955 - val_binary_accuracy: 0.9635\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1236 - auroc: 0.9885 - aupr: 0.9901 - binary_accuracy: 0.9590 - val_loss: 0.1355 - val_auroc: 0.9920 - val_aupr: 0.9938 - val_binary_accuracy: 0.9386\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1130 - auroc: 0.9898 - aupr: 0.9916 - binary_accuracy: 0.9616 - val_loss: 0.1131 - val_auroc: 0.9944 - val_aupr: 0.9958 - val_binary_accuracy: 0.9649\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0977 - auroc: 0.9928 - aupr: 0.9935 - binary_accuracy: 0.9662 - val_loss: 0.1028 - val_auroc: 0.9935 - val_aupr: 0.9950 - val_binary_accuracy: 0.9605\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0883 - auroc: 0.9940 - aupr: 0.9946 - binary_accuracy: 0.9701 - val_loss: 0.1693 - val_auroc: 0.9915 - val_aupr: 0.9940 - val_binary_accuracy: 0.9459\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0796 - auroc: 0.9945 - aupr: 0.9946 - binary_accuracy: 0.9728 - val_loss: 0.1785 - val_auroc: 0.9877 - val_aupr: 0.9829 - val_binary_accuracy: 0.9532\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2711 - auroc: 0.9750 - aupr: 0.9641 - binary_accuracy: 0.9262\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 10ms/step - loss: 0.5850 - auroc: 0.7576 - aupr: 0.7407 - binary_accuracy: 0.6839 - val_loss: 0.5163 - val_auroc: 0.8611 - val_aupr: 0.8536 - val_binary_accuracy: 0.7675\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4435 - auroc: 0.8761 - aupr: 0.8704 - binary_accuracy: 0.7986 - val_loss: 0.3734 - val_auroc: 0.9169 - val_aupr: 0.9267 - val_binary_accuracy: 0.8363\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.3242 - auroc: 0.9355 - aupr: 0.9374 - binary_accuracy: 0.8677 - val_loss: 0.2297 - val_auroc: 0.9720 - val_aupr: 0.9762 - val_binary_accuracy: 0.9035\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.2289 - auroc: 0.9671 - aupr: 0.9691 - binary_accuracy: 0.9091 - val_loss: 0.2221 - val_auroc: 0.9881 - val_aupr: 0.9906 - val_binary_accuracy: 0.9137\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.1591 - auroc: 0.9825 - aupr: 0.9848 - binary_accuracy: 0.9425 - val_loss: 0.1191 - val_auroc: 0.9903 - val_aupr: 0.9929 - val_binary_accuracy: 0.9474\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.1233 - auroc: 0.9888 - aupr: 0.9896 - binary_accuracy: 0.9586 - val_loss: 0.1234 - val_auroc: 0.9905 - val_aupr: 0.9931 - val_binary_accuracy: 0.9532\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.1037 - auroc: 0.9919 - aupr: 0.9923 - binary_accuracy: 0.9645 - val_loss: 0.1182 - val_auroc: 0.9900 - val_aupr: 0.9925 - val_binary_accuracy: 0.9620\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0830 - auroc: 0.9948 - aupr: 0.9952 - binary_accuracy: 0.9714 - val_loss: 0.1281 - val_auroc: 0.9912 - val_aupr: 0.9933 - val_binary_accuracy: 0.9488\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0898 - auroc: 0.9945 - aupr: 0.9948 - binary_accuracy: 0.9666 - val_loss: 0.2309 - val_auroc: 0.9869 - val_aupr: 0.9910 - val_binary_accuracy: 0.9240\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1197 - auroc: 0.9910 - aupr: 0.9917 - binary_accuracy: 0.9511 - val_loss: 0.1080 - val_auroc: 0.9915 - val_aupr: 0.9938 - val_binary_accuracy: 0.9605\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0630 - auroc: 0.9969 - aupr: 0.9970 - binary_accuracy: 0.9781 - val_loss: 0.1174 - val_auroc: 0.9923 - val_aupr: 0.9937 - val_binary_accuracy: 0.9561\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0565 - auroc: 0.9977 - aupr: 0.9979 - binary_accuracy: 0.9802 - val_loss: 0.1319 - val_auroc: 0.9891 - val_aupr: 0.9921 - val_binary_accuracy: 0.9547\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0479 - auroc: 0.9980 - aupr: 0.9973 - binary_accuracy: 0.9829 - val_loss: 0.1435 - val_auroc: 0.9887 - val_aupr: 0.9899 - val_binary_accuracy: 0.9591\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0734 - auroc: 0.9963 - aupr: 0.9963 - binary_accuracy: 0.9710 - val_loss: 0.1784 - val_auroc: 0.9860 - val_aupr: 0.9906 - val_binary_accuracy: 0.9444\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0502 - auroc: 0.9980 - aupr: 0.9983 - binary_accuracy: 0.9812 - val_loss: 0.1578 - val_auroc: 0.9880 - val_aupr: 0.9878 - val_binary_accuracy: 0.9474\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2423 - auroc: 0.9774 - aupr: 0.9704 - binary_accuracy: 0.9393\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.9209 - auroc: 0.5056 - aupr: 0.5033 - binary_accuracy: 0.5088 - val_loss: 0.7084 - val_auroc: 0.6361 - val_aupr: 0.6377 - val_binary_accuracy: 0.4708\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.6939 - auroc: 0.5145 - aupr: 0.5046 - binary_accuracy: 0.5067 - val_loss: 0.6973 - val_auroc: 0.6983 - val_aupr: 0.6907 - val_binary_accuracy: 0.4708\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.6658 - auroc: 0.6389 - aupr: 0.6183 - binary_accuracy: 0.5915 - val_loss: 0.5757 - val_auroc: 0.7952 - val_aupr: 0.7900 - val_binary_accuracy: 0.7135\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.5340 - auroc: 0.8112 - aupr: 0.7900 - binary_accuracy: 0.7384 - val_loss: 0.5604 - val_auroc: 0.8386 - val_aupr: 0.8259 - val_binary_accuracy: 0.7003\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4790 - auroc: 0.8535 - aupr: 0.8451 - binary_accuracy: 0.7817 - val_loss: 0.4134 - val_auroc: 0.8926 - val_aupr: 0.9009 - val_binary_accuracy: 0.8260\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4008 - auroc: 0.9005 - aupr: 0.9013 - binary_accuracy: 0.8249 - val_loss: 0.4105 - val_auroc: 0.9248 - val_aupr: 0.9367 - val_binary_accuracy: 0.8231\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.3126 - auroc: 0.9395 - aupr: 0.9421 - binary_accuracy: 0.8700 - val_loss: 0.2678 - val_auroc: 0.9620 - val_aupr: 0.9683 - val_binary_accuracy: 0.8947\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.2427 - auroc: 0.9631 - aupr: 0.9667 - binary_accuracy: 0.9108 - val_loss: 0.2519 - val_auroc: 0.9801 - val_aupr: 0.9852 - val_binary_accuracy: 0.8933\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.2266 - auroc: 0.9672 - aupr: 0.9679 - binary_accuracy: 0.9160 - val_loss: 0.1612 - val_auroc: 0.9872 - val_aupr: 0.9900 - val_binary_accuracy: 0.9342\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.1876 - auroc: 0.9756 - aupr: 0.9786 - binary_accuracy: 0.9371 - val_loss: 0.2049 - val_auroc: 0.9873 - val_aupr: 0.9905 - val_binary_accuracy: 0.9196\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1543 - auroc: 0.9824 - aupr: 0.9849 - binary_accuracy: 0.9461 - val_loss: 0.1337 - val_auroc: 0.9879 - val_aupr: 0.9910 - val_binary_accuracy: 0.9518\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.1493 - auroc: 0.9833 - aupr: 0.9855 - binary_accuracy: 0.9473 - val_loss: 0.1329 - val_auroc: 0.9889 - val_aupr: 0.9918 - val_binary_accuracy: 0.9532\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.1408 - auroc: 0.9853 - aupr: 0.9876 - binary_accuracy: 0.9511 - val_loss: 0.1382 - val_auroc: 0.9900 - val_aupr: 0.9926 - val_binary_accuracy: 0.9474\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1400 - auroc: 0.9851 - aupr: 0.9868 - binary_accuracy: 0.9522 - val_loss: 0.1166 - val_auroc: 0.9893 - val_aupr: 0.9925 - val_binary_accuracy: 0.9635\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1314 - auroc: 0.9872 - aupr: 0.9888 - binary_accuracy: 0.9576 - val_loss: 0.1278 - val_auroc: 0.9903 - val_aupr: 0.9931 - val_binary_accuracy: 0.9547\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.1284 - auroc: 0.9876 - aupr: 0.9892 - binary_accuracy: 0.9536 - val_loss: 0.1600 - val_auroc: 0.9913 - val_aupr: 0.9937 - val_binary_accuracy: 0.9371\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.1332 - auroc: 0.9858 - aupr: 0.9870 - binary_accuracy: 0.9547 - val_loss: 0.1206 - val_auroc: 0.9893 - val_aupr: 0.9923 - val_binary_accuracy: 0.9576\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.1322 - auroc: 0.9870 - aupr: 0.9895 - binary_accuracy: 0.9524 - val_loss: 0.1776 - val_auroc: 0.9877 - val_aupr: 0.9915 - val_binary_accuracy: 0.9284\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.1090 - auroc: 0.9902 - aupr: 0.9918 - binary_accuracy: 0.9630 - val_loss: 0.1105 - val_auroc: 0.9909 - val_aupr: 0.9936 - val_binary_accuracy: 0.9576\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1041 - auroc: 0.9911 - aupr: 0.9925 - binary_accuracy: 0.9653 - val_loss: 0.1192 - val_auroc: 0.9894 - val_aupr: 0.9929 - val_binary_accuracy: 0.9649\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1051 - auroc: 0.9914 - aupr: 0.9921 - binary_accuracy: 0.9613 - val_loss: 0.1203 - val_auroc: 0.9904 - val_aupr: 0.9934 - val_binary_accuracy: 0.9591\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.1002 - auroc: 0.9919 - aupr: 0.9930 - binary_accuracy: 0.9664 - val_loss: 0.5350 - val_auroc: 0.9816 - val_aupr: 0.9874 - val_binary_accuracy: 0.8012\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.1306 - auroc: 0.9886 - aupr: 0.9890 - binary_accuracy: 0.9519 - val_loss: 0.1130 - val_auroc: 0.9900 - val_aupr: 0.9930 - val_binary_accuracy: 0.9635\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0919 - auroc: 0.9927 - aupr: 0.9935 - binary_accuracy: 0.9691 - val_loss: 0.1145 - val_auroc: 0.9893 - val_aupr: 0.9927 - val_binary_accuracy: 0.9664\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1499 - auroc: 0.9855 - aupr: 0.9837 - binary_accuracy: 0.9605\n",
      "Processing: RBFOX2_K562_200.h5\n",
      "(6283, 200, 9) (6283, 1)\n",
      "Input shape adjusted:\n",
      "(6283, 200, 4)\n",
      "(1796, 200, 4)\n",
      "(897, 200, 4)\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 7ms/step - loss: 0.5041 - auroc: 0.8320 - aupr: 0.8415 - binary_accuracy: 0.7546 - val_loss: 0.4132 - val_auroc: 0.9098 - val_aupr: 0.9105 - val_binary_accuracy: 0.8183\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3712 - auroc: 0.9136 - aupr: 0.9203 - binary_accuracy: 0.8338 - val_loss: 0.3440 - val_auroc: 0.9278 - val_aupr: 0.9267 - val_binary_accuracy: 0.8517\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3146 - auroc: 0.9394 - aupr: 0.9422 - binary_accuracy: 0.8622 - val_loss: 0.3187 - val_auroc: 0.9416 - val_aupr: 0.9369 - val_binary_accuracy: 0.8584\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2919 - auroc: 0.9482 - aupr: 0.9483 - binary_accuracy: 0.8787 - val_loss: 0.3070 - val_auroc: 0.9443 - val_aupr: 0.9405 - val_binary_accuracy: 0.8606\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2577 - auroc: 0.9596 - aupr: 0.9608 - binary_accuracy: 0.8889 - val_loss: 0.2984 - val_auroc: 0.9498 - val_aupr: 0.9474 - val_binary_accuracy: 0.8629\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2312 - auroc: 0.9676 - aupr: 0.9672 - binary_accuracy: 0.9053 - val_loss: 0.2835 - val_auroc: 0.9526 - val_aupr: 0.9494 - val_binary_accuracy: 0.8841\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2085 - auroc: 0.9736 - aupr: 0.9733 - binary_accuracy: 0.9160 - val_loss: 0.2847 - val_auroc: 0.9537 - val_aupr: 0.9506 - val_binary_accuracy: 0.8785\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2003 - auroc: 0.9753 - aupr: 0.9755 - binary_accuracy: 0.9217 - val_loss: 0.2881 - val_auroc: 0.9517 - val_aupr: 0.9486 - val_binary_accuracy: 0.8740\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1848 - auroc: 0.9790 - aupr: 0.9794 - binary_accuracy: 0.9271 - val_loss: 0.3000 - val_auroc: 0.9499 - val_aupr: 0.9485 - val_binary_accuracy: 0.8763\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1637 - auroc: 0.9834 - aupr: 0.9827 - binary_accuracy: 0.9387 - val_loss: 0.3317 - val_auroc: 0.9492 - val_aupr: 0.9480 - val_binary_accuracy: 0.8796\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1754 - auroc: 0.9810 - aupr: 0.9809 - binary_accuracy: 0.9292 - val_loss: 0.3440 - val_auroc: 0.9495 - val_aupr: 0.9466 - val_binary_accuracy: 0.8584\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3387 - auroc: 0.9490 - aupr: 0.9510 - binary_accuracy: 0.8669\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 7ms/step - loss: 0.6088 - auroc: 0.7509 - aupr: 0.7436 - binary_accuracy: 0.6963 - val_loss: 0.4090 - val_auroc: 0.8959 - val_aupr: 0.8989 - val_binary_accuracy: 0.8183\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3897 - auroc: 0.9045 - aupr: 0.9104 - binary_accuracy: 0.8216 - val_loss: 0.3484 - val_auroc: 0.9253 - val_aupr: 0.9200 - val_binary_accuracy: 0.8517\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3450 - auroc: 0.9262 - aupr: 0.9281 - binary_accuracy: 0.8451 - val_loss: 0.3173 - val_auroc: 0.9396 - val_aupr: 0.9322 - val_binary_accuracy: 0.8651\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3169 - auroc: 0.9383 - aupr: 0.9408 - binary_accuracy: 0.8604 - val_loss: 0.3030 - val_auroc: 0.9461 - val_aupr: 0.9410 - val_binary_accuracy: 0.8740\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2939 - auroc: 0.9469 - aupr: 0.9508 - binary_accuracy: 0.8714 - val_loss: 0.3285 - val_auroc: 0.9473 - val_aupr: 0.9427 - val_binary_accuracy: 0.8562\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2819 - auroc: 0.9512 - aupr: 0.9536 - binary_accuracy: 0.8779 - val_loss: 0.2932 - val_auroc: 0.9513 - val_aupr: 0.9459 - val_binary_accuracy: 0.8896\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2649 - auroc: 0.9573 - aupr: 0.9580 - binary_accuracy: 0.8854 - val_loss: 0.2662 - val_auroc: 0.9598 - val_aupr: 0.9541 - val_binary_accuracy: 0.8974\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2395 - auroc: 0.9651 - aupr: 0.9674 - binary_accuracy: 0.8965 - val_loss: 0.2698 - val_auroc: 0.9598 - val_aupr: 0.9552 - val_binary_accuracy: 0.8974\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2167 - auroc: 0.9714 - aupr: 0.9727 - binary_accuracy: 0.9090 - val_loss: 0.2764 - val_auroc: 0.9608 - val_aupr: 0.9566 - val_binary_accuracy: 0.8885\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2034 - auroc: 0.9746 - aupr: 0.9754 - binary_accuracy: 0.9123 - val_loss: 0.2596 - val_auroc: 0.9618 - val_aupr: 0.9580 - val_binary_accuracy: 0.9075\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1915 - auroc: 0.9776 - aupr: 0.9789 - binary_accuracy: 0.9188 - val_loss: 0.2654 - val_auroc: 0.9629 - val_aupr: 0.9608 - val_binary_accuracy: 0.9064\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1693 - auroc: 0.9824 - aupr: 0.9835 - binary_accuracy: 0.9285 - val_loss: 0.3126 - val_auroc: 0.9621 - val_aupr: 0.9600 - val_binary_accuracy: 0.8740\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1782 - auroc: 0.9805 - aupr: 0.9814 - binary_accuracy: 0.9238 - val_loss: 0.2954 - val_auroc: 0.9641 - val_aupr: 0.9624 - val_binary_accuracy: 0.8986\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1595 - auroc: 0.9847 - aupr: 0.9854 - binary_accuracy: 0.9341 - val_loss: 0.2672 - val_auroc: 0.9639 - val_aupr: 0.9616 - val_binary_accuracy: 0.9086\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1446 - auroc: 0.9870 - aupr: 0.9875 - binary_accuracy: 0.9386 - val_loss: 0.3030 - val_auroc: 0.9619 - val_aupr: 0.9598 - val_binary_accuracy: 0.9041\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.3650 - auroc: 0.9481 - aupr: 0.9472 - binary_accuracy: 0.8792\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 2s 20ms/step - loss: 0.5030 - auroc: 0.8315 - aupr: 0.8445 - binary_accuracy: 0.7544 - val_loss: 0.4117 - val_auroc: 0.8898 - val_aupr: 0.9011 - val_binary_accuracy: 0.8272\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.4070 - auroc: 0.8944 - aupr: 0.9044 - binary_accuracy: 0.8209 - val_loss: 0.3665 - val_auroc: 0.9275 - val_aupr: 0.9239 - val_binary_accuracy: 0.8450\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.3515 - auroc: 0.9238 - aupr: 0.9266 - binary_accuracy: 0.8443 - val_loss: 0.3147 - val_auroc: 0.9417 - val_aupr: 0.9361 - val_binary_accuracy: 0.8740\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.3176 - auroc: 0.9378 - aupr: 0.9414 - binary_accuracy: 0.8661 - val_loss: 0.3082 - val_auroc: 0.9499 - val_aupr: 0.9431 - val_binary_accuracy: 0.8685\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.2743 - auroc: 0.9540 - aupr: 0.9573 - binary_accuracy: 0.8840 - val_loss: 0.2649 - val_auroc: 0.9619 - val_aupr: 0.9584 - val_binary_accuracy: 0.8930\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2437 - auroc: 0.9639 - aupr: 0.9649 - binary_accuracy: 0.8950 - val_loss: 0.2777 - val_auroc: 0.9596 - val_aupr: 0.9546 - val_binary_accuracy: 0.8907\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.2101 - auroc: 0.9731 - aupr: 0.9744 - binary_accuracy: 0.9118 - val_loss: 0.3109 - val_auroc: 0.9573 - val_aupr: 0.9529 - val_binary_accuracy: 0.8785\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.1956 - auroc: 0.9766 - aupr: 0.9768 - binary_accuracy: 0.9185 - val_loss: 0.2813 - val_auroc: 0.9569 - val_aupr: 0.9539 - val_binary_accuracy: 0.8952\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.1594 - auroc: 0.9844 - aupr: 0.9849 - binary_accuracy: 0.9357 - val_loss: 0.3445 - val_auroc: 0.9529 - val_aupr: 0.9429 - val_binary_accuracy: 0.8629\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.1488 - auroc: 0.9862 - aupr: 0.9867 - binary_accuracy: 0.9395 - val_loss: 0.3222 - val_auroc: 0.9529 - val_aupr: 0.9453 - val_binary_accuracy: 0.8818\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3266 - auroc: 0.9506 - aupr: 0.9419 - binary_accuracy: 0.8808\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 2s 12ms/step - loss: 0.7547 - auroc: 0.6123 - aupr: 0.6088 - binary_accuracy: 0.5811 - val_loss: 0.5002 - val_auroc: 0.8523 - val_aupr: 0.8651 - val_binary_accuracy: 0.7625\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.4735 - auroc: 0.8522 - aupr: 0.8648 - binary_accuracy: 0.7820 - val_loss: 0.4215 - val_auroc: 0.8827 - val_aupr: 0.8960 - val_binary_accuracy: 0.8149\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.4453 - auroc: 0.8693 - aupr: 0.8848 - binary_accuracy: 0.7974 - val_loss: 0.4372 - val_auroc: 0.8858 - val_aupr: 0.8991 - val_binary_accuracy: 0.8105\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.4370 - auroc: 0.8748 - aupr: 0.8885 - binary_accuracy: 0.8004 - val_loss: 0.4351 - val_auroc: 0.8905 - val_aupr: 0.9014 - val_binary_accuracy: 0.8049\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.4348 - auroc: 0.8762 - aupr: 0.8916 - binary_accuracy: 0.7998 - val_loss: 0.4157 - val_auroc: 0.8905 - val_aupr: 0.9000 - val_binary_accuracy: 0.8272\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.4166 - auroc: 0.8881 - aupr: 0.9025 - binary_accuracy: 0.8061 - val_loss: 0.4164 - val_auroc: 0.8970 - val_aupr: 0.9014 - val_binary_accuracy: 0.8082\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.3979 - auroc: 0.9008 - aupr: 0.9082 - binary_accuracy: 0.8133 - val_loss: 0.3724 - val_auroc: 0.9175 - val_aupr: 0.9204 - val_binary_accuracy: 0.8350\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.3677 - auroc: 0.9158 - aupr: 0.9220 - binary_accuracy: 0.8324 - val_loss: 0.3613 - val_auroc: 0.9267 - val_aupr: 0.9281 - val_binary_accuracy: 0.8417\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.3482 - auroc: 0.9247 - aupr: 0.9300 - binary_accuracy: 0.8458 - val_loss: 0.3826 - val_auroc: 0.9278 - val_aupr: 0.9264 - val_binary_accuracy: 0.8350\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.3406 - auroc: 0.9290 - aupr: 0.9301 - binary_accuracy: 0.8491 - val_loss: 0.3069 - val_auroc: 0.9450 - val_aupr: 0.9404 - val_binary_accuracy: 0.8662\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3246 - auroc: 0.9360 - aupr: 0.9354 - binary_accuracy: 0.8614 - val_loss: 0.2782 - val_auroc: 0.9543 - val_aupr: 0.9510 - val_binary_accuracy: 0.8841\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.2851 - auroc: 0.9503 - aupr: 0.9510 - binary_accuracy: 0.8806 - val_loss: 0.2646 - val_auroc: 0.9618 - val_aupr: 0.9580 - val_binary_accuracy: 0.8807\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.2736 - auroc: 0.9545 - aupr: 0.9558 - binary_accuracy: 0.8886 - val_loss: 0.2610 - val_auroc: 0.9630 - val_aupr: 0.9599 - val_binary_accuracy: 0.8863\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.2629 - auroc: 0.9580 - aupr: 0.9605 - binary_accuracy: 0.8918 - val_loss: 0.2509 - val_auroc: 0.9638 - val_aupr: 0.9620 - val_binary_accuracy: 0.8963\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.2511 - auroc: 0.9613 - aupr: 0.9630 - binary_accuracy: 0.8930 - val_loss: 0.2461 - val_auroc: 0.9631 - val_aupr: 0.9614 - val_binary_accuracy: 0.9008\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.2488 - auroc: 0.9620 - aupr: 0.9639 - binary_accuracy: 0.8953 - val_loss: 0.2670 - val_auroc: 0.9588 - val_aupr: 0.9561 - val_binary_accuracy: 0.8963\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.2372 - auroc: 0.9654 - aupr: 0.9673 - binary_accuracy: 0.9039 - val_loss: 0.2754 - val_auroc: 0.9603 - val_aupr: 0.9582 - val_binary_accuracy: 0.8818\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.2210 - auroc: 0.9701 - aupr: 0.9723 - binary_accuracy: 0.9078 - val_loss: 0.2475 - val_auroc: 0.9643 - val_aupr: 0.9614 - val_binary_accuracy: 0.8907\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.2091 - auroc: 0.9733 - aupr: 0.9744 - binary_accuracy: 0.9136 - val_loss: 0.2691 - val_auroc: 0.9669 - val_aupr: 0.9666 - val_binary_accuracy: 0.8952\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.2038 - auroc: 0.9748 - aupr: 0.9766 - binary_accuracy: 0.9136 - val_loss: 0.2456 - val_auroc: 0.9665 - val_aupr: 0.9653 - val_binary_accuracy: 0.8963\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.1778 - auroc: 0.9805 - aupr: 0.9822 - binary_accuracy: 0.9255 - val_loss: 0.2508 - val_auroc: 0.9628 - val_aupr: 0.9626 - val_binary_accuracy: 0.9008\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.1767 - auroc: 0.9806 - aupr: 0.9820 - binary_accuracy: 0.9309 - val_loss: 0.2920 - val_auroc: 0.9618 - val_aupr: 0.9582 - val_binary_accuracy: 0.8829\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.1528 - auroc: 0.9852 - aupr: 0.9856 - binary_accuracy: 0.9382 - val_loss: 0.2921 - val_auroc: 0.9605 - val_aupr: 0.9611 - val_binary_accuracy: 0.8963\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.1451 - auroc: 0.9865 - aupr: 0.9876 - binary_accuracy: 0.9467 - val_loss: 0.3120 - val_auroc: 0.9600 - val_aupr: 0.9552 - val_binary_accuracy: 0.8829\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.1392 - auroc: 0.9878 - aupr: 0.9884 - binary_accuracy: 0.9456 - val_loss: 0.2882 - val_auroc: 0.9599 - val_aupr: 0.9602 - val_binary_accuracy: 0.8907\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3496 - auroc: 0.9466 - aupr: 0.9381 - binary_accuracy: 0.8836\n",
      "Processing: SF3B4_K562_200.h5\n",
      "(22873, 200, 9) (22873, 1)\n",
      "Input shape adjusted:\n",
      "(22873, 200, 4)\n",
      "(6536, 200, 4)\n",
      "(3267, 200, 4)\n",
      "Epoch 1/100\n",
      "229/229 [==============================] - 2s 4ms/step - loss: 0.5047 - auroc: 0.8320 - aupr: 0.8281 - binary_accuracy: 0.7495 - val_loss: 0.3850 - val_auroc: 0.9107 - val_aupr: 0.9075 - val_binary_accuracy: 0.8283\n",
      "Epoch 2/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.3779 - auroc: 0.9112 - aupr: 0.9061 - binary_accuracy: 0.8312 - val_loss: 0.3695 - val_auroc: 0.9303 - val_aupr: 0.9320 - val_binary_accuracy: 0.8313\n",
      "Epoch 3/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.3347 - auroc: 0.9312 - aupr: 0.9289 - binary_accuracy: 0.8560 - val_loss: 0.3116 - val_auroc: 0.9420 - val_aupr: 0.9443 - val_binary_accuracy: 0.8650\n",
      "Epoch 4/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.3005 - auroc: 0.9450 - aupr: 0.9433 - binary_accuracy: 0.8725 - val_loss: 0.2930 - val_auroc: 0.9478 - val_aupr: 0.9502 - val_binary_accuracy: 0.8757\n",
      "Epoch 5/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2860 - auroc: 0.9501 - aupr: 0.9496 - binary_accuracy: 0.8775 - val_loss: 0.2884 - val_auroc: 0.9501 - val_aupr: 0.9526 - val_binary_accuracy: 0.8791\n",
      "Epoch 6/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2716 - auroc: 0.9552 - aupr: 0.9543 - binary_accuracy: 0.8872 - val_loss: 0.2950 - val_auroc: 0.9512 - val_aupr: 0.9536 - val_binary_accuracy: 0.8782\n",
      "Epoch 7/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2631 - auroc: 0.9582 - aupr: 0.9576 - binary_accuracy: 0.8914 - val_loss: 0.2769 - val_auroc: 0.9537 - val_aupr: 0.9540 - val_binary_accuracy: 0.8907\n",
      "Epoch 8/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2531 - auroc: 0.9614 - aupr: 0.9609 - binary_accuracy: 0.8960 - val_loss: 0.2770 - val_auroc: 0.9533 - val_aupr: 0.9526 - val_binary_accuracy: 0.8916\n",
      "Epoch 9/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2532 - auroc: 0.9612 - aupr: 0.9613 - binary_accuracy: 0.8952 - val_loss: 0.2689 - val_auroc: 0.9563 - val_aupr: 0.9564 - val_binary_accuracy: 0.8916\n",
      "Epoch 10/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2478 - auroc: 0.9630 - aupr: 0.9626 - binary_accuracy: 0.8995 - val_loss: 0.2732 - val_auroc: 0.9558 - val_aupr: 0.9560 - val_binary_accuracy: 0.8904\n",
      "Epoch 11/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2381 - auroc: 0.9658 - aupr: 0.9654 - binary_accuracy: 0.9032 - val_loss: 0.3188 - val_auroc: 0.9524 - val_aupr: 0.9559 - val_binary_accuracy: 0.8721\n",
      "Epoch 12/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2330 - auroc: 0.9673 - aupr: 0.9668 - binary_accuracy: 0.9043 - val_loss: 0.2903 - val_auroc: 0.9546 - val_aupr: 0.9568 - val_binary_accuracy: 0.8861\n",
      "Epoch 13/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2305 - auroc: 0.9680 - aupr: 0.9669 - binary_accuracy: 0.9071 - val_loss: 0.2938 - val_auroc: 0.9543 - val_aupr: 0.9560 - val_binary_accuracy: 0.8849\n",
      "Epoch 14/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2228 - auroc: 0.9700 - aupr: 0.9699 - binary_accuracy: 0.9076 - val_loss: 0.2772 - val_auroc: 0.9549 - val_aupr: 0.9553 - val_binary_accuracy: 0.8916\n",
      "205/205 [==============================] - 0s 1ms/step - loss: 0.2807 - auroc: 0.9532 - aupr: 0.9506 - binary_accuracy: 0.8822\n",
      "Epoch 1/100\n",
      "229/229 [==============================] - 2s 4ms/step - loss: 0.5853 - auroc: 0.7576 - aupr: 0.7611 - binary_accuracy: 0.6831 - val_loss: 0.4327 - val_auroc: 0.8898 - val_aupr: 0.8849 - val_binary_accuracy: 0.8059\n",
      "Epoch 2/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.4174 - auroc: 0.8905 - aupr: 0.8861 - binary_accuracy: 0.8049 - val_loss: 0.3433 - val_auroc: 0.9342 - val_aupr: 0.9333 - val_binary_accuracy: 0.8436\n",
      "Epoch 3/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.3474 - auroc: 0.9260 - aupr: 0.9238 - binary_accuracy: 0.8451 - val_loss: 0.3050 - val_auroc: 0.9435 - val_aupr: 0.9432 - val_binary_accuracy: 0.8711\n",
      "Epoch 4/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.3226 - auroc: 0.9366 - aupr: 0.9353 - binary_accuracy: 0.8600 - val_loss: 0.3006 - val_auroc: 0.9469 - val_aupr: 0.9449 - val_binary_accuracy: 0.8791\n",
      "Epoch 5/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.3017 - auroc: 0.9451 - aupr: 0.9438 - binary_accuracy: 0.8742 - val_loss: 0.2954 - val_auroc: 0.9493 - val_aupr: 0.9480 - val_binary_accuracy: 0.8779\n",
      "Epoch 6/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2855 - auroc: 0.9506 - aupr: 0.9491 - binary_accuracy: 0.8802 - val_loss: 0.3036 - val_auroc: 0.9501 - val_aupr: 0.9474 - val_binary_accuracy: 0.8745\n",
      "Epoch 7/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2724 - auroc: 0.9553 - aupr: 0.9542 - binary_accuracy: 0.8851 - val_loss: 0.2786 - val_auroc: 0.9555 - val_aupr: 0.9536 - val_binary_accuracy: 0.8858\n",
      "Epoch 8/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2678 - auroc: 0.9571 - aupr: 0.9554 - binary_accuracy: 0.8880 - val_loss: 0.2769 - val_auroc: 0.9540 - val_aupr: 0.9530 - val_binary_accuracy: 0.8855\n",
      "Epoch 9/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2562 - auroc: 0.9602 - aupr: 0.9598 - binary_accuracy: 0.8923 - val_loss: 0.2874 - val_auroc: 0.9529 - val_aupr: 0.9494 - val_binary_accuracy: 0.8840\n",
      "Epoch 10/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2505 - auroc: 0.9620 - aupr: 0.9614 - binary_accuracy: 0.8939 - val_loss: 0.2838 - val_auroc: 0.9555 - val_aupr: 0.9542 - val_binary_accuracy: 0.8834\n",
      "Epoch 11/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2439 - auroc: 0.9642 - aupr: 0.9636 - binary_accuracy: 0.8999 - val_loss: 0.3045 - val_auroc: 0.9520 - val_aupr: 0.9521 - val_binary_accuracy: 0.8672\n",
      "Epoch 12/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2380 - auroc: 0.9659 - aupr: 0.9654 - binary_accuracy: 0.9019 - val_loss: 0.2822 - val_auroc: 0.9560 - val_aupr: 0.9571 - val_binary_accuracy: 0.8892\n",
      "Epoch 13/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.2338 - auroc: 0.9669 - aupr: 0.9666 - binary_accuracy: 0.9032 - val_loss: 0.2873 - val_auroc: 0.9547 - val_aupr: 0.9565 - val_binary_accuracy: 0.8800\n",
      "205/205 [==============================] - 0s 1ms/step - loss: 0.2843 - auroc: 0.9548 - aupr: 0.9537 - binary_accuracy: 0.8856\n",
      "Epoch 1/100\n",
      "229/229 [==============================] - 3s 9ms/step - loss: 0.4773 - auroc: 0.8513 - aupr: 0.8427 - binary_accuracy: 0.7651 - val_loss: 0.3982 - val_auroc: 0.9208 - val_aupr: 0.9178 - val_binary_accuracy: 0.8234\n",
      "Epoch 2/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.3720 - auroc: 0.9147 - aupr: 0.9101 - binary_accuracy: 0.8358 - val_loss: 0.3213 - val_auroc: 0.9374 - val_aupr: 0.9346 - val_binary_accuracy: 0.8555\n",
      "Epoch 3/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.3430 - auroc: 0.9276 - aupr: 0.9239 - binary_accuracy: 0.8501 - val_loss: 0.3221 - val_auroc: 0.9436 - val_aupr: 0.9418 - val_binary_accuracy: 0.8650\n",
      "Epoch 4/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.3265 - auroc: 0.9349 - aupr: 0.9314 - binary_accuracy: 0.8619 - val_loss: 0.2953 - val_auroc: 0.9478 - val_aupr: 0.9468 - val_binary_accuracy: 0.8736\n",
      "Epoch 5/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.3106 - auroc: 0.9412 - aupr: 0.9383 - binary_accuracy: 0.8677 - val_loss: 0.3462 - val_auroc: 0.9309 - val_aupr: 0.9337 - val_binary_accuracy: 0.8522\n",
      "Epoch 6/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2973 - auroc: 0.9465 - aupr: 0.9436 - binary_accuracy: 0.8762 - val_loss: 0.2755 - val_auroc: 0.9541 - val_aupr: 0.9545 - val_binary_accuracy: 0.8855\n",
      "Epoch 7/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2856 - auroc: 0.9504 - aupr: 0.9485 - binary_accuracy: 0.8802 - val_loss: 0.2672 - val_auroc: 0.9570 - val_aupr: 0.9543 - val_binary_accuracy: 0.8956\n",
      "Epoch 8/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2763 - auroc: 0.9536 - aupr: 0.9509 - binary_accuracy: 0.8825 - val_loss: 0.2734 - val_auroc: 0.9572 - val_aupr: 0.9572 - val_binary_accuracy: 0.8889\n",
      "Epoch 9/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2717 - auroc: 0.9551 - aupr: 0.9544 - binary_accuracy: 0.8860 - val_loss: 0.2641 - val_auroc: 0.9583 - val_aupr: 0.9585 - val_binary_accuracy: 0.8889\n",
      "Epoch 10/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2631 - auroc: 0.9581 - aupr: 0.9575 - binary_accuracy: 0.8926 - val_loss: 0.2704 - val_auroc: 0.9575 - val_aupr: 0.9582 - val_binary_accuracy: 0.8871\n",
      "Epoch 11/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2660 - auroc: 0.9572 - aupr: 0.9561 - binary_accuracy: 0.8904 - val_loss: 0.2643 - val_auroc: 0.9579 - val_aupr: 0.9577 - val_binary_accuracy: 0.8913\n",
      "Epoch 12/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2568 - auroc: 0.9602 - aupr: 0.9596 - binary_accuracy: 0.8944 - val_loss: 0.3225 - val_auroc: 0.9539 - val_aupr: 0.9541 - val_binary_accuracy: 0.8684\n",
      "Epoch 13/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2537 - auroc: 0.9613 - aupr: 0.9602 - binary_accuracy: 0.8983 - val_loss: 0.2936 - val_auroc: 0.9561 - val_aupr: 0.9553 - val_binary_accuracy: 0.8770\n",
      "Epoch 14/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2482 - auroc: 0.9627 - aupr: 0.9616 - binary_accuracy: 0.8952 - val_loss: 0.2984 - val_auroc: 0.9477 - val_aupr: 0.9486 - val_binary_accuracy: 0.8739\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.3053 - auroc: 0.9454 - aupr: 0.9431 - binary_accuracy: 0.8716\n",
      "Epoch 1/100\n",
      "229/229 [==============================] - 3s 9ms/step - loss: 0.6413 - auroc: 0.7098 - aupr: 0.6958 - binary_accuracy: 0.6422 - val_loss: 0.4757 - val_auroc: 0.8633 - val_aupr: 0.8453 - val_binary_accuracy: 0.7818\n",
      "Epoch 2/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.4623 - auroc: 0.8631 - aupr: 0.8461 - binary_accuracy: 0.7782 - val_loss: 0.3821 - val_auroc: 0.9126 - val_aupr: 0.9016 - val_binary_accuracy: 0.8326\n",
      "Epoch 3/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.3976 - auroc: 0.9014 - aupr: 0.8916 - binary_accuracy: 0.8194 - val_loss: 0.3908 - val_auroc: 0.9320 - val_aupr: 0.9293 - val_binary_accuracy: 0.8182\n",
      "Epoch 4/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.3663 - auroc: 0.9170 - aupr: 0.9109 - binary_accuracy: 0.8402 - val_loss: 0.3101 - val_auroc: 0.9411 - val_aupr: 0.9401 - val_binary_accuracy: 0.8632\n",
      "Epoch 5/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.3459 - auroc: 0.9262 - aupr: 0.9208 - binary_accuracy: 0.8484 - val_loss: 0.3062 - val_auroc: 0.9457 - val_aupr: 0.9431 - val_binary_accuracy: 0.8757\n",
      "Epoch 6/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.3300 - auroc: 0.9333 - aupr: 0.9292 - binary_accuracy: 0.8575 - val_loss: 0.2933 - val_auroc: 0.9473 - val_aupr: 0.9463 - val_binary_accuracy: 0.8742\n",
      "Epoch 7/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.3140 - auroc: 0.9396 - aupr: 0.9362 - binary_accuracy: 0.8675 - val_loss: 0.2853 - val_auroc: 0.9512 - val_aupr: 0.9494 - val_binary_accuracy: 0.8788\n",
      "Epoch 8/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.3005 - auroc: 0.9449 - aupr: 0.9432 - binary_accuracy: 0.8721 - val_loss: 0.3093 - val_auroc: 0.9461 - val_aupr: 0.9433 - val_binary_accuracy: 0.8696\n",
      "Epoch 9/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2858 - auroc: 0.9500 - aupr: 0.9493 - binary_accuracy: 0.8777 - val_loss: 0.2857 - val_auroc: 0.9527 - val_aupr: 0.9527 - val_binary_accuracy: 0.8773\n",
      "Epoch 10/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2729 - auroc: 0.9547 - aupr: 0.9531 - binary_accuracy: 0.8848 - val_loss: 0.2789 - val_auroc: 0.9530 - val_aupr: 0.9532 - val_binary_accuracy: 0.8834\n",
      "Epoch 11/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2603 - auroc: 0.9588 - aupr: 0.9593 - binary_accuracy: 0.8888 - val_loss: 0.2735 - val_auroc: 0.9556 - val_aupr: 0.9550 - val_binary_accuracy: 0.8901\n",
      "Epoch 12/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2593 - auroc: 0.9591 - aupr: 0.9586 - binary_accuracy: 0.8911 - val_loss: 0.2671 - val_auroc: 0.9565 - val_aupr: 0.9563 - val_binary_accuracy: 0.8877\n",
      "Epoch 13/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2452 - auroc: 0.9634 - aupr: 0.9632 - binary_accuracy: 0.8980 - val_loss: 0.2802 - val_auroc: 0.9525 - val_aupr: 0.9520 - val_binary_accuracy: 0.8831\n",
      "Epoch 14/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2342 - auroc: 0.9667 - aupr: 0.9665 - binary_accuracy: 0.9023 - val_loss: 0.2773 - val_auroc: 0.9561 - val_aupr: 0.9566 - val_binary_accuracy: 0.8883\n",
      "Epoch 15/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2229 - auroc: 0.9699 - aupr: 0.9696 - binary_accuracy: 0.9092 - val_loss: 0.2789 - val_auroc: 0.9540 - val_aupr: 0.9543 - val_binary_accuracy: 0.8837\n",
      "Epoch 16/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2134 - auroc: 0.9722 - aupr: 0.9723 - binary_accuracy: 0.9117 - val_loss: 0.2958 - val_auroc: 0.9525 - val_aupr: 0.9534 - val_binary_accuracy: 0.8776\n",
      "Epoch 17/100\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2022 - auroc: 0.9750 - aupr: 0.9748 - binary_accuracy: 0.9168 - val_loss: 0.3059 - val_auroc: 0.9563 - val_aupr: 0.9573 - val_binary_accuracy: 0.8785\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.3146 - auroc: 0.9527 - aupr: 0.9533 - binary_accuracy: 0.8771\n",
      "Processing: SRSF1_K562_200.h5\n",
      "(4195, 200, 9) (4195, 1)\n",
      "Input shape adjusted:\n",
      "(4195, 200, 4)\n",
      "(1199, 200, 4)\n",
      "(600, 200, 4)\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 9ms/step - loss: 0.5644 - auroc: 0.7742 - aupr: 0.7481 - binary_accuracy: 0.7004 - val_loss: 0.4356 - val_auroc: 0.8790 - val_aupr: 0.8693 - val_binary_accuracy: 0.7667\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3948 - auroc: 0.8999 - aupr: 0.8801 - binary_accuracy: 0.8231 - val_loss: 0.3690 - val_auroc: 0.9262 - val_aupr: 0.9219 - val_binary_accuracy: 0.8350\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3281 - auroc: 0.9325 - aupr: 0.9193 - binary_accuracy: 0.8636 - val_loss: 0.3207 - val_auroc: 0.9425 - val_aupr: 0.9417 - val_binary_accuracy: 0.8600\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2831 - auroc: 0.9501 - aupr: 0.9413 - binary_accuracy: 0.8865 - val_loss: 0.2979 - val_auroc: 0.9483 - val_aupr: 0.9494 - val_binary_accuracy: 0.8667\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2555 - auroc: 0.9597 - aupr: 0.9547 - binary_accuracy: 0.8956 - val_loss: 0.2940 - val_auroc: 0.9499 - val_aupr: 0.9526 - val_binary_accuracy: 0.8633\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2257 - auroc: 0.9688 - aupr: 0.9663 - binary_accuracy: 0.9113 - val_loss: 0.3323 - val_auroc: 0.9471 - val_aupr: 0.9499 - val_binary_accuracy: 0.8533\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2013 - auroc: 0.9747 - aupr: 0.9714 - binary_accuracy: 0.9263 - val_loss: 0.3067 - val_auroc: 0.9477 - val_aupr: 0.9489 - val_binary_accuracy: 0.8717\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1759 - auroc: 0.9811 - aupr: 0.9791 - binary_accuracy: 0.9306 - val_loss: 0.3260 - val_auroc: 0.9447 - val_aupr: 0.9461 - val_binary_accuracy: 0.8700\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1539 - auroc: 0.9857 - aupr: 0.9841 - binary_accuracy: 0.9442 - val_loss: 0.3560 - val_auroc: 0.9415 - val_aupr: 0.9463 - val_binary_accuracy: 0.8650\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1337 - auroc: 0.9886 - aupr: 0.9870 - binary_accuracy: 0.9528 - val_loss: 0.3801 - val_auroc: 0.9395 - val_aupr: 0.9442 - val_binary_accuracy: 0.8633\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3601 - auroc: 0.9419 - aupr: 0.9429 - binary_accuracy: 0.8674\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 9ms/step - loss: 0.6812 - auroc: 0.6571 - aupr: 0.6147 - binary_accuracy: 0.6124 - val_loss: 0.4956 - val_auroc: 0.8424 - val_aupr: 0.8363 - val_binary_accuracy: 0.7333\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4505 - auroc: 0.8647 - aupr: 0.8398 - binary_accuracy: 0.7843 - val_loss: 0.3905 - val_auroc: 0.9231 - val_aupr: 0.9186 - val_binary_accuracy: 0.7917\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3550 - auroc: 0.9189 - aupr: 0.9073 - binary_accuracy: 0.8412 - val_loss: 0.3256 - val_auroc: 0.9369 - val_aupr: 0.9379 - val_binary_accuracy: 0.8500\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3131 - auroc: 0.9380 - aupr: 0.9306 - binary_accuracy: 0.8665 - val_loss: 0.2937 - val_auroc: 0.9513 - val_aupr: 0.9542 - val_binary_accuracy: 0.8833\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2925 - auroc: 0.9453 - aupr: 0.9375 - binary_accuracy: 0.8758 - val_loss: 0.3256 - val_auroc: 0.9506 - val_aupr: 0.9530 - val_binary_accuracy: 0.8700\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2659 - auroc: 0.9551 - aupr: 0.9501 - binary_accuracy: 0.8930 - val_loss: 0.2929 - val_auroc: 0.9527 - val_aupr: 0.9557 - val_binary_accuracy: 0.8733\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2407 - auroc: 0.9631 - aupr: 0.9595 - binary_accuracy: 0.8963 - val_loss: 0.3400 - val_auroc: 0.9476 - val_aupr: 0.9489 - val_binary_accuracy: 0.8617\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2566 - auroc: 0.9589 - aupr: 0.9558 - binary_accuracy: 0.8944 - val_loss: 0.3120 - val_auroc: 0.9504 - val_aupr: 0.9506 - val_binary_accuracy: 0.8733\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2032 - auroc: 0.9740 - aupr: 0.9711 - binary_accuracy: 0.9182 - val_loss: 0.2931 - val_auroc: 0.9508 - val_aupr: 0.9497 - val_binary_accuracy: 0.8817\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1862 - auroc: 0.9789 - aupr: 0.9776 - binary_accuracy: 0.9280 - val_loss: 0.3595 - val_auroc: 0.9517 - val_aupr: 0.9454 - val_binary_accuracy: 0.8717\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1766 - auroc: 0.9805 - aupr: 0.9777 - binary_accuracy: 0.9294 - val_loss: 0.3571 - val_auroc: 0.9498 - val_aupr: 0.9446 - val_binary_accuracy: 0.8583\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4120 - auroc: 0.9332 - aupr: 0.9236 - binary_accuracy: 0.8415\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.5726 - auroc: 0.7672 - aupr: 0.7477 - binary_accuracy: 0.6913 - val_loss: 0.4957 - val_auroc: 0.8719 - val_aupr: 0.8653 - val_binary_accuracy: 0.7767\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.4492 - auroc: 0.8696 - aupr: 0.8565 - binary_accuracy: 0.7902 - val_loss: 0.4040 - val_auroc: 0.9221 - val_aupr: 0.9210 - val_binary_accuracy: 0.8283\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.3548 - auroc: 0.9210 - aupr: 0.9131 - binary_accuracy: 0.8422 - val_loss: 0.3082 - val_auroc: 0.9427 - val_aupr: 0.9404 - val_binary_accuracy: 0.8550\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.3164 - auroc: 0.9376 - aupr: 0.9294 - binary_accuracy: 0.8679 - val_loss: 0.3054 - val_auroc: 0.9432 - val_aupr: 0.9391 - val_binary_accuracy: 0.8633\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.2581 - auroc: 0.9588 - aupr: 0.9543 - binary_accuracy: 0.8961 - val_loss: 0.3184 - val_auroc: 0.9430 - val_aupr: 0.9452 - val_binary_accuracy: 0.8733\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.2059 - auroc: 0.9737 - aupr: 0.9701 - binary_accuracy: 0.9223 - val_loss: 0.3372 - val_auroc: 0.9422 - val_aupr: 0.9344 - val_binary_accuracy: 0.8633\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.1844 - auroc: 0.9789 - aupr: 0.9779 - binary_accuracy: 0.9244 - val_loss: 0.3489 - val_auroc: 0.9353 - val_aupr: 0.9296 - val_binary_accuracy: 0.8450\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.1820 - auroc: 0.9795 - aupr: 0.9792 - binary_accuracy: 0.9254 - val_loss: 0.3451 - val_auroc: 0.9443 - val_aupr: 0.9380 - val_binary_accuracy: 0.8717\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.1187 - auroc: 0.9910 - aupr: 0.9909 - binary_accuracy: 0.9557 - val_loss: 0.3712 - val_auroc: 0.9401 - val_aupr: 0.9375 - val_binary_accuracy: 0.8583\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4058 - auroc: 0.9345 - aupr: 0.9353 - binary_accuracy: 0.8532\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.8768 - auroc: 0.5174 - aupr: 0.5049 - binary_accuracy: 0.5156 - val_loss: 0.6893 - val_auroc: 0.6859 - val_aupr: 0.6930 - val_binary_accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.6675 - auroc: 0.6278 - aupr: 0.6308 - binary_accuracy: 0.5888 - val_loss: 0.5826 - val_auroc: 0.7537 - val_aupr: 0.7719 - val_binary_accuracy: 0.6533\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.5442 - auroc: 0.7989 - aupr: 0.7757 - binary_accuracy: 0.7263 - val_loss: 0.5311 - val_auroc: 0.8275 - val_aupr: 0.8236 - val_binary_accuracy: 0.7300\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.4962 - auroc: 0.8383 - aupr: 0.8147 - binary_accuracy: 0.7588 - val_loss: 0.4778 - val_auroc: 0.8629 - val_aupr: 0.8600 - val_binary_accuracy: 0.7533\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.4468 - auroc: 0.8701 - aupr: 0.8499 - binary_accuracy: 0.7931 - val_loss: 0.3884 - val_auroc: 0.9070 - val_aupr: 0.9034 - val_binary_accuracy: 0.8067\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.4023 - auroc: 0.8963 - aupr: 0.8844 - binary_accuracy: 0.8119 - val_loss: 0.3466 - val_auroc: 0.9301 - val_aupr: 0.9279 - val_binary_accuracy: 0.8350\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.3751 - auroc: 0.9094 - aupr: 0.8985 - binary_accuracy: 0.8284 - val_loss: 0.3294 - val_auroc: 0.9346 - val_aupr: 0.9355 - val_binary_accuracy: 0.8583\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.3542 - auroc: 0.9220 - aupr: 0.9127 - binary_accuracy: 0.8422 - val_loss: 0.3524 - val_auroc: 0.9410 - val_aupr: 0.9409 - val_binary_accuracy: 0.8250\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.3685 - auroc: 0.9153 - aupr: 0.9054 - binary_accuracy: 0.8372 - val_loss: 0.3335 - val_auroc: 0.9409 - val_aupr: 0.9411 - val_binary_accuracy: 0.8567\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.3442 - auroc: 0.9258 - aupr: 0.9159 - binary_accuracy: 0.8505 - val_loss: 0.3479 - val_auroc: 0.9398 - val_aupr: 0.9391 - val_binary_accuracy: 0.8517\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.3375 - auroc: 0.9294 - aupr: 0.9212 - binary_accuracy: 0.8508 - val_loss: 0.3573 - val_auroc: 0.9449 - val_aupr: 0.9427 - val_binary_accuracy: 0.8433\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.3147 - auroc: 0.9390 - aupr: 0.9339 - binary_accuracy: 0.8620 - val_loss: 0.3242 - val_auroc: 0.9468 - val_aupr: 0.9444 - val_binary_accuracy: 0.8417\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.3157 - auroc: 0.9375 - aupr: 0.9322 - binary_accuracy: 0.8636 - val_loss: 0.3078 - val_auroc: 0.9496 - val_aupr: 0.9484 - val_binary_accuracy: 0.8600\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.3005 - auroc: 0.9445 - aupr: 0.9401 - binary_accuracy: 0.8691 - val_loss: 0.3038 - val_auroc: 0.9462 - val_aupr: 0.9444 - val_binary_accuracy: 0.8817\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.2993 - auroc: 0.9441 - aupr: 0.9400 - binary_accuracy: 0.8672 - val_loss: 0.2953 - val_auroc: 0.9466 - val_aupr: 0.9446 - val_binary_accuracy: 0.8733\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.2965 - auroc: 0.9447 - aupr: 0.9390 - binary_accuracy: 0.8644 - val_loss: 0.3134 - val_auroc: 0.9446 - val_aupr: 0.9431 - val_binary_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.2766 - auroc: 0.9533 - aupr: 0.9474 - binary_accuracy: 0.8849 - val_loss: 0.3120 - val_auroc: 0.9435 - val_aupr: 0.9418 - val_binary_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.2390 - auroc: 0.9644 - aupr: 0.9593 - binary_accuracy: 0.9066 - val_loss: 0.3241 - val_auroc: 0.9431 - val_aupr: 0.9401 - val_binary_accuracy: 0.8700\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.2215 - auroc: 0.9695 - aupr: 0.9687 - binary_accuracy: 0.9063 - val_loss: 0.3189 - val_auroc: 0.9414 - val_aupr: 0.9377 - val_binary_accuracy: 0.8683\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.2140 - auroc: 0.9718 - aupr: 0.9690 - binary_accuracy: 0.9144 - val_loss: 0.4043 - val_auroc: 0.9351 - val_aupr: 0.9322 - val_binary_accuracy: 0.8467\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3905 - auroc: 0.9372 - aupr: 0.9377 - binary_accuracy: 0.8407\n",
      "Processing: TARDBP_K562_200.h5\n",
      "(8477, 200, 9) (8477, 1)\n",
      "Input shape adjusted:\n",
      "(8477, 200, 4)\n",
      "(2422, 200, 4)\n",
      "(1211, 200, 4)\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 0.2586 - auroc: 0.9607 - aupr: 0.9648 - binary_accuracy: 0.8935 - val_loss: 0.1266 - val_auroc: 0.9875 - val_aupr: 0.9878 - val_binary_accuracy: 0.9604\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.1218 - auroc: 0.9888 - aupr: 0.9897 - binary_accuracy: 0.9593 - val_loss: 0.0982 - val_auroc: 0.9923 - val_aupr: 0.9911 - val_binary_accuracy: 0.9694\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.0898 - auroc: 0.9934 - aupr: 0.9939 - binary_accuracy: 0.9716 - val_loss: 0.0956 - val_auroc: 0.9925 - val_aupr: 0.9915 - val_binary_accuracy: 0.9744\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.0742 - auroc: 0.9953 - aupr: 0.9956 - binary_accuracy: 0.9772 - val_loss: 0.1255 - val_auroc: 0.9891 - val_aupr: 0.9908 - val_binary_accuracy: 0.9628\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.0629 - auroc: 0.9965 - aupr: 0.9964 - binary_accuracy: 0.9816 - val_loss: 0.1075 - val_auroc: 0.9909 - val_aupr: 0.9905 - val_binary_accuracy: 0.9727\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.0541 - auroc: 0.9972 - aupr: 0.9970 - binary_accuracy: 0.9838 - val_loss: 0.1002 - val_auroc: 0.9917 - val_aupr: 0.9912 - val_binary_accuracy: 0.9703\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.0489 - auroc: 0.9975 - aupr: 0.9973 - binary_accuracy: 0.9862 - val_loss: 0.1316 - val_auroc: 0.9878 - val_aupr: 0.9882 - val_binary_accuracy: 0.9661\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.0575 - auroc: 0.9971 - aupr: 0.9970 - binary_accuracy: 0.9817 - val_loss: 0.1062 - val_auroc: 0.9908 - val_aupr: 0.9895 - val_binary_accuracy: 0.9711\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0957 - auroc: 0.9928 - aupr: 0.9918 - binary_accuracy: 0.9694\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 0.2737 - auroc: 0.9541 - aupr: 0.9580 - binary_accuracy: 0.8811 - val_loss: 0.1430 - val_auroc: 0.9884 - val_aupr: 0.9892 - val_binary_accuracy: 0.9513\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.1235 - auroc: 0.9895 - aupr: 0.9900 - binary_accuracy: 0.9556 - val_loss: 0.1011 - val_auroc: 0.9909 - val_aupr: 0.9917 - val_binary_accuracy: 0.9694\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.1060 - auroc: 0.9921 - aupr: 0.9927 - binary_accuracy: 0.9644 - val_loss: 0.1167 - val_auroc: 0.9902 - val_aupr: 0.9917 - val_binary_accuracy: 0.9645\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.0925 - auroc: 0.9932 - aupr: 0.9931 - binary_accuracy: 0.9698 - val_loss: 0.0988 - val_auroc: 0.9919 - val_aupr: 0.9926 - val_binary_accuracy: 0.9719\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.0859 - auroc: 0.9942 - aupr: 0.9945 - binary_accuracy: 0.9718 - val_loss: 0.0966 - val_auroc: 0.9922 - val_aupr: 0.9930 - val_binary_accuracy: 0.9736\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.0685 - auroc: 0.9963 - aupr: 0.9959 - binary_accuracy: 0.9776 - val_loss: 0.1095 - val_auroc: 0.9926 - val_aupr: 0.9932 - val_binary_accuracy: 0.9661\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.0677 - auroc: 0.9962 - aupr: 0.9960 - binary_accuracy: 0.9770 - val_loss: 0.0918 - val_auroc: 0.9931 - val_aupr: 0.9935 - val_binary_accuracy: 0.9703\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.0551 - auroc: 0.9977 - aupr: 0.9975 - binary_accuracy: 0.9830 - val_loss: 0.0946 - val_auroc: 0.9928 - val_aupr: 0.9924 - val_binary_accuracy: 0.9703\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.0574 - auroc: 0.9970 - aupr: 0.9967 - binary_accuracy: 0.9809 - val_loss: 0.0927 - val_auroc: 0.9922 - val_aupr: 0.9918 - val_binary_accuracy: 0.9736\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.0595 - auroc: 0.9974 - aupr: 0.9972 - binary_accuracy: 0.9781 - val_loss: 0.1247 - val_auroc: 0.9926 - val_aupr: 0.9909 - val_binary_accuracy: 0.9546\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.0412 - auroc: 0.9985 - aupr: 0.9983 - binary_accuracy: 0.9858 - val_loss: 0.1064 - val_auroc: 0.9919 - val_aupr: 0.9907 - val_binary_accuracy: 0.9719\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.0308 - auroc: 0.9990 - aupr: 0.9987 - binary_accuracy: 0.9893 - val_loss: 0.1241 - val_auroc: 0.9903 - val_aupr: 0.9899 - val_binary_accuracy: 0.9694\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.1353 - auroc: 0.9902 - aupr: 0.9880 - binary_accuracy: 0.9649\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 2s 11ms/step - loss: 0.2763 - auroc: 0.9528 - aupr: 0.9579 - binary_accuracy: 0.8767 - val_loss: 0.1345 - val_auroc: 0.9904 - val_aupr: 0.9902 - val_binary_accuracy: 0.9538\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.1279 - auroc: 0.9882 - aupr: 0.9883 - binary_accuracy: 0.9571 - val_loss: 0.1045 - val_auroc: 0.9917 - val_aupr: 0.9920 - val_binary_accuracy: 0.9612\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.1064 - auroc: 0.9921 - aupr: 0.9922 - binary_accuracy: 0.9645 - val_loss: 0.1045 - val_auroc: 0.9922 - val_aupr: 0.9926 - val_binary_accuracy: 0.9612\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.1030 - auroc: 0.9921 - aupr: 0.9920 - binary_accuracy: 0.9661 - val_loss: 0.1049 - val_auroc: 0.9932 - val_aupr: 0.9931 - val_binary_accuracy: 0.9628\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.0746 - auroc: 0.9953 - aupr: 0.9948 - binary_accuracy: 0.9768 - val_loss: 0.0938 - val_auroc: 0.9929 - val_aupr: 0.9931 - val_binary_accuracy: 0.9703\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.0627 - auroc: 0.9964 - aupr: 0.9960 - binary_accuracy: 0.9816 - val_loss: 0.1527 - val_auroc: 0.9877 - val_aupr: 0.9901 - val_binary_accuracy: 0.9587\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.0665 - auroc: 0.9965 - aupr: 0.9963 - binary_accuracy: 0.9775 - val_loss: 0.1132 - val_auroc: 0.9939 - val_aupr: 0.9938 - val_binary_accuracy: 0.9604\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.0608 - auroc: 0.9971 - aupr: 0.9968 - binary_accuracy: 0.9798 - val_loss: 0.0920 - val_auroc: 0.9935 - val_aupr: 0.9940 - val_binary_accuracy: 0.9711\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.0356 - auroc: 0.9985 - aupr: 0.9983 - binary_accuracy: 0.9887 - val_loss: 0.1277 - val_auroc: 0.9903 - val_aupr: 0.9909 - val_binary_accuracy: 0.9645\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.0344 - auroc: 0.9987 - aupr: 0.9985 - binary_accuracy: 0.9895 - val_loss: 0.2164 - val_auroc: 0.9835 - val_aupr: 0.9882 - val_binary_accuracy: 0.9587\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.0540 - auroc: 0.9975 - aupr: 0.9972 - binary_accuracy: 0.9807 - val_loss: 0.1150 - val_auroc: 0.9927 - val_aupr: 0.9931 - val_binary_accuracy: 0.9628\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.0334 - auroc: 0.9989 - aupr: 0.9986 - binary_accuracy: 0.9888 - val_loss: 0.1110 - val_auroc: 0.9902 - val_aupr: 0.9905 - val_binary_accuracy: 0.9694\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.0359 - auroc: 0.9987 - aupr: 0.9984 - binary_accuracy: 0.9861 - val_loss: 0.1187 - val_auroc: 0.9917 - val_aupr: 0.9917 - val_binary_accuracy: 0.9637\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.1239 - auroc: 0.9907 - aupr: 0.9888 - binary_accuracy: 0.9604\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 2s 11ms/step - loss: 0.7681 - auroc: 0.5040 - aupr: 0.5019 - binary_accuracy: 0.5071 - val_loss: 0.6811 - val_auroc: 0.9082 - val_aupr: 0.9213 - val_binary_accuracy: 0.5054\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.3102 - auroc: 0.9438 - aupr: 0.9505 - binary_accuracy: 0.8658 - val_loss: 0.1955 - val_auroc: 0.9801 - val_aupr: 0.9811 - val_binary_accuracy: 0.9240\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.1899 - auroc: 0.9774 - aupr: 0.9794 - binary_accuracy: 0.9311 - val_loss: 0.1509 - val_auroc: 0.9851 - val_aupr: 0.9848 - val_binary_accuracy: 0.9397\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.1860 - auroc: 0.9784 - aupr: 0.9809 - binary_accuracy: 0.9349 - val_loss: 0.1790 - val_auroc: 0.9882 - val_aupr: 0.9884 - val_binary_accuracy: 0.9356\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.1368 - auroc: 0.9871 - aupr: 0.9882 - binary_accuracy: 0.9526 - val_loss: 0.1256 - val_auroc: 0.9913 - val_aupr: 0.9913 - val_binary_accuracy: 0.9538\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.1281 - auroc: 0.9884 - aupr: 0.9894 - binary_accuracy: 0.9572 - val_loss: 0.1324 - val_auroc: 0.9910 - val_aupr: 0.9912 - val_binary_accuracy: 0.9488\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.1143 - auroc: 0.9909 - aupr: 0.9912 - binary_accuracy: 0.9635 - val_loss: 0.1040 - val_auroc: 0.9917 - val_aupr: 0.9922 - val_binary_accuracy: 0.9645\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.1040 - auroc: 0.9919 - aupr: 0.9927 - binary_accuracy: 0.9676 - val_loss: 0.1005 - val_auroc: 0.9922 - val_aupr: 0.9926 - val_binary_accuracy: 0.9653\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.1071 - auroc: 0.9918 - aupr: 0.9920 - binary_accuracy: 0.9643 - val_loss: 0.1021 - val_auroc: 0.9929 - val_aupr: 0.9941 - val_binary_accuracy: 0.9612\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.1011 - auroc: 0.9924 - aupr: 0.9927 - binary_accuracy: 0.9658 - val_loss: 0.1034 - val_auroc: 0.9921 - val_aupr: 0.9924 - val_binary_accuracy: 0.9620\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.0853 - auroc: 0.9940 - aupr: 0.9945 - binary_accuracy: 0.9730 - val_loss: 0.0996 - val_auroc: 0.9921 - val_aupr: 0.9915 - val_binary_accuracy: 0.9719\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.0881 - auroc: 0.9940 - aupr: 0.9939 - binary_accuracy: 0.9723 - val_loss: 0.1186 - val_auroc: 0.9913 - val_aupr: 0.9921 - val_binary_accuracy: 0.9620\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.0810 - auroc: 0.9945 - aupr: 0.9941 - binary_accuracy: 0.9736 - val_loss: 0.0952 - val_auroc: 0.9935 - val_aupr: 0.9947 - val_binary_accuracy: 0.9678\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.0689 - auroc: 0.9961 - aupr: 0.9962 - binary_accuracy: 0.9766 - val_loss: 0.1078 - val_auroc: 0.9912 - val_aupr: 0.9912 - val_binary_accuracy: 0.9694\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.0654 - auroc: 0.9963 - aupr: 0.9962 - binary_accuracy: 0.9786 - val_loss: 0.1137 - val_auroc: 0.9909 - val_aupr: 0.9922 - val_binary_accuracy: 0.9661\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.0632 - auroc: 0.9967 - aupr: 0.9966 - binary_accuracy: 0.9775 - val_loss: 0.1380 - val_auroc: 0.9901 - val_aupr: 0.9870 - val_binary_accuracy: 0.9571\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.0574 - auroc: 0.9971 - aupr: 0.9967 - binary_accuracy: 0.9811 - val_loss: 0.1191 - val_auroc: 0.9903 - val_aupr: 0.9905 - val_binary_accuracy: 0.9678\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.0583 - auroc: 0.9968 - aupr: 0.9970 - binary_accuracy: 0.9817 - val_loss: 0.1175 - val_auroc: 0.9907 - val_aupr: 0.9910 - val_binary_accuracy: 0.9645\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.1104 - auroc: 0.9917 - aupr: 0.9923 - binary_accuracy: 0.9637\n",
      "Processing: TIA1_K562_200.h5\n",
      "(12663, 200, 9) (12663, 1)\n",
      "Input shape adjusted:\n",
      "(12663, 200, 4)\n",
      "(3619, 200, 4)\n",
      "(1808, 200, 4)\n",
      "Epoch 1/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.5062 - auroc: 0.8333 - aupr: 0.8210 - binary_accuracy: 0.7558 - val_loss: 0.4357 - val_auroc: 0.8954 - val_aupr: 0.8802 - val_binary_accuracy: 0.8003\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4001 - auroc: 0.9003 - aupr: 0.8892 - binary_accuracy: 0.8259 - val_loss: 0.4024 - val_auroc: 0.9056 - val_aupr: 0.8958 - val_binary_accuracy: 0.8241\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3765 - auroc: 0.9119 - aupr: 0.9020 - binary_accuracy: 0.8387 - val_loss: 0.3784 - val_auroc: 0.9111 - val_aupr: 0.9042 - val_binary_accuracy: 0.8363\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3571 - auroc: 0.9212 - aupr: 0.9135 - binary_accuracy: 0.8483 - val_loss: 0.3957 - val_auroc: 0.9108 - val_aupr: 0.9038 - val_binary_accuracy: 0.8302\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3401 - auroc: 0.9286 - aupr: 0.9222 - binary_accuracy: 0.8568 - val_loss: 0.3856 - val_auroc: 0.9107 - val_aupr: 0.9074 - val_binary_accuracy: 0.8418\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3344 - auroc: 0.9313 - aupr: 0.9265 - binary_accuracy: 0.8579 - val_loss: 0.3984 - val_auroc: 0.9082 - val_aupr: 0.9047 - val_binary_accuracy: 0.8285\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3186 - auroc: 0.9377 - aupr: 0.9339 - binary_accuracy: 0.8665 - val_loss: 0.3934 - val_auroc: 0.9092 - val_aupr: 0.9064 - val_binary_accuracy: 0.8346\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3127 - auroc: 0.9402 - aupr: 0.9360 - binary_accuracy: 0.8696 - val_loss: 0.3889 - val_auroc: 0.9112 - val_aupr: 0.9089 - val_binary_accuracy: 0.8374\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.3843 - auroc: 0.9117 - aupr: 0.9043 - binary_accuracy: 0.8331\n",
      "Epoch 1/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.5605 - auroc: 0.7878 - aupr: 0.7844 - binary_accuracy: 0.7163 - val_loss: 0.4514 - val_auroc: 0.8722 - val_aupr: 0.8648 - val_binary_accuracy: 0.8025\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4455 - auroc: 0.8757 - aupr: 0.8661 - binary_accuracy: 0.8001 - val_loss: 0.4128 - val_auroc: 0.8945 - val_aupr: 0.8857 - val_binary_accuracy: 0.8180\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4072 - auroc: 0.8970 - aupr: 0.8858 - binary_accuracy: 0.8226 - val_loss: 0.4018 - val_auroc: 0.9028 - val_aupr: 0.8949 - val_binary_accuracy: 0.8191\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3835 - auroc: 0.9091 - aupr: 0.9020 - binary_accuracy: 0.8338 - val_loss: 0.3915 - val_auroc: 0.9044 - val_aupr: 0.8981 - val_binary_accuracy: 0.8291\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3678 - auroc: 0.9167 - aupr: 0.9110 - binary_accuracy: 0.8420 - val_loss: 0.3894 - val_auroc: 0.9064 - val_aupr: 0.9008 - val_binary_accuracy: 0.8230\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3529 - auroc: 0.9236 - aupr: 0.9187 - binary_accuracy: 0.8495 - val_loss: 0.3996 - val_auroc: 0.9030 - val_aupr: 0.8997 - val_binary_accuracy: 0.8197\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3465 - auroc: 0.9268 - aupr: 0.9217 - binary_accuracy: 0.8576 - val_loss: 0.3951 - val_auroc: 0.9049 - val_aupr: 0.8998 - val_binary_accuracy: 0.8230\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3352 - auroc: 0.9313 - aupr: 0.9269 - binary_accuracy: 0.8582 - val_loss: 0.4440 - val_auroc: 0.9024 - val_aupr: 0.8994 - val_binary_accuracy: 0.8180\n",
      "Epoch 9/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3164 - auroc: 0.9393 - aupr: 0.9336 - binary_accuracy: 0.8700 - val_loss: 0.4141 - val_auroc: 0.9020 - val_aupr: 0.8957 - val_binary_accuracy: 0.8164\n",
      "Epoch 10/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3204 - auroc: 0.9376 - aupr: 0.9334 - binary_accuracy: 0.8648 - val_loss: 0.4244 - val_auroc: 0.9029 - val_aupr: 0.8968 - val_binary_accuracy: 0.8241\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.4184 - auroc: 0.9044 - aupr: 0.8997 - binary_accuracy: 0.8262\n",
      "Epoch 1/100\n",
      "127/127 [==============================] - 2s 10ms/step - loss: 0.5123 - auroc: 0.8296 - aupr: 0.8135 - binary_accuracy: 0.7531 - val_loss: 0.5163 - val_auroc: 0.8791 - val_aupr: 0.8684 - val_binary_accuracy: 0.7478\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.4292 - auroc: 0.8841 - aupr: 0.8677 - binary_accuracy: 0.8093 - val_loss: 0.4219 - val_auroc: 0.8898 - val_aupr: 0.8856 - val_binary_accuracy: 0.8075\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.4092 - auroc: 0.8955 - aupr: 0.8825 - binary_accuracy: 0.8227 - val_loss: 0.4133 - val_auroc: 0.8929 - val_aupr: 0.8887 - val_binary_accuracy: 0.8092\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.3840 - auroc: 0.9087 - aupr: 0.8972 - binary_accuracy: 0.8344 - val_loss: 0.4176 - val_auroc: 0.8991 - val_aupr: 0.8937 - val_binary_accuracy: 0.8202\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.3693 - auroc: 0.9160 - aupr: 0.9060 - binary_accuracy: 0.8449 - val_loss: 0.4088 - val_auroc: 0.8991 - val_aupr: 0.8945 - val_binary_accuracy: 0.8197\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.3549 - auroc: 0.9225 - aupr: 0.9164 - binary_accuracy: 0.8474 - val_loss: 0.4045 - val_auroc: 0.8985 - val_aupr: 0.8972 - val_binary_accuracy: 0.8147\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.3355 - auroc: 0.9307 - aupr: 0.9253 - binary_accuracy: 0.8552 - val_loss: 0.4037 - val_auroc: 0.8981 - val_aupr: 0.8983 - val_binary_accuracy: 0.8197\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.3307 - auroc: 0.9332 - aupr: 0.9247 - binary_accuracy: 0.8595 - val_loss: 0.4065 - val_auroc: 0.8975 - val_aupr: 0.9002 - val_binary_accuracy: 0.8131\n",
      "Epoch 9/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.3136 - auroc: 0.9396 - aupr: 0.9350 - binary_accuracy: 0.8646 - val_loss: 0.4196 - val_auroc: 0.8902 - val_aupr: 0.8933 - val_binary_accuracy: 0.8153\n",
      "Epoch 10/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.3033 - auroc: 0.9435 - aupr: 0.9390 - binary_accuracy: 0.8698 - val_loss: 0.4470 - val_auroc: 0.9011 - val_aupr: 0.9037 - val_binary_accuracy: 0.8197\n",
      "Epoch 11/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.2990 - auroc: 0.9451 - aupr: 0.9404 - binary_accuracy: 0.8748 - val_loss: 0.4171 - val_auroc: 0.8946 - val_aupr: 0.8961 - val_binary_accuracy: 0.8119\n",
      "Epoch 12/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.2896 - auroc: 0.9484 - aupr: 0.9441 - binary_accuracy: 0.8752 - val_loss: 0.4252 - val_auroc: 0.8938 - val_aupr: 0.8961 - val_binary_accuracy: 0.8219\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.4147 - auroc: 0.8999 - aupr: 0.8884 - binary_accuracy: 0.8207\n",
      "Epoch 1/100\n",
      "127/127 [==============================] - 2s 10ms/step - loss: 0.7635 - auroc: 0.5506 - aupr: 0.5402 - binary_accuracy: 0.5360 - val_loss: 0.5528 - val_auroc: 0.8221 - val_aupr: 0.8132 - val_binary_accuracy: 0.7179\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.5191 - auroc: 0.8261 - aupr: 0.8047 - binary_accuracy: 0.7540 - val_loss: 0.4753 - val_auroc: 0.8562 - val_aupr: 0.8436 - val_binary_accuracy: 0.7821\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.4821 - auroc: 0.8507 - aupr: 0.8318 - binary_accuracy: 0.7745 - val_loss: 0.4485 - val_auroc: 0.8736 - val_aupr: 0.8585 - val_binary_accuracy: 0.7992\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.4481 - auroc: 0.8741 - aupr: 0.8547 - binary_accuracy: 0.7978 - val_loss: 0.4399 - val_auroc: 0.8857 - val_aupr: 0.8789 - val_binary_accuracy: 0.8014\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.4443 - auroc: 0.8750 - aupr: 0.8614 - binary_accuracy: 0.8015 - val_loss: 0.4466 - val_auroc: 0.8765 - val_aupr: 0.8696 - val_binary_accuracy: 0.7871\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.4336 - auroc: 0.8819 - aupr: 0.8676 - binary_accuracy: 0.8059 - val_loss: 0.4231 - val_auroc: 0.8884 - val_aupr: 0.8820 - val_binary_accuracy: 0.8108\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.4185 - auroc: 0.8908 - aupr: 0.8785 - binary_accuracy: 0.8124 - val_loss: 0.4329 - val_auroc: 0.8875 - val_aupr: 0.8864 - val_binary_accuracy: 0.8025\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.4131 - auroc: 0.8941 - aupr: 0.8835 - binary_accuracy: 0.8177 - val_loss: 0.4133 - val_auroc: 0.8943 - val_aupr: 0.8895 - val_binary_accuracy: 0.8180\n",
      "Epoch 9/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.4038 - auroc: 0.8980 - aupr: 0.8876 - binary_accuracy: 0.8204 - val_loss: 0.4221 - val_auroc: 0.8917 - val_aupr: 0.8816 - val_binary_accuracy: 0.8153\n",
      "Epoch 10/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.4043 - auroc: 0.8983 - aupr: 0.8876 - binary_accuracy: 0.8223 - val_loss: 0.4114 - val_auroc: 0.8963 - val_aupr: 0.8941 - val_binary_accuracy: 0.8225\n",
      "Epoch 11/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.3904 - auroc: 0.9051 - aupr: 0.8952 - binary_accuracy: 0.8297 - val_loss: 0.4090 - val_auroc: 0.8975 - val_aupr: 0.8873 - val_binary_accuracy: 0.8180\n",
      "Epoch 12/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.3842 - auroc: 0.9084 - aupr: 0.8996 - binary_accuracy: 0.8336 - val_loss: 0.4383 - val_auroc: 0.8969 - val_aupr: 0.8930 - val_binary_accuracy: 0.8086\n",
      "Epoch 13/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.3708 - auroc: 0.9148 - aupr: 0.9075 - binary_accuracy: 0.8372 - val_loss: 0.4005 - val_auroc: 0.9013 - val_aupr: 0.8991 - val_binary_accuracy: 0.8213\n",
      "Epoch 14/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.3652 - auroc: 0.9173 - aupr: 0.9113 - binary_accuracy: 0.8407 - val_loss: 0.4009 - val_auroc: 0.9009 - val_aupr: 0.8996 - val_binary_accuracy: 0.8241\n",
      "Epoch 15/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.3507 - auroc: 0.9242 - aupr: 0.9203 - binary_accuracy: 0.8474 - val_loss: 0.4217 - val_auroc: 0.8922 - val_aupr: 0.8843 - val_binary_accuracy: 0.8147\n",
      "Epoch 16/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.3402 - auroc: 0.9287 - aupr: 0.9221 - binary_accuracy: 0.8526 - val_loss: 0.4098 - val_auroc: 0.8981 - val_aupr: 0.8963 - val_binary_accuracy: 0.8213\n",
      "Epoch 17/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.3275 - auroc: 0.9342 - aupr: 0.9294 - binary_accuracy: 0.8594 - val_loss: 0.4238 - val_auroc: 0.8970 - val_aupr: 0.8955 - val_binary_accuracy: 0.8169\n",
      "Epoch 18/100\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.3133 - auroc: 0.9404 - aupr: 0.9363 - binary_accuracy: 0.8646 - val_loss: 0.4077 - val_auroc: 0.9022 - val_aupr: 0.8995 - val_binary_accuracy: 0.8197\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.3914 - auroc: 0.9069 - aupr: 0.9030 - binary_accuracy: 0.8270\n",
      "Processing: U2AF1_K562_200.h5\n",
      "(2349, 200, 9) (2349, 1)\n",
      "Input shape adjusted:\n",
      "(2349, 200, 4)\n",
      "(672, 200, 4)\n",
      "(336, 200, 4)\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 1s 13ms/step - loss: 0.6065 - auroc: 0.7419 - aupr: 0.7860 - binary_accuracy: 0.6662 - val_loss: 0.4294 - val_auroc: 0.9217 - val_aupr: 0.9389 - val_binary_accuracy: 0.8363\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3699 - auroc: 0.9151 - aupr: 0.9321 - binary_accuracy: 0.8467 - val_loss: 0.2876 - val_auroc: 0.9498 - val_aupr: 0.9603 - val_binary_accuracy: 0.9048\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2763 - auroc: 0.9533 - aupr: 0.9649 - binary_accuracy: 0.8872 - val_loss: 0.2580 - val_auroc: 0.9581 - val_aupr: 0.9654 - val_binary_accuracy: 0.9048\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2319 - auroc: 0.9673 - aupr: 0.9734 - binary_accuracy: 0.9085 - val_loss: 0.2397 - val_auroc: 0.9631 - val_aupr: 0.9695 - val_binary_accuracy: 0.9137\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1979 - auroc: 0.9752 - aupr: 0.9802 - binary_accuracy: 0.9293 - val_loss: 0.2400 - val_auroc: 0.9623 - val_aupr: 0.9695 - val_binary_accuracy: 0.9137\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1773 - auroc: 0.9811 - aupr: 0.9850 - binary_accuracy: 0.9319 - val_loss: 0.2327 - val_auroc: 0.9649 - val_aupr: 0.9706 - val_binary_accuracy: 0.9226\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1401 - auroc: 0.9877 - aupr: 0.9896 - binary_accuracy: 0.9506 - val_loss: 0.2505 - val_auroc: 0.9621 - val_aupr: 0.9656 - val_binary_accuracy: 0.9077\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1142 - auroc: 0.9911 - aupr: 0.9925 - binary_accuracy: 0.9642 - val_loss: 0.2392 - val_auroc: 0.9643 - val_aupr: 0.9713 - val_binary_accuracy: 0.9196\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1011 - auroc: 0.9940 - aupr: 0.9945 - binary_accuracy: 0.9664 - val_loss: 0.2677 - val_auroc: 0.9628 - val_aupr: 0.9699 - val_binary_accuracy: 0.9077\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1002 - auroc: 0.9937 - aupr: 0.9951 - binary_accuracy: 0.9689 - val_loss: 0.3400 - val_auroc: 0.9565 - val_aupr: 0.9584 - val_binary_accuracy: 0.8720\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0672 - auroc: 0.9973 - aupr: 0.9973 - binary_accuracy: 0.9825 - val_loss: 0.3072 - val_auroc: 0.9586 - val_aupr: 0.9637 - val_binary_accuracy: 0.8958\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4742 - auroc: 0.9222 - aupr: 0.9181 - binary_accuracy: 0.8482\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 1s 15ms/step - loss: 0.7243 - auroc: 0.6222 - aupr: 0.6310 - binary_accuracy: 0.6024 - val_loss: 0.5567 - val_auroc: 0.8926 - val_aupr: 0.9156 - val_binary_accuracy: 0.8333\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4928 - auroc: 0.8667 - aupr: 0.8904 - binary_accuracy: 0.7948 - val_loss: 0.3856 - val_auroc: 0.9174 - val_aupr: 0.9370 - val_binary_accuracy: 0.8780\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3795 - auroc: 0.9112 - aupr: 0.9311 - binary_accuracy: 0.8391 - val_loss: 0.3124 - val_auroc: 0.9348 - val_aupr: 0.9478 - val_binary_accuracy: 0.8839\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3034 - auroc: 0.9415 - aupr: 0.9559 - binary_accuracy: 0.8740 - val_loss: 0.2851 - val_auroc: 0.9539 - val_aupr: 0.9606 - val_binary_accuracy: 0.8899\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2626 - auroc: 0.9577 - aupr: 0.9652 - binary_accuracy: 0.8931 - val_loss: 0.2668 - val_auroc: 0.9567 - val_aupr: 0.9637 - val_binary_accuracy: 0.8958\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2338 - auroc: 0.9666 - aupr: 0.9727 - binary_accuracy: 0.9038 - val_loss: 0.2566 - val_auroc: 0.9600 - val_aupr: 0.9615 - val_binary_accuracy: 0.8958\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1958 - auroc: 0.9757 - aupr: 0.9799 - binary_accuracy: 0.9276 - val_loss: 0.2770 - val_auroc: 0.9553 - val_aupr: 0.9572 - val_binary_accuracy: 0.8720\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1758 - auroc: 0.9805 - aupr: 0.9831 - binary_accuracy: 0.9298 - val_loss: 0.3172 - val_auroc: 0.9624 - val_aupr: 0.9655 - val_binary_accuracy: 0.8601\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1483 - auroc: 0.9863 - aupr: 0.9880 - binary_accuracy: 0.9378 - val_loss: 0.2531 - val_auroc: 0.9637 - val_aupr: 0.9646 - val_binary_accuracy: 0.9018\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1245 - auroc: 0.9897 - aupr: 0.9907 - binary_accuracy: 0.9570 - val_loss: 0.2557 - val_auroc: 0.9619 - val_aupr: 0.9636 - val_binary_accuracy: 0.8869\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0946 - auroc: 0.9945 - aupr: 0.9949 - binary_accuracy: 0.9681 - val_loss: 0.3426 - val_auroc: 0.9547 - val_aupr: 0.9549 - val_binary_accuracy: 0.8929\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0771 - auroc: 0.9965 - aupr: 0.9971 - binary_accuracy: 0.9693 - val_loss: 0.3750 - val_auroc: 0.9541 - val_aupr: 0.9510 - val_binary_accuracy: 0.8839\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0692 - auroc: 0.9965 - aupr: 0.9961 - binary_accuracy: 0.9762 - val_loss: 0.3369 - val_auroc: 0.9573 - val_aupr: 0.9565 - val_binary_accuracy: 0.8899\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0679 - auroc: 0.9969 - aupr: 0.9969 - binary_accuracy: 0.9757 - val_loss: 0.4322 - val_auroc: 0.9435 - val_aupr: 0.9329 - val_binary_accuracy: 0.8839\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6884 - auroc: 0.9083 - aupr: 0.8884 - binary_accuracy: 0.8467\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 1s 19ms/step - loss: 0.6348 - auroc: 0.6980 - aupr: 0.7087 - binary_accuracy: 0.6352 - val_loss: 0.4486 - val_auroc: 0.8776 - val_aupr: 0.8863 - val_binary_accuracy: 0.8065\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4697 - auroc: 0.8614 - aupr: 0.8766 - binary_accuracy: 0.7884 - val_loss: 0.4098 - val_auroc: 0.9089 - val_aupr: 0.9260 - val_binary_accuracy: 0.8304\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3942 - auroc: 0.9024 - aupr: 0.9212 - binary_accuracy: 0.8335 - val_loss: 0.3331 - val_auroc: 0.9343 - val_aupr: 0.9459 - val_binary_accuracy: 0.8690\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3427 - auroc: 0.9266 - aupr: 0.9409 - binary_accuracy: 0.8497 - val_loss: 0.3000 - val_auroc: 0.9469 - val_aupr: 0.9574 - val_binary_accuracy: 0.8899\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2913 - auroc: 0.9473 - aupr: 0.9579 - binary_accuracy: 0.8834 - val_loss: 0.3364 - val_auroc: 0.9370 - val_aupr: 0.9438 - val_binary_accuracy: 0.8571\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2293 - auroc: 0.9683 - aupr: 0.9753 - binary_accuracy: 0.9063 - val_loss: 0.3232 - val_auroc: 0.9499 - val_aupr: 0.9555 - val_binary_accuracy: 0.8720\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2054 - auroc: 0.9735 - aupr: 0.9781 - binary_accuracy: 0.9204 - val_loss: 0.3344 - val_auroc: 0.9400 - val_aupr: 0.9483 - val_binary_accuracy: 0.8512\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1638 - auroc: 0.9836 - aupr: 0.9872 - binary_accuracy: 0.9336 - val_loss: 0.3468 - val_auroc: 0.9419 - val_aupr: 0.9386 - val_binary_accuracy: 0.8631\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1777 - auroc: 0.9804 - aupr: 0.9841 - binary_accuracy: 0.9234 - val_loss: 0.3368 - val_auroc: 0.9441 - val_aupr: 0.9519 - val_binary_accuracy: 0.8482\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4521 - auroc: 0.9187 - aupr: 0.9303 - binary_accuracy: 0.8304\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 1s 20ms/step - loss: 1.0882 - auroc: 0.4943 - aupr: 0.5399 - binary_accuracy: 0.4989 - val_loss: 0.6957 - val_auroc: 0.5184 - val_aupr: 0.5119 - val_binary_accuracy: 0.5089\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7101 - auroc: 0.4853 - aupr: 0.5351 - binary_accuracy: 0.5023 - val_loss: 0.7057 - val_auroc: 0.5574 - val_aupr: 0.5548 - val_binary_accuracy: 0.5089\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6944 - auroc: 0.4916 - aupr: 0.5348 - binary_accuracy: 0.5177 - val_loss: 0.6972 - val_auroc: 0.5878 - val_aupr: 0.5670 - val_binary_accuracy: 0.5089\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6925 - auroc: 0.4896 - aupr: 0.5320 - binary_accuracy: 0.5381 - val_loss: 0.6927 - val_auroc: 0.6426 - val_aupr: 0.6304 - val_binary_accuracy: 0.5089\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6899 - auroc: 0.5129 - aupr: 0.5439 - binary_accuracy: 0.5466 - val_loss: 0.6884 - val_auroc: 0.7235 - val_aupr: 0.7211 - val_binary_accuracy: 0.5089\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6810 - auroc: 0.5965 - aupr: 0.6054 - binary_accuracy: 0.5717 - val_loss: 0.6716 - val_auroc: 0.7568 - val_aupr: 0.7512 - val_binary_accuracy: 0.5327\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6126 - auroc: 0.7365 - aupr: 0.7597 - binary_accuracy: 0.6645 - val_loss: 0.5050 - val_auroc: 0.8428 - val_aupr: 0.8619 - val_binary_accuracy: 0.7619\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4723 - auroc: 0.8617 - aupr: 0.8773 - binary_accuracy: 0.7910 - val_loss: 0.4029 - val_auroc: 0.9033 - val_aupr: 0.9153 - val_binary_accuracy: 0.8125\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4391 - auroc: 0.8793 - aupr: 0.8946 - binary_accuracy: 0.8072 - val_loss: 0.4010 - val_auroc: 0.9119 - val_aupr: 0.9219 - val_binary_accuracy: 0.8274\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4267 - auroc: 0.8857 - aupr: 0.9054 - binary_accuracy: 0.8131 - val_loss: 0.3948 - val_auroc: 0.9117 - val_aupr: 0.9223 - val_binary_accuracy: 0.8185\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3687 - auroc: 0.9151 - aupr: 0.9303 - binary_accuracy: 0.8387 - val_loss: 0.4415 - val_auroc: 0.9293 - val_aupr: 0.9358 - val_binary_accuracy: 0.7946\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3787 - auroc: 0.9108 - aupr: 0.9270 - binary_accuracy: 0.8421 - val_loss: 0.3221 - val_auroc: 0.9348 - val_aupr: 0.9440 - val_binary_accuracy: 0.8750\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3494 - auroc: 0.9241 - aupr: 0.9378 - binary_accuracy: 0.8565 - val_loss: 0.3587 - val_auroc: 0.9357 - val_aupr: 0.9420 - val_binary_accuracy: 0.8482\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3306 - auroc: 0.9327 - aupr: 0.9454 - binary_accuracy: 0.8608 - val_loss: 0.3510 - val_auroc: 0.9374 - val_aupr: 0.9392 - val_binary_accuracy: 0.8452\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3084 - auroc: 0.9409 - aupr: 0.9525 - binary_accuracy: 0.8714 - val_loss: 0.3049 - val_auroc: 0.9416 - val_aupr: 0.9429 - val_binary_accuracy: 0.8750\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2839 - auroc: 0.9502 - aupr: 0.9607 - binary_accuracy: 0.8778 - val_loss: 0.2992 - val_auroc: 0.9448 - val_aupr: 0.9424 - val_binary_accuracy: 0.8750\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2943 - auroc: 0.9465 - aupr: 0.9552 - binary_accuracy: 0.8668 - val_loss: 0.2877 - val_auroc: 0.9506 - val_aupr: 0.9486 - val_binary_accuracy: 0.8661\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2718 - auroc: 0.9558 - aupr: 0.9617 - binary_accuracy: 0.8919 - val_loss: 0.3208 - val_auroc: 0.9522 - val_aupr: 0.9529 - val_binary_accuracy: 0.8512\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2557 - auroc: 0.9599 - aupr: 0.9679 - binary_accuracy: 0.8863 - val_loss: 0.2803 - val_auroc: 0.9525 - val_aupr: 0.9491 - val_binary_accuracy: 0.8810\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2587 - auroc: 0.9587 - aupr: 0.9649 - binary_accuracy: 0.8948 - val_loss: 0.2642 - val_auroc: 0.9588 - val_aupr: 0.9556 - val_binary_accuracy: 0.9018\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2298 - auroc: 0.9677 - aupr: 0.9731 - binary_accuracy: 0.9008 - val_loss: 0.3171 - val_auroc: 0.9584 - val_aupr: 0.9627 - val_binary_accuracy: 0.8690\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2394 - auroc: 0.9643 - aupr: 0.9720 - binary_accuracy: 0.9034 - val_loss: 0.2759 - val_auroc: 0.9544 - val_aupr: 0.9524 - val_binary_accuracy: 0.8780\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2364 - auroc: 0.9657 - aupr: 0.9721 - binary_accuracy: 0.8966 - val_loss: 0.3899 - val_auroc: 0.9443 - val_aupr: 0.9429 - val_binary_accuracy: 0.8423\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2070 - auroc: 0.9736 - aupr: 0.9772 - binary_accuracy: 0.9136 - val_loss: 0.2858 - val_auroc: 0.9520 - val_aupr: 0.9572 - val_binary_accuracy: 0.8750\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1858 - auroc: 0.9786 - aupr: 0.9824 - binary_accuracy: 0.9298 - val_loss: 0.2967 - val_auroc: 0.9598 - val_aupr: 0.9577 - val_binary_accuracy: 0.8810\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3857 - auroc: 0.9283 - aupr: 0.9286 - binary_accuracy: 0.8393\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, callbacks, activations, optimizers\n",
    "\n",
    "directory_path = \"/home/pgarcia/rbp_project/data\"\n",
    "perf = pd.DataFrame()\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for file_path in os.listdir(directory_path):\n",
    "    data_path = os.path.join(directory_path, file_path)\n",
    "\n",
    "    # Check if the item is a file (not a subdirectory)\n",
    "    if os.path.isfile(data_path):\n",
    "\n",
    "        # Process the file here\n",
    "        print(\"Processing:\", file_path)\n",
    "        \n",
    "        # Processing code goes here\n",
    "        \n",
    "        from data_4_models import data_arrays, input_shape_check\n",
    "        x_train, y_train, x_valid, y_valid, x_test, y_test, alphabet = data_arrays(data_path)\n",
    "        print(x_train.shape, y_train.shape)\n",
    "\n",
    "\n",
    "        x_train, x_test, x_valid = input_shape_check(x_train, x_test,x_valid) #check shape of data\n",
    "        \n",
    "        # import models\n",
    "        from rbp_models import deepbind, deepbind_exp, baseline_cnn, baseline_cnn_exp\n",
    "        rbp_models_list = [deepbind, deepbind_exp, baseline_cnn, baseline_cnn_exp]\n",
    "        for m_func in rbp_models_list:\n",
    "            model = m_func() # call function to create model\n",
    "            loss = keras.losses.BinaryCrossentropy()\n",
    "            opti = tf.keras.optimizers.Adam(learning_rate = 0.005)\n",
    "            \n",
    "\n",
    "            # Compile the model\n",
    "            model.compile(\n",
    "                loss=loss,\n",
    "                optimizer=opti, \n",
    "                metrics=[\n",
    "                    tf.keras.metrics.AUC(curve=\"ROC\", name=\"auroc\"),\n",
    "                    tf.keras.metrics.AUC(curve=\"PR\", name=\"aupr\"),  # add AUPR curve to track dataset bias\n",
    "                    tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None)\n",
    "                ])\n",
    "            # Define an early stopping callback\n",
    "            es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(\n",
    "                x_train, y_train,\n",
    "                batch_size=100,\n",
    "                epochs=100,\n",
    "                validation_data=(x_valid, y_valid),\n",
    "                callbacks=[es_callback]\n",
    "            )\n",
    "            # Saving model\n",
    "            model.save(f'models_deepbind3/{m_func.__name__} + {file_path}') \n",
    "\n",
    "            # Evaluate model\n",
    "            eval = model.evaluate(x_test, y_test)\n",
    "\n",
    "\n",
    "            # Add performance data to Dataframe\n",
    "            performance_data = {\n",
    "                \"Exp\": [file_path],\n",
    "                \"Model\": [m_func.__name__],\n",
    "                \"Loss\": [eval[0]],\n",
    "                \"AUROC\": [eval[1]],\n",
    "                \"AUPR\": [eval[2]],\n",
    "                \"Accuracy\": [eval[3]],\n",
    "                \"Dir\": [data_path]\n",
    "            }\n",
    "            # Convert dictionary to DataFrame\n",
    "            performance_data = pd.DataFrame(performance_data)\n",
    "\n",
    "            # Add new rows to DataFrame\n",
    "            perf = pd.concat([perf, performance_data], ignore_index=True)\n",
    "\n",
    "            # convert DataFrame to CSV file\n",
    "            perf.to_csv(path_or_buf='/home/pgarcia/rbp_project/perf_data_10rbps.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exp</th>\n",
       "      <th>Model</th>\n",
       "      <th>Loss</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPR</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HNRNPK_K562_200.h5</td>\n",
       "      <td>deepbind</td>\n",
       "      <td>0.243198</td>\n",
       "      <td>0.977016</td>\n",
       "      <td>0.974916</td>\n",
       "      <td>0.931065</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/HNRNPK_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HNRNPK_K562_200.h5</td>\n",
       "      <td>deepbind_exp</td>\n",
       "      <td>0.201808</td>\n",
       "      <td>0.978255</td>\n",
       "      <td>0.976007</td>\n",
       "      <td>0.933682</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/HNRNPK_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HNRNPK_K562_200.h5</td>\n",
       "      <td>baseline_cnn</td>\n",
       "      <td>0.229653</td>\n",
       "      <td>0.980639</td>\n",
       "      <td>0.979791</td>\n",
       "      <td>0.934555</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/HNRNPK_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HNRNPK_K562_200.h5</td>\n",
       "      <td>baseline_cnn_exp</td>\n",
       "      <td>0.196165</td>\n",
       "      <td>0.980351</td>\n",
       "      <td>0.971561</td>\n",
       "      <td>0.943281</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/HNRNPK_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PTBP1_K562_200.h5</td>\n",
       "      <td>deepbind</td>\n",
       "      <td>0.211431</td>\n",
       "      <td>0.976631</td>\n",
       "      <td>0.980031</td>\n",
       "      <td>0.915045</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/PTBP1_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PTBP1_K562_200.h5</td>\n",
       "      <td>deepbind_exp</td>\n",
       "      <td>0.172111</td>\n",
       "      <td>0.980363</td>\n",
       "      <td>0.982465</td>\n",
       "      <td>0.928329</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/PTBP1_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PTBP1_K562_200.h5</td>\n",
       "      <td>baseline_cnn</td>\n",
       "      <td>0.200818</td>\n",
       "      <td>0.978184</td>\n",
       "      <td>0.979211</td>\n",
       "      <td>0.930491</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/PTBP1_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PTBP1_K562_200.h5</td>\n",
       "      <td>baseline_cnn_exp</td>\n",
       "      <td>0.183511</td>\n",
       "      <td>0.977798</td>\n",
       "      <td>0.981644</td>\n",
       "      <td>0.925239</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/PTBP1_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PUM2_K562_200.h5</td>\n",
       "      <td>deepbind</td>\n",
       "      <td>0.302554</td>\n",
       "      <td>0.949903</td>\n",
       "      <td>0.951401</td>\n",
       "      <td>0.877241</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/PUM2_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PUM2_K562_200.h5</td>\n",
       "      <td>deepbind_exp</td>\n",
       "      <td>0.314208</td>\n",
       "      <td>0.945462</td>\n",
       "      <td>0.947392</td>\n",
       "      <td>0.869655</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/PUM2_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PUM2_K562_200.h5</td>\n",
       "      <td>baseline_cnn</td>\n",
       "      <td>0.349606</td>\n",
       "      <td>0.936664</td>\n",
       "      <td>0.939158</td>\n",
       "      <td>0.858966</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/PUM2_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PUM2_K562_200.h5</td>\n",
       "      <td>baseline_cnn_exp</td>\n",
       "      <td>0.325821</td>\n",
       "      <td>0.947436</td>\n",
       "      <td>0.951173</td>\n",
       "      <td>0.864138</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/PUM2_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>QKI_K562_200.h5</td>\n",
       "      <td>deepbind</td>\n",
       "      <td>0.167283</td>\n",
       "      <td>0.983766</td>\n",
       "      <td>0.986385</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/QKI_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>QKI_K562_200.h5</td>\n",
       "      <td>deepbind_exp</td>\n",
       "      <td>0.271089</td>\n",
       "      <td>0.975021</td>\n",
       "      <td>0.964123</td>\n",
       "      <td>0.926170</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/QKI_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>QKI_K562_200.h5</td>\n",
       "      <td>baseline_cnn</td>\n",
       "      <td>0.242259</td>\n",
       "      <td>0.977395</td>\n",
       "      <td>0.970377</td>\n",
       "      <td>0.939327</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/QKI_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>QKI_K562_200.h5</td>\n",
       "      <td>baseline_cnn_exp</td>\n",
       "      <td>0.149864</td>\n",
       "      <td>0.985520</td>\n",
       "      <td>0.983662</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/QKI_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RBFOX2_K562_200.h5</td>\n",
       "      <td>deepbind</td>\n",
       "      <td>0.338700</td>\n",
       "      <td>0.948959</td>\n",
       "      <td>0.951011</td>\n",
       "      <td>0.866926</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/RBFOX2_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RBFOX2_K562_200.h5</td>\n",
       "      <td>deepbind_exp</td>\n",
       "      <td>0.364967</td>\n",
       "      <td>0.948132</td>\n",
       "      <td>0.947196</td>\n",
       "      <td>0.879176</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/RBFOX2_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RBFOX2_K562_200.h5</td>\n",
       "      <td>baseline_cnn</td>\n",
       "      <td>0.326607</td>\n",
       "      <td>0.950623</td>\n",
       "      <td>0.941921</td>\n",
       "      <td>0.880846</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/RBFOX2_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RBFOX2_K562_200.h5</td>\n",
       "      <td>baseline_cnn_exp</td>\n",
       "      <td>0.349577</td>\n",
       "      <td>0.946599</td>\n",
       "      <td>0.938058</td>\n",
       "      <td>0.883630</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/RBFOX2_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SF3B4_K562_200.h5</td>\n",
       "      <td>deepbind</td>\n",
       "      <td>0.280731</td>\n",
       "      <td>0.953171</td>\n",
       "      <td>0.950554</td>\n",
       "      <td>0.882191</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/SF3B4_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SF3B4_K562_200.h5</td>\n",
       "      <td>deepbind_exp</td>\n",
       "      <td>0.284308</td>\n",
       "      <td>0.954813</td>\n",
       "      <td>0.953711</td>\n",
       "      <td>0.885557</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/SF3B4_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SF3B4_K562_200.h5</td>\n",
       "      <td>baseline_cnn</td>\n",
       "      <td>0.305311</td>\n",
       "      <td>0.945419</td>\n",
       "      <td>0.943135</td>\n",
       "      <td>0.871634</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/SF3B4_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SF3B4_K562_200.h5</td>\n",
       "      <td>baseline_cnn_exp</td>\n",
       "      <td>0.314575</td>\n",
       "      <td>0.952719</td>\n",
       "      <td>0.953342</td>\n",
       "      <td>0.877142</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/SF3B4_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SRSF1_K562_200.h5</td>\n",
       "      <td>deepbind</td>\n",
       "      <td>0.360106</td>\n",
       "      <td>0.941947</td>\n",
       "      <td>0.942865</td>\n",
       "      <td>0.867390</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/SRSF1_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SRSF1_K562_200.h5</td>\n",
       "      <td>deepbind_exp</td>\n",
       "      <td>0.412010</td>\n",
       "      <td>0.933220</td>\n",
       "      <td>0.923567</td>\n",
       "      <td>0.841535</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/SRSF1_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SRSF1_K562_200.h5</td>\n",
       "      <td>baseline_cnn</td>\n",
       "      <td>0.405804</td>\n",
       "      <td>0.934500</td>\n",
       "      <td>0.935321</td>\n",
       "      <td>0.853211</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/SRSF1_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SRSF1_K562_200.h5</td>\n",
       "      <td>baseline_cnn_exp</td>\n",
       "      <td>0.390454</td>\n",
       "      <td>0.937221</td>\n",
       "      <td>0.937736</td>\n",
       "      <td>0.840701</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/SRSF1_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TARDBP_K562_200.h5</td>\n",
       "      <td>deepbind</td>\n",
       "      <td>0.095718</td>\n",
       "      <td>0.992812</td>\n",
       "      <td>0.991757</td>\n",
       "      <td>0.969447</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/TARDBP_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TARDBP_K562_200.h5</td>\n",
       "      <td>deepbind_exp</td>\n",
       "      <td>0.135305</td>\n",
       "      <td>0.990201</td>\n",
       "      <td>0.987950</td>\n",
       "      <td>0.964905</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/TARDBP_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>TARDBP_K562_200.h5</td>\n",
       "      <td>baseline_cnn</td>\n",
       "      <td>0.123941</td>\n",
       "      <td>0.990722</td>\n",
       "      <td>0.988798</td>\n",
       "      <td>0.960363</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/TARDBP_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TARDBP_K562_200.h5</td>\n",
       "      <td>baseline_cnn_exp</td>\n",
       "      <td>0.110426</td>\n",
       "      <td>0.991673</td>\n",
       "      <td>0.992322</td>\n",
       "      <td>0.963666</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/TARDBP_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>TIA1_K562_200.h5</td>\n",
       "      <td>deepbind</td>\n",
       "      <td>0.384287</td>\n",
       "      <td>0.911678</td>\n",
       "      <td>0.904345</td>\n",
       "      <td>0.833103</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/TIA1_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TIA1_K562_200.h5</td>\n",
       "      <td>deepbind_exp</td>\n",
       "      <td>0.418394</td>\n",
       "      <td>0.904361</td>\n",
       "      <td>0.899664</td>\n",
       "      <td>0.826195</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/TIA1_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>TIA1_K562_200.h5</td>\n",
       "      <td>baseline_cnn</td>\n",
       "      <td>0.414705</td>\n",
       "      <td>0.899854</td>\n",
       "      <td>0.888397</td>\n",
       "      <td>0.820669</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/TIA1_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TIA1_K562_200.h5</td>\n",
       "      <td>baseline_cnn_exp</td>\n",
       "      <td>0.391396</td>\n",
       "      <td>0.906898</td>\n",
       "      <td>0.902964</td>\n",
       "      <td>0.827024</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/TIA1_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>U2AF1_K562_200.h5</td>\n",
       "      <td>deepbind</td>\n",
       "      <td>0.474239</td>\n",
       "      <td>0.922177</td>\n",
       "      <td>0.918111</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/U2AF1_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>U2AF1_K562_200.h5</td>\n",
       "      <td>deepbind_exp</td>\n",
       "      <td>0.688450</td>\n",
       "      <td>0.908260</td>\n",
       "      <td>0.888420</td>\n",
       "      <td>0.846726</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/U2AF1_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>U2AF1_K562_200.h5</td>\n",
       "      <td>baseline_cnn</td>\n",
       "      <td>0.452076</td>\n",
       "      <td>0.918736</td>\n",
       "      <td>0.930290</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/U2AF1_K562_200.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>U2AF1_K562_200.h5</td>\n",
       "      <td>baseline_cnn_exp</td>\n",
       "      <td>0.385701</td>\n",
       "      <td>0.928264</td>\n",
       "      <td>0.928611</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>/home/pgarcia/rbp_project/data/U2AF1_K562_200.h5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Exp             Model      Loss     AUROC      AUPR  \\\n",
       "0   HNRNPK_K562_200.h5          deepbind  0.243198  0.977016  0.974916   \n",
       "1   HNRNPK_K562_200.h5      deepbind_exp  0.201808  0.978255  0.976007   \n",
       "2   HNRNPK_K562_200.h5      baseline_cnn  0.229653  0.980639  0.979791   \n",
       "3   HNRNPK_K562_200.h5  baseline_cnn_exp  0.196165  0.980351  0.971561   \n",
       "4    PTBP1_K562_200.h5          deepbind  0.211431  0.976631  0.980031   \n",
       "5    PTBP1_K562_200.h5      deepbind_exp  0.172111  0.980363  0.982465   \n",
       "6    PTBP1_K562_200.h5      baseline_cnn  0.200818  0.978184  0.979211   \n",
       "7    PTBP1_K562_200.h5  baseline_cnn_exp  0.183511  0.977798  0.981644   \n",
       "8     PUM2_K562_200.h5          deepbind  0.302554  0.949903  0.951401   \n",
       "9     PUM2_K562_200.h5      deepbind_exp  0.314208  0.945462  0.947392   \n",
       "10    PUM2_K562_200.h5      baseline_cnn  0.349606  0.936664  0.939158   \n",
       "11    PUM2_K562_200.h5  baseline_cnn_exp  0.325821  0.947436  0.951173   \n",
       "12     QKI_K562_200.h5          deepbind  0.167283  0.983766  0.986385   \n",
       "13     QKI_K562_200.h5      deepbind_exp  0.271089  0.975021  0.964123   \n",
       "14     QKI_K562_200.h5      baseline_cnn  0.242259  0.977395  0.970377   \n",
       "15     QKI_K562_200.h5  baseline_cnn_exp  0.149864  0.985520  0.983662   \n",
       "16  RBFOX2_K562_200.h5          deepbind  0.338700  0.948959  0.951011   \n",
       "17  RBFOX2_K562_200.h5      deepbind_exp  0.364967  0.948132  0.947196   \n",
       "18  RBFOX2_K562_200.h5      baseline_cnn  0.326607  0.950623  0.941921   \n",
       "19  RBFOX2_K562_200.h5  baseline_cnn_exp  0.349577  0.946599  0.938058   \n",
       "20   SF3B4_K562_200.h5          deepbind  0.280731  0.953171  0.950554   \n",
       "21   SF3B4_K562_200.h5      deepbind_exp  0.284308  0.954813  0.953711   \n",
       "22   SF3B4_K562_200.h5      baseline_cnn  0.305311  0.945419  0.943135   \n",
       "23   SF3B4_K562_200.h5  baseline_cnn_exp  0.314575  0.952719  0.953342   \n",
       "24   SRSF1_K562_200.h5          deepbind  0.360106  0.941947  0.942865   \n",
       "25   SRSF1_K562_200.h5      deepbind_exp  0.412010  0.933220  0.923567   \n",
       "26   SRSF1_K562_200.h5      baseline_cnn  0.405804  0.934500  0.935321   \n",
       "27   SRSF1_K562_200.h5  baseline_cnn_exp  0.390454  0.937221  0.937736   \n",
       "28  TARDBP_K562_200.h5          deepbind  0.095718  0.992812  0.991757   \n",
       "29  TARDBP_K562_200.h5      deepbind_exp  0.135305  0.990201  0.987950   \n",
       "30  TARDBP_K562_200.h5      baseline_cnn  0.123941  0.990722  0.988798   \n",
       "31  TARDBP_K562_200.h5  baseline_cnn_exp  0.110426  0.991673  0.992322   \n",
       "32    TIA1_K562_200.h5          deepbind  0.384287  0.911678  0.904345   \n",
       "33    TIA1_K562_200.h5      deepbind_exp  0.418394  0.904361  0.899664   \n",
       "34    TIA1_K562_200.h5      baseline_cnn  0.414705  0.899854  0.888397   \n",
       "35    TIA1_K562_200.h5  baseline_cnn_exp  0.391396  0.906898  0.902964   \n",
       "36   U2AF1_K562_200.h5          deepbind  0.474239  0.922177  0.918111   \n",
       "37   U2AF1_K562_200.h5      deepbind_exp  0.688450  0.908260  0.888420   \n",
       "38   U2AF1_K562_200.h5      baseline_cnn  0.452076  0.918736  0.930290   \n",
       "39   U2AF1_K562_200.h5  baseline_cnn_exp  0.385701  0.928264  0.928611   \n",
       "\n",
       "    Accuracy                                                Dir  \n",
       "0   0.931065  /home/pgarcia/rbp_project/data/HNRNPK_K562_200.h5  \n",
       "1   0.933682  /home/pgarcia/rbp_project/data/HNRNPK_K562_200.h5  \n",
       "2   0.934555  /home/pgarcia/rbp_project/data/HNRNPK_K562_200.h5  \n",
       "3   0.943281  /home/pgarcia/rbp_project/data/HNRNPK_K562_200.h5  \n",
       "4   0.915045   /home/pgarcia/rbp_project/data/PTBP1_K562_200.h5  \n",
       "5   0.928329   /home/pgarcia/rbp_project/data/PTBP1_K562_200.h5  \n",
       "6   0.930491   /home/pgarcia/rbp_project/data/PTBP1_K562_200.h5  \n",
       "7   0.925239   /home/pgarcia/rbp_project/data/PTBP1_K562_200.h5  \n",
       "8   0.877241    /home/pgarcia/rbp_project/data/PUM2_K562_200.h5  \n",
       "9   0.869655    /home/pgarcia/rbp_project/data/PUM2_K562_200.h5  \n",
       "10  0.858966    /home/pgarcia/rbp_project/data/PUM2_K562_200.h5  \n",
       "11  0.864138    /home/pgarcia/rbp_project/data/PUM2_K562_200.h5  \n",
       "12  0.958333     /home/pgarcia/rbp_project/data/QKI_K562_200.h5  \n",
       "13  0.926170     /home/pgarcia/rbp_project/data/QKI_K562_200.h5  \n",
       "14  0.939327     /home/pgarcia/rbp_project/data/QKI_K562_200.h5  \n",
       "15  0.960526     /home/pgarcia/rbp_project/data/QKI_K562_200.h5  \n",
       "16  0.866926  /home/pgarcia/rbp_project/data/RBFOX2_K562_200.h5  \n",
       "17  0.879176  /home/pgarcia/rbp_project/data/RBFOX2_K562_200.h5  \n",
       "18  0.880846  /home/pgarcia/rbp_project/data/RBFOX2_K562_200.h5  \n",
       "19  0.883630  /home/pgarcia/rbp_project/data/RBFOX2_K562_200.h5  \n",
       "20  0.882191   /home/pgarcia/rbp_project/data/SF3B4_K562_200.h5  \n",
       "21  0.885557   /home/pgarcia/rbp_project/data/SF3B4_K562_200.h5  \n",
       "22  0.871634   /home/pgarcia/rbp_project/data/SF3B4_K562_200.h5  \n",
       "23  0.877142   /home/pgarcia/rbp_project/data/SF3B4_K562_200.h5  \n",
       "24  0.867390   /home/pgarcia/rbp_project/data/SRSF1_K562_200.h5  \n",
       "25  0.841535   /home/pgarcia/rbp_project/data/SRSF1_K562_200.h5  \n",
       "26  0.853211   /home/pgarcia/rbp_project/data/SRSF1_K562_200.h5  \n",
       "27  0.840701   /home/pgarcia/rbp_project/data/SRSF1_K562_200.h5  \n",
       "28  0.969447  /home/pgarcia/rbp_project/data/TARDBP_K562_200.h5  \n",
       "29  0.964905  /home/pgarcia/rbp_project/data/TARDBP_K562_200.h5  \n",
       "30  0.960363  /home/pgarcia/rbp_project/data/TARDBP_K562_200.h5  \n",
       "31  0.963666  /home/pgarcia/rbp_project/data/TARDBP_K562_200.h5  \n",
       "32  0.833103    /home/pgarcia/rbp_project/data/TIA1_K562_200.h5  \n",
       "33  0.826195    /home/pgarcia/rbp_project/data/TIA1_K562_200.h5  \n",
       "34  0.820669    /home/pgarcia/rbp_project/data/TIA1_K562_200.h5  \n",
       "35  0.827024    /home/pgarcia/rbp_project/data/TIA1_K562_200.h5  \n",
       "36  0.848214   /home/pgarcia/rbp_project/data/U2AF1_K562_200.h5  \n",
       "37  0.846726   /home/pgarcia/rbp_project/data/U2AF1_K562_200.h5  \n",
       "38  0.830357   /home/pgarcia/rbp_project/data/U2AF1_K562_200.h5  \n",
       "39  0.839286   /home/pgarcia/rbp_project/data/U2AF1_K562_200.h5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CSV\n",
    "pd.read_csv('perf_data_10rbps.csv',index_col=0)\n",
    "\n",
    "# load model and add accuracy to the CSV\n",
    "\n",
    "# clean up dataframe (remove \"_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pgarcia/.conda/envs/tf_2/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/pgarcia/.conda/envs/tf_2/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/pgarcia/.conda/envs/tf_2/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/pgarcia/.conda/envs/tf_2/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#add csv file to dataframe\n",
    "df = pd.read_csv('perf_data_test.csv',index_col=0)\n",
    "\n",
    "# Define a function to remove the last 12 characters from a string\n",
    "def remove_last_12_chars(s):\n",
    "    return s[:-12] if len(s) >= 12 else s\n",
    "\n",
    "# Apply the function to the specified column\n",
    "df['Exp'] = df['Exp'].apply(remove_last_12_chars)\n",
    "\n",
    "\n",
    "# Create a bar plot with Seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.barplot(x='Exp', y='Accuracy', hue='Model', data=df, palette='viridis')\n",
    "\n",
    "# Customize the plot by setting labels and a title\n",
    "ax.set(ylabel='Accuracy')\n",
    "ax.set_title('Accuracy for each protein experiment')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the legend\n",
    "ax.legend(title='Models', title_fontsize='9', fontsize='8',loc='lower right')\n",
    "\n",
    "plt.savefig(\"Accuracy_protein_plot.svg\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only include protein name on the x axis\n",
    "# get accuracy metric from new csv file\n",
    "\n",
    "# rename models \n",
    "# resen_test = \"CNN baseline\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pgarcia/.conda/envs/tf_2/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/pgarcia/.conda/envs/tf_2/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/pgarcia/.conda/envs/tf_2/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/pgarcia/.conda/envs/tf_2/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAH4CAYAAACxPBJHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABuMElEQVR4nO3dd1hUV/4G8HdmqIpKEQkIdgEVUIyaFYkENEaxg9EkYqLRtWvW6NobRgGN2FBXEmvsG7GAorGbApbEAjEWIhYsQaSsDRiYub8//DFhhiLgMHdg3s/z+ARu/d7JwLyce+45EkEQBBARERGRilTsAoiIiIj0DQMSERERkQYGJCIiIiINDEhEREREGhiQiIiIiDQwIBERERFpYEAiIiIi0sCARERERKSBAYmIiIhIAwMSEVXI3r174eLigvv37+vsnPv370f37t3RqlUrtGvXTmfn1ZX79+/DxcUFGzZsELuUcvPz88P06dMrtK+LiwsiIiK0XBHRm2FAItJzBUHExcUFv/76a5H1giDAx8cHLi4uGDVqVIXOsX37duzdu/dNS61Ut27dwowZM9CgQQN89dVXWLBggdgl6Z1z586p3isHDhwodpuPPvoILi4u6NWrl46rI6paGJCIqghTU1McPHiwyPLz58/jr7/+gomJSYWPvXPnTuzbt69c+/Tt2xcJCQmoX79+hc9bHufPn4dSqcSsWbMQEBAAf39/nZy3KirpvXL//n1cunQJpqamIlRFVLUwIBFVET4+Pjhy5Ajy8/PVlh88eBCtWrWCra2tTup4+fIlAEAmk8HU1BQSiUQn501PTwcA1KpVS2vHzM7O1tqx9ImPjw/i4uKQkZGhtvzgwYOoW7cu3NzcRKqMqOpgQCKqInr27ImsrCz88ssvqmVyuRw//PADevfuXew+SqUSmzdvRs+ePeHu7g4vLy/MnTsX//vf/1Tb+Pn5ISkpCefPn1fdnhkyZAiAv2/vnT9/HvPnz0fHjh3h4+Ojtk6zD9KZM2cQFBQET09PtG3bFoGBgYiJiVGtv3PnDiZMmIBOnTrB3d0dnTt3xqRJk/Ds2bMSr93Pz0/VR6Vjx45F+qxs374dPXv2hJubG7y9vREcHIynT5+qHWPIkCHo1asXfv/9dwwePBitW7fGsmXLSn3Nb926hYkTJ6JDhw5wd3dHQEAATpw4obZNVlYWFi9ejN69e6uuecSIEbh+/XqR4+Xm5iIiIgIffPAB3N3d4e3tjfHjx+PevXtFtt29eze6du0KNzc3BAYGIiEhodRaC+vSpQtMTExw5MgRteUHDx5Ejx49IJPJiuyTn5+PNWvWqM7p5+eHZcuWQS6Xq20nCALWrl2Lzp07o3Xr1hgyZAiSkpKKrePp06dYtGgRfHx84Obmhvfffx/ffPMNlEplma+FSCxGYhdARGVTv359tGnTBocOHVKFlB9//BHPnj2Dv78/tm7dWmSfuXPnYt++fQgICMCQIUNw//59bN++HX/88Qd27twJY2NjzJw5E1999RVq1KiB0aNHAwDq1q2rdpzg4GBYW1tj3Lhxqhak4uzduxczZ85E8+bNMWrUKNSqVQvXrl3DTz/9hN69e0Mul2P48OGQy+UICgpC3bp1kZqaitOnT+Pp06cltg7NnDkT+/fvx7FjxzB//nzUqFEDLi4uAICIiAisXr0aXl5e+Pjjj3H79m3s3LkTiYmJqmsskJWVhX/+85/o2bMn+vTpAxsbmxKvJSkpCR9//DHs7Ozwz3/+EzVq1MDhw4cxbtw4RERE4P333wcApKSk4Pjx4+jevTscHR3x5MkT7N69G0FBQTh06BDs7OwAAAqFAqNGjUJ8fDx69uyJTz/9FC9evMAvv/yCmzdvokGDBqpzHzx4EC9evMCgQYMgkUiwfv16TJgwAcePH1e7npKYmZnBz88Phw4dwieffAIAuH79OpKSkrBw4ULcuHGjyD6zZ8/Gvn378MEHH2DYsGFISEhAZGQkbt26hTVr1qi2W7lyJf7zn//Ax8cHPj4+uHr1Kj7//HPk5eWpHS87OxtBQUFITU3FRx99BHt7e1y6dAnLli1DWloaZs2a9drrIBKVQER6LSoqSnB2dhYSEhKEbdu2CZ6enkJ2drYgCIIwceJEYciQIYIgCIKvr68wcuRI1X4XLlwQnJ2dhejoaLXj/fjjj0WW9+zZUwgKCirx3B9//LGQn59f7LqUlBRBEATh6dOngqenp/Dhhx8KOTk5atsqlUpBEAThjz/+EJydnYXDhw+X+3VYtWqV4OzsLKSnp6uWpaenC61atRI+//xzQaFQqJZv27ZNcHZ2Fvbs2aNaFhQUJDg7Ows7d+4s0/k+++wzoVevXkJubq7adQwaNEjo1q2ballubq7auQVBEFJSUgQ3Nzdh9erVqmV79uwRnJ2dhU2bNhU5V8Hrk5KSIjg7OwsdOnQQsrKyVOuPHz8uODs7CydPniy15rNnz6pe31OnTgkuLi7Cw4cPBUEQhMWLFwtdunRRvRY9e/ZU7Xft2jXB2dlZmDVrltrxwsLCBGdnZyE+Pl4QhL9f75EjR6pqFgRBWLZsmeDs7CxMmzZNtWzNmjVCmzZthNu3b6sdc+nSpUKLFi1UdQmCIDg7OwurVq0q9dqIdI232IiqkB49eiA3NxenTp3C8+fPcfr06RJvrx05cgS1atVCp06dkJGRofrXqlUr1KhRA+fOnSvzeQcOHFjsbZnCfvnlF7x48QIjR44s0gm4oJ+ShYUFAODnn3/WSv+fuLg45OXl4dNPP4VU+vevsw8//BAWFhY4c+aM2vYmJiYICAh47XGzsrJw9uxZ9OjRA8+fP1e9dpmZmfD29sadO3eQmpqqOmbBuRUKBTIzM1GjRg00btwYf/zxh+qYR48ehZWVFYKCgoqcT7Mfl7+/P+rUqaP6vmBIg5SUlNfWXqBTp06oU6cODh06BEEQEBsbi549exa7bcHrNGzYMLXln3/+udr6gtc7KChIrebPPvusyDGPHDmCt99+G7Vr11Z7/3l5eUGhUODChQtlvhYiMfAWG1EVYm1tjY4dO+LgwYPIycmBQqHABx98UOy2d+/exbNnz9CxY8di1xd0ei4LR0fH125T0I+mefPmJW7j5OSEYcOGYdOmTYiJiUG7du3g5+eHPn36VKjz9cOHDwEATZo0UVtuYmICJycnPHjwQG25nZ1dmZ72u3fvHgRBwMqVK7Fy5cpit0lPT4ednR2USiW+++477NixA/fv34dCoVBtY2lpqXbMxo0bw8jo9b927e3t1b4vCEua/apKY2xsjO7du+PgwYPw8PDAo0ePSgzTDx48gFQqVbvNBwC2traoXbu26nUseL0bNWqktp21tbVaoANevf9u3LhR4vtPswM5kb5hQCKqYnr16oU5c+bgyZMn6Ny5M2rXrl3sdkqlEjY2Nli6dGmx662trct8Tm0+Fj59+nT0798fJ06cwC+//IKFCxciMjIS//3vf/HWW29p7TzFMTMzK9N2BZ2IP//8c7z77rvFblMQJtatW4eVK1ciMDAQX3zxBerUqQOpVIqQkBAIglChOktqrSvv8Xr37o1du3YhIiICrq6uaNasWanba/OJRKVSiU6dOmHEiBHFrtcMWUT6hgGJqIp5//33MW/ePFy+fBnLly8vcbsGDRogPj4ebdu2fW0w0MYHY0FgSEpKQsOGDUvdtuBpubFjx+LixYv4+OOPsXPnTkyaNKlc53RwcAAAJCcnw8nJSbVcLpfj/v378PLyKudVvFJwLGNj49ce44cffsA777yDkJAQteVPnz6FlZWV6vsGDRrgypUryMvLK1NHa214++234eDggPPnz2PKlCklble/fn0olUrcvXsXTZs2VS1/8uQJnj59qhrrquD1vnPnjtrrnZGRofZkJPDqel++fFnh/wdEYmMfJKIqpmbNmpg/fz4mTJgAPz+/Erfr0aMHFAoF1q5dW2Rdfn6+2u0ac3Pzct2+KY63tzdq1qyJyMhI5Obmqq0raPl4/vx5kXGcnJ2dIZVKizxOXhZeXl4wNjbG1q1b1VpX9uzZg2fPnqme9isvGxsbdOjQAbt378bjx4+LrC98e0gmkxVp2Tl8+LCqj1KBbt26ITMzE9u3by9yvIq2NL2ORCLBrFmzMH78ePTt27fE7Qpepy1btqgt37Rpk9r6gtd727ZtajVr7ge8ev9dunQJP/30U5F1T58+LfI+INI3bEEiqoL69+//2m06dOiAQYMGITIyEteuXUOnTp1gbGyMO3fu4MiRI5g1axa6d+8OAGjVqhV27tyJtWvXomHDhqq+TuVhYWGBGTNmYPbs2RgwYAB69eqF2rVr4/r168jJycHixYtx9uxZLFiwAN27d0ejRo2gUChw4MAByGSyEvtSlcba2hqjRo3C6tWrMWLECPj5+eH27dvYsWMH3N3d0adPn3Ifs8C8efPwySefoHfv3hg4cCCcnJzw5MkTXL58GX/99Reio6MBAO+99x7WrFmDGTNmwNPTEzdv3kRMTIxaCwsA9OvXD/v370doaCgSEhLw9ttvIzs7G/Hx8fj444/RtWvXCtdamq5du7722K6urujfvz92796Np0+fon379khMTMS+ffvQtWtX/OMf/wDw6vX+/PPPERkZiVGjRsHHxwd//PEHfvzxR7XWMgAYPnw4Tp48idGjR6N///5o1aoVsrOzcfPmTfzwww84ceJEuW7zEukaAxJRNbZgwQK4ublh165dWL58OWQyGerXr48+ffqgbdu2qu3GjRuHhw8fYv369Xjx4gU6dOhQ7oAEvHp6zMbGBt988w3Wrl0LIyMjNGnSBEOHDgXw6taat7c3Tp06hdTUVJibm8PFxQXffvst2rRpU6FrnDBhAqytrbFt2zaEhoaiTp06GDhwIL788ss3upXVrFkzREVFYfXq1di3bx+ysrJgbW2Nli1bYty4cartRo8ejezsbMTExCA2NhYtW7ZEZGQkwsPD1Y4nk8nw7bff4j//+Q8OHjyIo0ePwtLSEm3btlWN6SSmhQsXwtHREfv27cPx48dRt25djBo1CuPHj1fb7l//+hdMTEywa9cunDt3Dh4eHti4cWOReQDNzc2xdetWREZG4siRI9i/fz8sLCzQqFEjTJgwQasjohNVBolQWW27RERERFUU+yARERERaWBAIiIiItLAgERERESkgQGJiIiISAMDEhEREZEGBiQiIiIiDaKOg3ThwgVs2LABv//+O9LS0rBmzZrXDmh27tw5hIWFISkpCfb29hgzZkyR2bm3b9+ODRs2IC0tDa6urpgzZw48PDxU63NzcxEWFobY2FjI5XJ4e3tj3rx5qFu3bplrVyqVyM/Ph1Qq1er8RURERFR5BEGAUqmEkZERpNKS24lEDUgvX76Ei4sLAgMDiwxGVpyUlBSMGjUKH330EZYuXYr4+HjMnj0btra2qgklY2NjERoaiuDgYLRu3RpbtmzB8OHDceTIEdjY2AAAQkJCcObMGaxYsQK1atXCV199hfHjx2PXrl1lrj0/Px+JiYkVu3AiIiISlbu7O0xMTEpcL2pA8vHxKddcSbt27YKjoyOmT58OAGjatCl+++03bN68WRWQNm3ahIEDByIwMBAAEBwcjNOnTyMqKgojR47Es2fPEBUVhaVLl6pGCg4JCYG/vz8uX75c5tF8C1Jny5YtS5x5m4iIiPSLQqHAH3/8UWrrEVDFphq5fPlykekPvL29VbNoy+VyXL16VW3Ie6lUCi8vL1y6dAkA8PvvvyMvL09thummTZvCwcGhXAGp4LbaH3/88SaXRERERCJ4XfeYKhWQnjx5UqSfUN26dfH8+XPk5OTgf//7HxQKhepWWgEbGxskJyerjmFsbIzatWsX2SYtLa3cNbm7u7MFiYiIqIpQKBRl6iJTpQKSPpLJZAxIRERE1UyVCkh169bFkydP1JY9efIEFhYWMDMzg1QqhUwmQ3p6uto26enpqpanunXrIi8vD0+fPlVrRUpPT4etrW3lXwQRERHpvSo1DlKbNm1w9uxZtWVxcXGqfkMmJiZo1aoV4uPjVeuVSiXi4+Ph6ekJAHBzc4OxsbHaNsnJyXj48GGZ+x8RERFR9SZqC9KLFy9w79491ff379/HtWvXUKdOHTg4OCA8PBypqalYsmQJAOCjjz7C9u3bsWTJEgQGBuLs2bM4fPgwIiMjVccYNmwYpk2bBjc3N3h4eGDLli3Izs5WjZVUq1YtBAYGIiwsDHXq1IGFhQUWLlwIT09PBiQiIiICIHJA+v333/Hpp5+qvg8NDQUA9O/fH2FhYUhLS8OjR49U652cnBAZGYnQ0FB89913eOutt7Bw4ULVI/4A4O/vj4yMDKxatQppaWlo0aIF1q9fr9a5e+bMmZBKpZg4caLaQJFEREREACARBEEQu4iqSKFQqIYFYCdtIiKiqqGsn99Vqg8SERERkS4wIBERERFpYEAiIiIi0sCARERERKShSg0UaWgEQUBOTk6p64HS55MxMzN77XwzREREpI4BSU8JgoCRI0eWab6Y0nh4eCAyMpIhiaia4R9QRJWLAUmP8RcX6Rt+KOsH/gFFVPkYkPSURCJBZGRkiR9G2dnZ8Pf3BwDExsbC3Ny82O34YaQdDAb8UNY3fP2IKhcDkh6TSCQlBp/CzM3Ny7QdVQyDwd+qcu3VCf+AIqp8DEik9/Sh9YYfIvxQ1jf8A4qocjEgUanEDif60HrDYPA3figTkaFgQKIS6UM4AfSj9YbBgIjIsDAgUanEDidsvSF9JHbLKhFVPgYkKpG+hBO23pA+0ZeWVSKqXAxIVCqGE9I3+tB6w1BDVP0xIBFRlaEPrTf60rJKRJWLAYmIqhR9CBVsWSWq/hiQiKjKYOsNEekKAxIRVSlsvSEiXZCKXQARERGRvmFAIiIiItLAgERERESkgQGJiIiISAMDEhEREZEGBiQiIiIiDQxIRERERBoYkIiIiIg0MCARERERaWBAIiIiItLAgERERESkgXOxkcETBKHEyU/LIjs7u9ivK4KTqBIR6QcGJDJ4OTk58PX11cqxCmaSr6hTp05xglXSq9AOMLiTYWJAIiIA+vWhbOgfyPoU2gEGdzJMDEgkKn34UC68n99cZ8hMyt81TxAEAKjQh7pCrsTJBTfLvZ+26dOHMj+QiUhsDEgGTF/CiTb+wgW085eyzEQKowoEJKLKIkZoB/QnuBOJhQFJJAwnpM+sbN6DRCIr935v8qEsCApkpp8u937api8/mwUY2onEwYAkEn26naEv8gf5AEbl/1DG/38ooyJ/KecrYLT7TPn3q+YkEhkkkvL/eqgO3Yb4s0lEgB4EpO3bt2PDhg1IS0uDq6sr5syZAw8Pj2K3zcvLQ2RkJPbv34/U1FQ0btwYU6ZMQefOnVXb+Pn54cGDB0X2/eSTTzBv3jwAwJAhQ3D+/Hm19YMGDcKCBQu0eGVVi9CuKyDTcThRKCD59fjf3xvJAOMK1EBERKRlogak2NhYhIaGIjg4GK1bt8aWLVswfPhwHDlyBDY2NkW2X7FiBaKjo7Fw4UI0adIEP/30E8aPH49du3ahZcuWAIA9e/ZAoVCo9klKSsKwYcPQvXt3tWMNHDgQEydOVH0vZodQvbidIZMBMtHzMpFeEaVVEwBy5DCK+rli+xKRVoj6ibhp0yYMHDgQgYGBAIDg4GCcPn0aUVFRGDlyZJHtDxw4gDFjxsDHxwfAq1ah+Ph4bNy4EUuXLgUAWFtbq+3zzTffoEGDBujQoYPacjMzM9ja2lbGZZWbId/OINJrYrVq5rMllUhsogUkuVyOq1evYtSoUaplUqkUXl5euHTpUrH75OXlwcTERG2ZqakpLl68WOI5oqOjMWzYsCKtLDExMYiOjoatrS18fX0xduzYCrUiFW6t0sV+VL0pFArR3hv69J6s6OtQeB9tHINeEfN9SaRtZX0vixaQMjMzoVAoitxKs7GxQXJycrH7eHt7Y/PmzWjfvj0aNGiA+Ph4HDt2rMSLPX78OJ49e4b+/furLe/VqxccHBxQr1493LhxA0uXLsXt27exevXqcl9HYmJiufcBgNzc3ArtR9VbQkICTE1NRTm3Pr0nK/o6FL4GbRyDXhHzfUkklirV6WTWrFmYPXs2evToAYlEAicnJwQEBCAqKqrY7aOiotC5c2fY2dmpLR80aJDqaxcXF9ja2mLo0KG4d+8eGjRoUK6a3N3dIatA52ZtDP9P1Y+Hh4do/eH06T1Z0deh8DVo4xj0ipjvSyJtUygUZWrcEC0gWVlZQSaTIT09XW15eno66tatW+w+1tbWWLt2LXJzc5GVlYV69eph6dKlcHJyKrLtgwcPEBcXh4iIiNfW0rp1awDA3bt3yx2QZDJZhQJSRfah6q+i7ydtnVtfyOXyCtUjl8u1egx6Rcz3JZFYRAtIJiYmaNWqFeLj49G1a1cAgFKpRHx8PIKCgkrd19TUFHZ2dsjLy8PRo0fRo0ePItvs3bsXNjY2eO+9915by7Vr1wBAbzptExk6bYwfxDGIiOhNiHqLbdiwYZg2bRrc3Nzg4eGBLVu2IDs7GwEBAQCAqVOnws7ODpMnTwYAXLlyBampqWjRogVSU1MREREBpVKJESNGqB1XqVRi79696NevH4yM1C/x3r17iImJgY+PDywtLXHjxg2Ehoaiffv2cHV11c2FExERkV4TNSD5+/sjIyMDq1atQlpaGlq0aIH169erbrE9evQIUunfQ+zn5uZixYoVSElJQY0aNeDj44MlS5agdu3aaseNi4vDw4cPVcMHFGZsbIz4+Hh89913ePnyJezt7dGtWzeMHTu2ci+WiMpFLwYvJSKDJXon7aCgoBJvqW3dulXt+w4dOiA2Nva1x/T29saNGzeKXWdvb49t27aVv1Ai0i0OXkpEIuIMiEREREQaGJCIiIiINLD9moiIqixBEJCTk/PabYDS5600MzOr0LyWVH0xIBERUZUkCAJGjhxZ4RkNCvPw8EBkZCRDEqnwFhsREVVZDDRUWdiCREREVZJEIkFkZGSpt9iys7NVg4bGxsaWOGUKb7GRJgYkIiKqsiQSSZnniTM3N+ecclRmvMVGREREpIEBiYiIiEgDAxIRERGRBgYkIiIiIg3spE1ERPQGOFhl9cSAREREVEEcrLL6YkAiIiJ6Aww0f3tda1pVakljQCIiIqogDlb5N221pulLSxoDEhER0RvgYJV/EzvUaBMDEhEREb2x17WmVbWWNAYkIiIi0oqytqZVhZY0joNEREREpIEBiYiIiEgDb7ERERFVA9XpEXt9wIBERERUxVW3R+z1AW+xERERVQMMNdrFFiQiIqIqrro9Yq8PGJCIiIiqger0iL0+4C02IiIiIg0MSEREREQaGJCIiIiINDAgEREREWlgQCIiIiLSwIBEREREpIEBiYiIiEgDAxIRERGRBgYkIiIiIg0MSEREREQaGJCIiIiINHAuNiIiPaaQKw3qvET6ggFJDwiCQvxzKvJ1XoMo5ySqYk4uuCl2CUQGSfSAtH37dmzYsAFpaWlwdXXFnDlz4OHhUey2eXl5iIyMxP79+5GamorGjRtjypQp6Ny5s2qbiIgIrF69Wm2/xo0b48iRI6rvc3NzERYWhtjYWMjlcnh7e2PevHmoW7du5Vzka2SmnxblvIVJfj0hdgmkR/QitBMRiUjUgBQbG4vQ0FAEBwejdevW2LJlC4YPH44jR47AxsamyPYrVqxAdHQ0Fi5ciCZNmuCnn37C+PHjsWvXLrRs2VK1XfPmzbFp0ybV9zKZTO04ISEhOHPmDFasWIFatWrhq6++Uh2HiPQjtLNV8xW/uc6Qmei+u6hCrmTrFRk0UQPSpk2bMHDgQAQGBgIAgoODcfr0aURFRWHkyJFFtj9w4ADGjBkDHx8fAMAnn3yC+Ph4bNy4EUuXLlVtJ5PJYGtrW+w5nz17hqioKCxduhQdO3YE8Cow+fv74/Lly2jTpo2Wr/L1rGzeg0Qie/2GWiQICrUPQaFdF0Cm47eDIl/vWq7E6HfBvh7F07f3hlhkJlIYiRCQiAydaAFJLpfj6tWrGDVqlGqZVCqFl5cXLl26VOw+eXl5MDExUVtmamqKixcvqi27e/cuvL29YWpqijZt2mDy5MlwcHAAAPz+++/Iy8uDl5eXavumTZvCwcGhQgFJoajYbYHC+0kkMkgkIt/tlBnpPiDpIbH/YlYoFBV+T2nj3AX0IbST/hDzffmmCtct1nWwBv2pQbOO0oj2iZiZmQmFQlHkVpqNjQ2Sk5OL3cfb2xubN29G+/bt0aBBA8THx+PYsWNqF+vh4YHQ0FA0btwYaWlpWLNmDQYPHoyYmBhYWFjgyZMnMDY2Ru3atYucNy0trdzXkZiYWO59gFf9oIg0JSQkwNTUVJRzF35P6kNoZ6um/hDzffmmCr+vxboO1qA/NZRHlWoymDVrFmbPno0ePXpAIpHAyckJAQEBiIqKUm1TcPsNAFxdXdG6dWv4+vri8OHD+PDDD7Vek7u7e5E+TmWRnZ2t9VrozYnR36NwXw8PDw+Ym5vr9PwF9O49yVZNvSHm+/JNFX5fi3UdrEF/agBetSCVpXFDtN8+VlZWkMlkSE9PV1uenp5e4tNk1tbWWLt2LXJzc5GVlYV69eph6dKlcHJyKvE8tWvXRqNGjXDv3j0AQN26dZGXl4enT5+qtSKlp6eX2G+pNDKZrEIBqSL7VHv5IjS3apxT7P4eFX0/aevcRMUR8335pgrXLdZ1sAb9qaE8RAtIJiYmaNWqFeLj49G1a1cAgFKpRHx8PIKCgkrd19TUFHZ2dsjLy8PRo0fRo0ePErd98eIFUlJSVOHHzc0NxsbGiI+PxwcffAAASE5OxsOHD0XpoE1/M9p9RuwSiIiIAIh8i23YsGGYNm0a3Nzc4OHhgS1btiA7OxsBAQEAgKlTp8LOzg6TJ08GAFy5cgWpqalo0aIFUlNTERERAaVSiREjRqiOuXjxYvj6+sLBwQGPHz9GREQEpFIpevXqBQCoVasWAgMDERYWhjp16sDCwgILFy6Ep6cnAxIREREBEDkg+fv7IyMjA6tWrUJaWhpatGiB9evXq26xPXr0CFLp37c7cnNzsWLFCqSkpKBGjRrw8fHBkiVL1G6V/fXXX/jyyy+RlZUFa2trvP322/jvf/8La2tr1TYzZ86EVCrFxIkT1QaKJHHlD/IBjHTc5JqvYMsVEREVIXoPyKCgoBJvqW3dulXt+w4dOiA2NrbU4y1fvvy15zQ1NcW8efMYivSNkQww1u970kREZBg4+hgRERGRBtFbkIhI/1R0XjRBEAAAEolEZ+ckIqoMDEhEVARHtCYiQ8eApAf41zoREZF+YUDSA/xrnfSBmZkZTp06VeH9s7Oz4e/vDwCIjY2t0Ci5hY9BRCQmBiQiAvCqJVJbQ/+bm5tX2akpiIgABiTR8K91oipAjOlvxDwvEakwIImEf60T6T8OIkpkuDgOEhEREZEGtiAREZVAlOlvACBHDqOon3V/XiJSYUAiIiqJWNPf5HPKHSKxMSARFaKQKyu035uMSVXRcxIRUeVhQCIq5OSCm2KXQEREeoABiYiIiF5LEATk5ORUeP/s7Oxiv64IMzOzCrXYlwcDEtH/08Z4UhU9RgEzM7MK70tEVJlycnLg6+urlWO96Rh8p06dqvThbRiQiP6fNsaT4phUpG1i9It7k/MSVRcMSEREeoz94kgf+c11hsyk/EMpvukDLbr8eWBAIiIionKRmUhhVIGAVJUwINErigrO/fT/fw2gIs34FT0nka5UdE60N/m5KLw/KtavTZv94gD2jSPDxIBEAADJr8fFLoFI7+jDXGxv2q+N/eKIKoYBifSHGH+tc9Z0IiIqBgOSATMzM8OpU6cqvL82mvELH0Mf/lonKqAPwz4AvL1FJBYGJAMmkUi01vTOZnyqbjjsA5FhY0AiUelDK1bhWoiI9M2bjmANaGcU6zcd/bqqYUAiUbEVi4iodNocwRp481GsDUX1HsSAiIiIqALYgkRERFRF5A/yAYxkFdv5DZ/4NbQHaRiQiIiIqgojGWBcwYBE5cJbbEREREQaGJCIiIiINDAgEREREWlgHyQi0k+cQJmIRMSARER6iRMoE5GYeIuNiIiISANbkIhIb3DqGdI3+jDNh6FN8aEvGJCISG9w6hnSN5zmw3AxIBERkV5i6w2JiQGJiIj0kr613gjtugIyEab5kMshuVTxW89UMaJ30t6+fTv8/Pzg7u6ODz/8EAkJCSVum5eXh9WrV6Nr165wd3dHnz598OOPP6ptExkZicDAQHh6eqJjx44YO3YskpOT1bYZMmQIXFxc1P7NnTu3Uq6PiIiqCZkMkBlV7J+R8at/Fdpf9I9qgyRqC1JsbCxCQ0MRHByM1q1bY8uWLRg+fDiOHDkCGxubItuvWLEC0dHRWLhwIZo0aYKffvoJ48ePx65du9CyZUsAwPnz5zF48GC4u7tDoVBg2bJlGD58OA4dOoQaNWqojjVw4EBMnDhR9T37KhAR6S8rm/cgkVSs9Ub4/9YbSQVab5RKObIyfqrQealqEzWWbtq0CQMHDkRgYCCaNWuG4OBgmJmZISoqqtjtDxw4gNGjR8PHxwdOTk745JNP4OPjg40bN6q22bBhAwICAtC8eXO4uroiLCwMDx8+xNWrV9WOZWZmBltbW9U/CwuLSr1WIiKqOIlEBonEqEL/pFJjSKXGFdyfE8MaKtFakORyOa5evYpRo0aplkmlUnh5eeHSpUvF7pOXlwcTExO1Zaamprh48WKJ53n27BkAoE6dOmrLY2JiEB0dDVtbW/j6+mLs2LEVakVSiDTybuHzKhQKUepgDfpTgz7Qh9eBNehPDdpQVeumyvcm7+uy7idaQMrMzIRCoShyK83GxqZIn6EC3t7e2Lx5M9q3b48GDRogPj4ex44dK/FilUolQkJC0LZtWzg7O6uW9+rVCw4ODqhXrx5u3LiBpUuX4vbt21i9enW5ryMxMbHc+2hDbm6u6uuEhASYmpqyBgOuQR/ow+vAGvSnBm0ofB1EhenifV2lnmKbNWsWZs+ejR49ekAikcDJyQkBAQEl3pILDg5GUlISduzYobZ80KBBqq9dXFxga2uLoUOH4t69e2jQoEG5anJ3d4esok81vIHCj556eHiI0oeKNehPDfpAH14H1qA/NWgDH7GnkrzJ+1qhUJSpcUO0gGRlZQWZTIb09HS15enp6ahbt26x+1hbW2Pt2rXIzc1FVlYW6tWrh6VLl8LJyanItgsWLMDp06exbds2vPXWW6XW0rp1awDA3bt3yx2QZDKZKAGp8DlZA2vQB/rwOrAG/alBG6pq3VT5dPG+Fq2TtomJCVq1aoX4+HjVMqVSifj4eHh6epa6r6mpKezs7JCfn4+jR4+iS5cuqnWCIGDBggU4duwYtmzZUmx40nTt2jUAgK2tbQWvhoiIiKoTUW+xDRs2DNOmTYObmxs8PDywZcsWZGdnIyAgAAAwdepU2NnZYfLkyQCAK1euIDU1FS1atEBqaioiIiKgVCoxYsQI1TGDg4Nx8OBBrF27FjVr1kRaWhoAoFatWjAzM8O9e/cQExMDHx8fWFpa4saNGwgNDUX79u3h6uqq+xeBiIiI9I6oAcnf3x8ZGRlYtWoV0tLS0KJFC6xfv151i+3Ro0eQSv9u5MrNzcWKFSuQkpKCGjVqwMfHB0uWLEHt2rVV2+zcuRPAq8EgCwsNDUVAQACMjY0RHx+P7777Di9fvoS9vT26deuGsWPH6uCKiYiIqCoQvZN2UFAQgoKCil23detWte87dOiA2NjYUo9348aNUtfb29tj27Zt5SuSiIiIDArHLyciIiLSwIBEREREpIEBiYiIiEgDAxIRERGRBgYkIiIiIg0MSEREREQaGJCIiIiINDAgEREREWlgQCIiIiLSUO6RtB89egSJRIK33noLAJCQkICYmBg0a9YMgwYN0nqBRERERLpW7hakyZMn4+zZswCAtLQ0DBs2DImJiVi+fDlWr16t9QKJiIiIdK3cASkpKQkeHh4AgMOHD6N58+bYtWsXli5din379mm9QCIiIiJdK3dAys/Ph4mJCQAgLi4Ofn5+AIAmTZogLS1Nu9URERERiaDcAalZs2bYtWsXfv31V8TFxaFz584AgMePH8PS0lLb9RERERHpXLkD0pQpU7B7924MGTIEPXv2hKurKwDg5MmTqltvRERERFVZuZ9ie+edd3D27Fk8f/4cderUUS0fOHAgzM3NtVocERERkRgqNA6SIAi4evUqdu3ahefPnwMAjI2NYWZmptXiiIiIiMRQ7hakBw8eYMSIEXj06BHkcjk6deoECwsLfPvtt5DL5ViwYEFl1GmQBEFATk5Oseuys7OL/VqTmZkZJBKJ1msjIiKqzsodkBYtWgQ3NzccOHAA77zzjmr5+++/jzlz5mi1OEMmCAJGjhyJxMTE127r7+9f4joPDw9ERkYyJBEREZVDuQPSb7/9hp07d6oe9S9Qv359pKamaq0wAkMNERGRSModkJRKJZRKZZHlf/31F2rWrKmVouhVOIqMjCzxFhvwqpWpYNuS8BYbERFR+ZU7IHXq1AlbtmzBV199pVr24sULREREwMfHR6vFGTqJRMInA4mIiERQ7qfYpk+fjosXL8Lf3x9yuRxTpkyBn58fUlNTMWXKlMqokYiIiEinyt2C9NZbb+HAgQM4dOgQbty4gZcvX2LAgAHo3bs3H/MnIiKiaqHcAQkAjIyM0LdvX23XQkRERKQXyh2Q9u/fX+r6fv36VbAUIiIiIv1QoXGQCsvPz0d2djaMjY1hbm7OgETVEgftJCIyLOUOSBcuXCiy7M6dO5g/fz6GDx+ulaKI9AkH7SQiMjwVmotNU6NGjTB58uQirUtE1QVDDRGRYalQJ+1iD2RkhMePH2vrcER6g4N2EhEZnnIHpBMnTqh9LwgC0tLSsH37drRt21ZrhRHpEw7aSURkWModkMaNG6f2vUQigbW1Nf7xj39g2rRpWiuM9AM7J1NhfD8QkaEod0C6fv16ZdRBeoidk6kwvh+IyJBopZM2VV/8EKPC+H4gIkNRphak0NDQMh9wxowZFS6G9As7J1NhfD/oF97uJKpcZQpIf/zxR5kOxh+06oedk6kwvh/0A293ElW+MgWkrVu3VnYdRERUDgw1RJVLa+MgERGRbvB2J1Hlq1BASkxMxOHDh/Ho0SPk5eWprVu9enW5jrV9+3Zs2LABaWlpcHV1xZw5c+Dh4VHstnl5eYiMjMT+/fuRmpqKxo0bY8qUKejcuXO5jpmbm4uwsDDExsZCLpfD29sb8+bNQ926dctVOxGRWHi7k6hylfsptkOHDuHjjz9GcnIyjh07hvz8fCQlJeHs2bOoVatWuY4VGxuL0NBQjBs3Dvv27YOrqyuGDx+O9PT0YrdfsWIFdu/ejTlz5iA2NhYfffQRxo8fr9ZHqizHDAkJwalTp7BixQps3boVjx8/xvjx48v7UhAREVE1Ve6AtG7dOsyYMQPr1q2DsbExZs2ahSNHjqBHjx6wt7cv17E2bdqEgQMHIjAwEM2aNUNwcDDMzMwQFRVV7PYHDhzA6NGj4ePjAycnJ3zyySfw8fHBxo0by3zMZ8+eISoqCtOnT0fHjh3h5uaGkJAQXLp0CZcvXy7vy0E6IAgCsrOzS/xXoLRtCm43EBERlUW5b7GlpKTAx8cHAGBiYoKXL19CIpFg6NCh+OyzzzBx4sQyHUcul+Pq1asYNWqUaplUKoWXlxcuXbpU7D55eXkwMTFRW2ZqaoqLFy+W+Zi///478vLy4OXlpdqmadOmcHBwwOXLl9GmTZsy1V9AoVCUa3sqH0EQMGbMGK08rbN27Vr2t6jmCv88KhQKUX4+9aGG6oKvHZXkTX62yrpfuQNS7dq18eLFCwBAvXr1kJSUBBcXFzx9+rTU8TY0ZWZmQqFQwMbGRm25jY0NkpOTi93H29sbmzdvRvv27dGgQQPEx8fj2LFjqostyzGfPHkCY2Nj1K5du8g2aWlpZa6/QFk+uKniBEFQvd/exPPnz3H58mUGpGouNzdX9XVCQgJMTU0NsobqovBrSVSYLn62yhyQbt68CWdnZ7Rv3x5xcXFwcXFB9+7dsWjRIpw9exZxcXHo2LFjZdaKWbNmYfbs2ejRowckEgmcnJwQEBBQ4i05XXB3d4dMJhPt/Ibgu+++49M6VCaF/0jz8PAQpROzPtRQXZTnj24yLG/ys6VQKMrUuFHmgNSnTx+4u7uja9eu6N69OwBgzJgxMDY2xsWLF9GtWzeMGTOmzAVaWVlBJpMV6ZCdnp5e4tNk1tbWWLt2LXJzc5GVlYV69eph6dKlcHJyKvMx69ati7y8PDx9+lStFSk9PR22trZlrr+ATCZjQNIBCwsLsUugKqDwz6JYP5v6UEN1wdeOSqKLn60yd9Letm0bmjVrhsjISPj7+2PatGm4ePEiRo4ciXXr1mH69OmoU6dOmU9sYmKCVq1aIT4+XrVMqVQiPj4enp6epe5ramoKOzs75Ofn4+jRo+jSpUuZj+nm5gZjY2O1bZKTk/Hw4cNy9z8iIiKi6qnMLUjt2rVDu3btMGfOHBw+fBj79u1DUFAQGjZsiMDAQPTv37/cLTDDhg3DtGnT4ObmBg8PD2zZsgXZ2dkICAgAAEydOhV2dnaYPHkyAODKlStITU1FixYtkJqaioiICCiVSowYMaLMx6xVqxYCAwMRFhaGOnXqwMLCAgsXLoSnpycDEhEREQGoQCftGjVqIDAwEIGBgbh79y727t2LHTt2YNWqVfD29sa6devKfCx/f39kZGRg1apVSEtLQ4sWLbB+/XrV7bBHjx5BKv27kSs3NxcrVqxASkoKatSoAR8fHyxZskTtVtnrjgkAM2fOhFQqxcSJE9UGiiQiIiIC3nCqkYYNG2LUqFFwcHDAsmXLcObMmXIfIygoCEFBQcWu05wDrkOHDoiNjX2jYwKvbtHNmzePoYiIiIiKVeGAdOHCBURFReGHH36AVCpFjx49MGDAAG3WRkRERCSKcgWk1NRU7Nu3D/v27cPdu3fh6empeuy+Ro0alVUjERERkU6VOSCNGDEC8fHxsLKyQt++fREYGIgmTZpUZm1EREREoihzQDIyMsLKlSvh6+vLsSmIiIioWitzQCrP02lEREREVVmZB4okIiIiMhQMSEREREQaGJCIiIiINDAgEREREWlgQCIiIiLSwIBEREREpIEBiYiIiEgDAxIRERGRhgpPVktEJAZBEJCTk1Psuuzs7GK/1mRmZgaJRFKlayCiysWARERVhiAIGDlyJBITE1+7rb+/f4nrPDw8EBkZWaGAog81EFHl4y02IqpS9CFQ6EMNRFS52IJERFWGRCJBZGRkibe3gFctPAXbluRNbm/pQw1EVPkYkIioSpFIJDA3Nzf4GoiocvEWGxEREZEGBiQiIiIiDQxIRERERBoYkIiIiIg0MCARERERaWBAIiIiItLAgERERESkgeMgERERlYUiX6TzKsQ5r4FjQCIiIioDya8nxC6BdIi32IiIiIg0sAWJiIioDIR2XQCZCB+b8lxILp3W/XkNHAMSERFRWciMxAlIMpH6PpVCIVdW+3MyIBERkd4TBHE6Kot1Xn13csFNsUuodAxIRESk9zLTT4tdAhkYBiQiIiIqF7+5zpCZ6PY5L4VcqdOWKwYkIiLSe1Y270Eiken8vEqlHFkZP+n8vPpOZiKFkY4Dkq4xIBERkd6TSGSQSHT/kSWRsA+Soare8Y+IiIioAhiQiIiIiDTwFhsREVFVkS/SLT+xzisi0QPS9u3bsWHDBqSlpcHV1RVz5syBh4dHidtv3rwZO3fuxKNHj2BlZYUPPvgAkydPhqmpKQDAz88PDx48KLLfJ598gnnz5gEAhgwZgvPnz6utHzRoEBYsWKDFKyMiItIuo91nxC7BYIgakGJjYxEaGorg4GC0bt0aW7ZswfDhw3HkyBHY2NgU2T4mJgbh4eEICQmBp6cn7ty5g+nTp0MikWDGjBkAgD179kBRaObjpKQkDBs2DN27d1c71sCBAzFx4kTV9+bm5pV0lURERFTViBqQNm3ahIEDByIwMBAAEBwcjNOnTyMqKgojR44ssv2lS5fQtm1b9O7dGwDg6OiIXr164cqVK6ptrK2t1fb55ptv0KBBA3To0EFtuZmZGWxtbd/4GgqHMSIi0h7+fi0qf5APYKT74Q6Qr9Cr1iuFQlHh90dZ9xMtIMnlcly9ehWjRo1SLZNKpfDy8sKlS5eK3cfT0xPR0dFISEiAh4cHUlJScObMGfTt27fEc0RHR2PYsGGQSCRq62JiYhAdHQ1bW1v4+vpi7NixFWpFSkxMLPc+RET0erm5uWKXoH+MZICxCAFJzyQkJKi61lQW0QJSZmYmFApFkVtpNjY2SE5OLnaf3r17IzMzE5988gkEQUB+fj4++ugjjB49utjtjx8/jmfPnqF///5qy3v16gUHBwfUq1cPN27cwNKlS3H79m2sXr263Nfh7u4OmYxvViIibcvOzha7BNJTHh4eFe4ao1AoytS4IXon7fI4d+4cIiMjMW/ePHh4eODevXtYtGgR1qxZg3HjxhXZPioqCp07d4adnZ3a8kGDBqm+dnFxga2tLYYOHYp79+6hQYMG5apJJpMxIBERVQL+bqWS6OKzV7RxkKysrCCTyZCenq62PD09HXXr1i12n5UrV6JPnz748MMP4eLigvfffx+TJk3CN998A6VSqbbtgwcPEBcXhwEDBry2ltatWwMA7t69W8GrISIioupEtIBkYmKCVq1aIT4+XrVMqVQiPj4enp6exe6Tk5MDqVS95IIEKQiC2vK9e/fCxsYG77333mtruXbtGgBopdM2ERERVX2i3mIbNmwYpk2bBjc3N3h4eGDLli3Izs5GQEAAAGDq1Kmws7PD5MmTAQC+vr7YtGkTWrZsqbrFtnLlSvj6+qo1tSmVSuzduxf9+vWDkZH6Jd67dw8xMTHw8fGBpaUlbty4gdDQULRv3x6urq66u3giIiLSW6IGJH9/f2RkZGDVqlVIS0tDixYtsH79etUttkePHqm1GI0ZMwYSiQQrVqxAamoqrK2t4evri0mTJqkdNy4uDg8fPlQNH1CYsbEx4uPj8d133+Hly5ewt7dHt27dMHbs2Mq9WCIiIqoyRO+kHRQUhKCgoGLXbd26Ve17IyMjjB8/HuPHjy/1mN7e3rhx40ax6+zt7bFt27aKFUtEREQGgZPVEhEREWlgQCIiIiLSwIBEREREpIEBiYiIiEgDAxIRERGRBgYkIiIiIg2iP+ZPRET0OoKgeIN9X820IJFIdHpeqtoYkIiISO9lpp8WuwQyMLzFRkRERKSBLUhERKSXzMzMcOrUqTc6RnZ2Nvz9/QEAsbGxMDc3r/D+ZFgYkIiISC9JJJJyB5rSmJuba/V4VL3xFhsRERGRBgYkIiIiIg0MSEREREQaGJCIiIiINDAgEREREWlgQCIiIiLSwIBEREREpIEBiYiIiEgDAxIRERGRBgYkIiIiIg0MSEREREQaOBdbJRAEAfn5+VAoFGKXQnrK2NgYMplM7DKIiKgEDEhaJpfL8ejRI7x8+VLsUkiPSSQSODo6wsLCQuxSiIioGAxIWqRUKnH79m3IZDI4ODjAxMQEEolE7LJIzwiCgLS0NNy/fx/NmzdnSxIRkR5iQNIiuVwOpVIJJycn1KhRQ+xySI/Z2trizp07yMvLY0AiItJD7KRdCaRSvqxUOrYsEhHpN36SExEREWlgQCKdadeuHc6dO1embYcMGYLNmzdXbkFEREQlYECiIoYMGQIXFxfExcWpLV+/fj1cXFywaNEikSojIiLSDXbSpmI1btwYUVFR8PLyUi3bu3cvmjRpImJVREQGLv8NxtcThFf/rUgfyDc5bxXFgETF6tmzJ7Zu3Ypnz56hVq1auHLlCgCgdevWqm0SExOxaNEi/Pnnn6hXrx7Gjh2LXr16AXg15MGqVavw3//+F1KpFGPGjClyjkOHDmHdunV49OgRGjZsiFmzZqFt27ZFtsvKysKsWbNw/vx5CIKABg0aICIiAvXr16+kqyci0k9Gu8+IXYLB4C02KlatWrXw7rvv4uDBgwCAqKgoBAQEqNY/ffoUI0aMQM+ePREfH4/58+djzpw5+O233wC8am3at28ftm7dimPHjuH333/HixcvVPufOXMGixcvRlhYGM6fP49Ro0ZhzJgxyMzMLFLLxo0boVAo8OOPP+LcuXNYtGgRatasWcmvABERGTK2IFGJAgICsGLFCvTv3x8//PADDh48iPDwcADA6dOnYW1tjSFDhgAAOnTogF69emH//v14++23ERMTg6CgIDRt2hQAMHnyZOzdu1d17O3bt2P48OFo1aoVAKBbt27YuHEjzpw5g379+qnVYWRkhKysLNy9exeurq5o0aKFDq6eiEhPSP8eKy02Nhbm5ublPkR2djb8/f21dgxDwIBEJerYsSNmzZqFtWvXwtPTE7a2tqp1f/31V5FbXE5OTrhw4QIA4PHjx2rr69atCxMTE9X3Dx48wPLlyxEREaFalp+fj8ePHxepY/jw4cjNzcUXX3yB58+fo0ePHpgyZQrMzMy0dq1ERK/1JvNrvkn/H6VS9aW5uXmFwk1h2jiGIWBAohJJpVL069cP69atw6pVq9TWvfXWW3jw4IHasvv37+Ott94CANSrV09tfXp6OuRyudr+QUFB+Pjjj19bR82aNfHvf/8b//73v5GSkoIxY8Zgx44d+Pzzz9/k8oiIykXy63GxSyAdYh8kKtXQoUOxceNG+Pr6qi338fFBRkYGtm/fjvz8fPz666+IiYlB3759AQC9evXCjh07kJycjJycHISHh6uNMD548GBs2LABv//+OwRBQHZ2NuLi4vDXX38VqeHUqVO4ffs2lEolLCwsYGRkxOk5iIioUonegrR9+3Zs2LABaWlpcHV1xZw5c+Dh4VHi9ps3b8bOnTvx6NEjWFlZ4YMPPsDkyZNhamoKAIiIiMDq1avV9mncuDGOHDmi+j43NxdhYWGIjY2FXC6Ht7c35s2bh7p161bORVZhlpaWao/6F6hTpw6+/fZbhISEYNmyZahXrx7mz5+Pdu3aAQACAwNx//59DB48GDKZDKNHj8bRo0dV+/v5+SE3Nxdz5sxBSkoKTExM4OHhgblz5xY51927d7Fw4UKkp6ejRo0a6NatW5lanoiI3pSZmRlOnTr1RsfQRv+fwvWQbogakGJjYxEaGorg4GC0bt0aW7ZswfDhw3HkyBHY2NgU2T4mJgbh4eEICQmBp6cn7ty5g+nTp0MikWDGjBmq7Zo3b45NmzapvtdsbQgJCcGZM2ewYsUK1KpVC1999RXGjx+PXbt2Vd7FViFbt24tcV1YWJjqaw8PjxJfM6lUikmTJmHSpEmqZUFBQWrb9OjRAz169HhtDUOHDsXQoUPLUjoRkVZJJBKt9tdh/5+qQ9RbbJs2bcLAgQMRGBiIZs2aITg4GGZmZoiKiip2+0uXLqFt27bo3bs3HB0d4e3tjV69eiEhIUFtO5lMBltbW9U/a2tr1bpnz54hKioK06dPR8eOHeHm5oaQkBBcunQJly9frszLJSIioipCtBYkuVyOq1evYtSoUaplUqkUXl5euHTpUrH7eHp6Ijo6GgkJCfDw8EBKSgrOnDmj6vdS4O7du/D29oapqSnatGmDyZMnw8HBAQDw+++/Iy8vT+22UdOmTeHg4IDLly+jTZs25boORaGnGhQKBQRBUP0jKknBe0ShUKi9h4hIuzR/R4vx81ZdatCn31Vv8jqWdT/RAlJmZiYUCkWRW2k2NjZITk4udp/evXsjMzMTn3zyCQRBQH5+Pj766COMHj1atY2HhwdCQ0PRuHFjpKWlYc2aNRg8eDBiYmJgYWGBJ0+ewNjYGLVr1y5y3rS0tHJfR2Jiotr3RkZGyM7OhrLQY5lEmnJzc5GXl4fr16+LXQpRtZabm6v6OiEhQdVflTWUv4bCxxCbLl5H0Ttpl8e5c+cQGRmJefPmwcPDA/fu3cOiRYuwZs0ajBs3DsCrp6sKuLq6onXr1vD19cXhw4fx4Ycfar0md3d3VR+nnJwc3L17F+bm5uxIR6WSSqUwNjZGs2bN+F4hqkTZ2dmqrz08PETp/1Ndaih8DLG9yeuoUCiKNG4UR7SAZGVlBZlMhvT0dLXl6enpJT5NtnLlSvTp00cVdFxcXPDy5UvMnTsXY8aMUXuMvEDt2rXRqFEj3Lt3D8CrAQvz8vLw9OlTtVak9PR0tYEQy0omk6kCkkwmg0QiUf0jKknBe6Tw+4eItK/wz5dYP2/VpQZ9+l2li9dRtE7aJiYmaNWqFeLj41XLlEol4uPj4enpWew+OTk5RUJQwQtUUp+fFy9eICUlRRV+3NzcYGxsrHbe5ORkPHz4sNz9j4iIiKh6EvUW27BhwzBt2jS4ubnBw8MDW7ZsQXZ2tmpS1KlTp8LOzg6TJ08GAPj6+mLTpk1o2bKl6hbbypUr4evrqwpKixcvhq+vLxwcHPD48WNERERAKpWqZpmvVasWAgMDERYWhjp16sDCwgILFy6Ep6dnpQWkgs7b2lbQAkFERETaJWpA8vf3R0ZGBlatWoW0tDS0aNEC69evV91ie/TokVqL0ZgxYyCRSLBixQqkpqbC2toavr6+amPt/PXXX/jyyy+RlZUFa2trvP322/jvf/+r9qj/zJkzIZVKMXHiRLWBIiuDQqFAr169kZmZofVjW1lZ4+DBGIYkIiLSKYW8Yg8iFTQWVKQbSkXPWVGid9IOCgoqMoBgAc0BC42MjDB+/HiMHz++xOMtX778tec0NTXFvHnzKi0UFSYIAjIzM2BdtysAbfZLEpDx5HiFW6beeecdREVFwdHRUYs1vZqPrV+/fvj111+LrEtNTcWkSZOwY8eOch83ICAA06ZNwzvvvKONMomI6A2cXHBT7BIqnegByXBIIJFor8uXIFS9YQTs7OwqFI6IiIh0jQHJQJw4cQJLly6FkZER3n33XdXyO3fuICQkBOnp6ZDL5Rg0aJCqRS8hIQFLly7F8+fPoVQqMWrUKPTo0UPVSvThhx/i559/hlKpxKxZs9QG31y8eHGRdZqtSy4uLpg0aRKOHz+OjIwMjBs3DoGBgQCAixcvIjg4GAqFAu7u7no1QBkRkSF603npqtqcdAxIBiA9PR0zZ87E9u3b0axZM+zevRtZWVlQKpX48ssv8fXXX6Np06bIzs7GwIED4eHhgUaNGmHu3Ln45ptvUK9ePWRkZCAgIABt27YF8GrKliZNmmDatGm4fPkyxowZg2PHjr12nSYTExPs2bMHt27dwoABA9C3b18olUpMmjQJoaGh8PLyws8//4y9e/fq7PUiIqKitDkvXVWYk44ByQBcvnwZzs7OaNasGQBgwIAB+OqrryCXy/Hnn3/iyy+/VG374sUL3Lp1C5mZmUhJScE///lPtWMlJyfDyckJRkZGqqcN27Rpg3r16uHatWuwt7cvdZ2m3r17A3g13YuRkRGePHmCrKwsyGQyVYuUt7c3nJyctP/CEBERlYAByQAVPD0gCALq1KmDAwcOFNnm9OnTaN68OXbt2lVk3f3790s9bnnWFR4qXiqVIj8/v9zHJiIi0jbRBoo0PAIEQam1f0DZn17z9PTEzZs3cevWLQBAVFQU8vLyYGJiAgsLC0RFRam2vXv3LrKysuDp6Yn79+8jLi5Ote7atWuQy+UAgPz8fFWwSkhIwOPHj+Hq6vradWXRpEkTKBQKnD17FgAQFxenGgmdiIhIF9iCVMkkEgmsrKyR8eS41o9tZWVdppYVa2trLFq0COPHj4exsTHeffddWFpaQiaTITIyEiEhIdi8eTOUSiWsrKwQHh4OOzs7REZGYvHixQgLC0N+fj7s7e2xdu1aAK8G3ExKSkKfPn2gUCgQHh4OCwsLZGVllbquLExMTLB8+XIEBwdDqVTCzc2tXAGLiIjoTTEgVTKZTIaDB2NEH0m7a9eu6Nq1q+r7f//736qv161bV+w+rVq1wnfffVfiMadNm1ZkmaOjY7FjIBW37saNG2rrz507p/q6bdu2xd76IyIi0gUGJB3gSNdERERVC/sgUbmV1kpERERUHTAgEREREWlgQCIiIiLSwIBEREREpIGdtHVAoVCI/hQbERERlR0DUiVTKBTo2bs3sjIytH5sS2trHIqJYUgiIiLSMgakSiYIArIyMiC80x3Q5nQZgoCsc0cq3DL1zjvvICoqCo6OjtqrCa+mIenXr1+xT7mlpqZi0qRJ2LFjR7mPGxAQgGnTpuGdd97RRplERESlYkDSFYkEkGqxy5dSqb1j6YidnV2FwhEREZGusZO2gThx4gR69OiB3r17Y8mSJarld+7cwciRIxEYGIjevXtj27ZtqnUJCQn49NNPERAQgH79+uHw4cMAXrUStWvXDosXL0bv3r3Rs2dPtTnbABS7rmC/Ai4uLli3bh0GDBgAPz8/tTnhLl68iL59+6JXr16YMWMGFArFa6/xp59+wscff4yAgAAMGDBANZfb7NmzsWDBAgBAVlYWunbtigsXLgAA/Pz8sHjxYgQEBOD999/H+vXry/W6EhFR9cQWJAOQnp6OmTNnYvv27WjWrBl2796NrKwsKJVKfPnll/j666/RtGlTZGdnY+DAgfDw8ECjRo0wd+5cfPPNN6hXrx4yMjIQEBCAtm3bAgCePXuGJk2aYNq0abh8+TLGjBmDY8eOvXadJhMTE+zZswe3bt3CgAED0LdvXyiVSkyaNAmhoaHw8vLCzz//jL1795Z6jSkpKVi9ejU2bNgACwsL3L17F4MHD8bJkycxZ84cDBw4EIcPH8aBAwfw4Ycfon379mqvT1RUFDIzM1XXWHCdRERkmBiQDMDly5fh7OyMZs2aAQAGDBiAr776CnK5HH/++Se+/PJL1bYvXrzArVu3kJmZiZSUFPzzn/9UO1ZycjKcnJxgZGSEgIAAAECbNm1Qr149XLt2Dfb29qWu09S7d28AQNOmTWFkZIQnT54gKysLMpkMXl5eAABvb284OTmVeo0//vijKhQVkEgkePjwIRo1aoSVK1ciMDAQbdq0wciRI9X2HTBgACQSCaytrfH+++8jLi6OAYmIyMAxIOmKIGi339AbDBsg+f/O4oIgoE6dOsVOCnv69Gk0b94cu3btKrLu/v37pR63POtMTU1VX0ulUuTn55f72AU6deqE8PDwYtfdvn0b5ubmyMjIQF5eHkxMTMpdKxERGQ72QapkEokEltbWkJw7AsnZw9r7d+7Iq+OW4cPc09MTN2/exK1btwAAUVFRqpBgYWGh1vfn7t27yMrKgqenJ+7fv6/Wt+jatWuQy+UAgPz8fFWwSkhIwOPHj+Hq6vradWXRpEkTKBQKVR+iuLg43Lt3r9R9vL29ERcXh+vXr6uWJSQkAAAePnyI4OBgbN68Ga1bt8aiRYvU9t23bx+AV/2Tjh8/jo4dO5a5ViIiqp7YglTJZDIZDsXEiDpQpLW1NRYtWoTx48fD2NgY7777LiwtLSGTyRAZGYmQkBBs3rwZSqUSVlZWCA8Ph52dHSIjI7F48WKEhYUhPz8f9vb2WLt2LQCgVq1aSEpKQp8+faBQKBAeHg4LCwtkZWWVuq4sTExMsHz5cgQHB0OpVMLNze21Aathw4YIDw/HvHnzkJ2djby8PLRs2RKLFy/Gl19+iS+++ALNmjXDzJkz8dFHHyE2Nhb+/v4AACsrKwQEBODZs2cYPHgwb68REREkQmV8chsAhUKBy5cvo02bNqqQkpOTg9u3b6Nx48YwMzMTucLKU9pYR1WNn58f1qxZgxYtWuj0vIbyXiESW3Z2Nnx9fQEAp06dgrm5OWsw4BqA4j+/i8MWJCIiqrIEQUBOTk6J67Ozs4v9WpOZmRn7H5IaBiQqN0dHR9Faj0aPHo1Hjx6pLatduza2bt1aoeOdPHlSG2URkQgEQcDIkSORmJhYpu0LbqsXx8PDA5GRkQxJpMKARFXKunXrxC6BiPQIAw1VFgYkIiKqkiQSCSIjI0u9xQZA9ZBMaWGKt9hIEwMSERFVWRKJRLTOvlS9MSDpgEKhEPUxfyIiIiofBqRKplAo0LNPb2SlZ2j92JY21jgUHcOQREREpGUMSJVMEARkpWcgP8gPkGrx/rZSQNa2k2VqmXJxccGFCxdQu3Zt7Z2/GBEREXj69ClmzZqFEydO4Ny5c5g5c2alnpOIiKgyMCDpilQCSLU5s4sW53WrBF26dEGXLl3ELoOIiKhCGJAMxIYNG3DmzBlkZ2dj3Lhx6NOnDwBg8uTJuH37NvLy8mBvb49FixbB1tYWGRkZmDJlCtLS0gAAbm5uCA0NVR3r8OHDUCgUsLa2xoIFC1C/fn218+3duxfHjx/H2rVrce7cOXz11Vdo164dLl68CIVCgbCwMLi7uwMAfvrpJ6xduxa5ubmQSqWYMmUK/vGPf5R4Lc+ePUNYWBiuXLkCqVSKVq1aITQ0FBEREbh16xZycnJw79491K1bF6tWrYKlpSX27t2L6OhoWFtbIykpCcbGxli5ciWcnJwq4+UmIqIqjgHJQEgkEuzfvx8pKSkIDAxE27Zt4ejoiFmzZsHa2hoA8M033yAiIgILFixAdHQ0HB0dsXHjRgBQzaMWExOD27dvY/fu3ZDJZNi/fz+Cg4PxzTfflHr+5ORkLFq0CPPnz8fOnTuxYsUKbNiwASkpKVi9ejU2bNgACwsL3L17F4MHD8bJkydhYmJS7LFCQkJgamqK6OhoSKVSZGT83b8rISEBUVFRsLKywqRJk7B7926MGjUKAJCYmIj9+/fDyckJS5cuxbfffosFCxa86UtLRETVEAOSgfjwww8BAE5OTmjXrh1+/fVXODo6IiYmBgcOHIBcLkdubi6srKwAAK1bt8bmzZsRFhaGdu3aoXPnzgCA48ePIzExEQEBAQAApbJst/oaNGiA1q1bAwA8PT1VwevHH39UhaICEokEDx8+RKNGjYo91qlTp/D9999D+v+3LAsCHgB4e3urrqFNmza4efOmal2bNm1ULUZt2rTBtm3bylQ7EREZHgYkA/brr79i69at2L17N2xsbHDixAmsWrUKwKsQs3//fsTFxeHYsWNYuXIl9u/fD0EQMGrUKAwaNKhc5zI1NVV9LZVKoVAoVN936tQJ4eHhWrmmwueRyWRq5yltHRERvbnS5saravPiMSDpilKAVjtWK8s3rtLevXsxYcIE3L9/H7/99htmzpyJmzdvombNmrC0tIRcLsfu3btV26ekpMDOzg7+/v7o3LkzOnbsiJcvX6Jr167YtGkTPvjgA1haWiIvLw9JSUlo2bJlhS7D29sbq1evxvXr1+Hq6grg1W0yDw+PEvfx8/PDhg0bMHfuXNUttsKtSEREpHvlmRuvKsyLJ3pA2r59OzZs2IC0tDS4urpizpw5pX44bt68GTt37sSjR49gZWWFDz74AJMnT1a1DkRGRuLo0aNITk6GmZkZPD09MWXKFDRp0kR1jCFDhuD8+fNqxx00aFCl9EeRSCSwtLFG1jbtT4pqaWNd5jeQQqFAv379kJ2djVmzZsHR0RF2dnaIjo5G9+7dYWlpCS8vL6SmpgIAzp8/j82bN6tae6ZOnYpatWqhT58+yMrKwqeffqo6bmBgYIUDUsOGDREeHo558+YhOzsbeXl5aNmyZaktSjNnzkRISAh69+4NIyMjuLu7Y+HChRU6PxHRmyqt1QSoei0nb6Kq11+YRKiMIZ7LKDY2FlOnTkVwcDBat26NLVu24MiRIzhy5AhsbGyKbB8TE6P6cPT09MSdO3cwffp09OzZEzNmzAAADB8+HD179oS7uzsUCgWWLVuGpKQkHDp0CDVq1ADwKiA1atQIEydOVB3b3NwcFhYWZa5doVDg8uXLaNOmjWqgxpycHNy+fRuNGzeGmZmZ2rYcSZsKK+m9QkRVS3laTV6nMltOsrOz4evrC+BVP87Kmp7ldWFRH+bFK+7zuziitiBt2rQJAwcORGBgIAAgODgYp0+fRlRUFEaOHFlk+0uXLqFt27bo3bs3AMDR0RG9evXClStXVNts2LBBbZ+wsDB07NgRV69eRfv27VXLzczMYGtrWxmXVQRDDBFR9VWdWk3eVHWaG0+0gCSXy3H16lXVI9jAq867Xl5euHTpUrH7eHp6Ijo6WtVHJSUlBWfOnEHfvn1LPM+zZ88AAHXq1FFbHhMTg+joaNja2sLX1xdjx46t0P/Uwh19C1qKCv5RxZ05cwbLly8vsnzkyJGl3ruuKgreIwqFgp3Fiaq4tWvXltpqApS95aSsTwaXl+ZnlSH/3inrtYsWkDIzM6FQKIrcSrOxsUFycnKx+/Tu3RuZmZn45JNPIAgC8vPz8dFHH2H06NHFbq9UKhESEoK2bdvC2dlZtbxXr15wcHBAvXr1cOPGDSxduhS3b9/G6tWry30dms2qRkZGyM7OrrQ3uaFo3749duzYUey6ly9f6rga7cvNzUVeXh6uX78udilEZAByc3NVXyckJKg91UvFE72TdnmcO3cOkZGRmDdvHjw8PHDv3j0sWrQIa9aswbhx44psHxwcjKSkpCIftIUfUXdxcYGtrS2GDh2Ke/fuoUGDBuWqyd3dXa0P0t27d2Fubs5+JVQqqVQKY2NjNGvWjO8VIqp0hTuHe3h4VJvbYBWhUCjK1GdMtIBkZWUFmUyG9PR0teXp6emoW7dusfusXLkSffr0UQ166OLigpcvX2Lu3LkYM2aMauBAAFiwYAFOnz6Nbdu24a233iq1loIBDO/evVvugCSTyVQBSSaTQSKRqP4RlaTgPVL4/UNEVFkK/57h752y0ebsqeViYmKCVq1aIT4+XrVMqVQiPj4enp6exe6Tk5OjFoKAv/+nF9zfFQQBCxYswLFjx7Bly5YyzbV17do1ANBZp20iIiLSb6LeYhs2bBimTZsGNzc3eHh4YMuWLcjOzlZNYzF16lTY2dlh8uTJAABfX19s2rQJLVu2VN1iW7lyJXx9fVVBKTg4GAcPHsTatWtRs2ZN1WSrtWrVgpmZGe7du4eYmBj4+PjA0tISN27cQGhoKNq3b68aqFDb+Jg/ERFR1SJqQPL390dGRgZWrVqFtLQ0tGjRAuvXr1fdYnv06JFai9GYMWMgkUiwYsUKpKamwtraGr6+vpg0aZJqm507dwJ4NdZRYaGhoQgICICxsTHi4+Px3Xff4eXLl7C3t0e3bt0wduzYSrlGhUKB3n17I+NJxus3LifrutaIORDDkERERKRlog4UWZWVdaDI/Px8eHt7o9tCV0hk2uuXJCgEHJ19HT///DOMjErPuS4uLrhw4QJq166ttfMXJyIiAk+fPsWsWbNw4sQJnDt3DjNnzqzUc1ZVHCiSiLTtdfOgFQyREhsbW2In7eowmvfrVImBIg2JRCaBVIsBSd8HEejSpQu6dOkidhlERAahus2Dpg8YkAzEhg0bcObMGWRnZ2PcuHHo06cPAGDy5Mm4ffs28vLyYG9vj0WLFsHW1hYZGRmYMmWKqg+Xm5sbQkNDVcc6fPgwFAoFrK2tsWDBAtSvX1/tfHv37sXx48exdu1anDt3Dl999RXatWuHixcvQqFQICwsDO7u7gCAn376CWvXrkVubi6kUimmTJmCf/zjHyVey7NnzxAWFoYrV65AKpWiVatWCA0NRUREBG7duoWcnBzcu3cPdevWxapVq2BpaYm9e/ciOjoa1tbWSEpKgrGxMVauXFlqJ/7nz58jLCwM169fR25uLtq0aYM5c+bg/v37GDp0KLZv3w4nJyds2LABcXFx+Pbbb7F//37s378fNWrUwL1792BlZYXFixfD0dHxjf7/ERG9DkONdjEgGQiJRIL9+/cjJSUFgYGBaNu2LRwdHTFr1ixYW1sDAL755htERERgwYIFiI6OhqOjIzZu3AgAyMrKAvBqBPLbt29j9+7dkMlk2L9/P4KDg/HNN9+Uev7k5GQsWrQI8+fPx86dO7FixQps2LABKSkpWL16NTZs2AALCwvcvXsXgwcPxsmTJ2FiYlLssUJCQmBqaoro6GhIpVJkZPzdvyshIQFRUVGwsrLCpEmTsHv3btVo7YmJidi/fz+cnJywdOlSfPvtt6VOULx48WK0a9cOCxcuhCAImD17Nr777juMGDECU6dOxRdffIFp06Zh+/bt2LNnj6q/3MWLF3HgwAE0bdoU3377LebOnat6HYmIKoNEIkFkZKTez4NWlTAgGYiCsaOcnJzQrl07/Prrr3B0dERMTAwOHDgAuVyO3NxcWFlZAXg1NtTmzZsRFhaGdu3aoXPnzgCA48ePIzExUfWkYVlHDG/QoIFqvClPT09VYPjxxx9VoaiARCLBw4cP0ahRo2KPderUKXz//feqQFIQ8ADA29tbdQ1t2rTBzZs3VevatGmjajFq06YNtm3bVmrNx48fx+XLl7Fp0yYAr/oNFdyv7tWrF86dO4fhw4dj8+bNajV4enqiadOmAF4NSrpy5UooFAp2pieiSlWd5kHTBwxIOiIoBK32GxIUb963/tdff8XWrVuxe/du2NjY4MSJE1i1ahWAVx/y+/fvR1xcHI4dO4aVK1di//79EAQBo0aNUhuNvCwKD2svlUrV5sLp1KkTwsPD3/h6NM8jk8nUzlPauuIIgoBVq1ahcePGRdbl5+cjKSkJlpaWePz4sRYqJyIifcKAVMkkEgms61rj6Gztz7llXde6zE2he/fuxYQJE3D//n389ttvmDlzJm7evImaNWvC0tIScrkcu3fvVm2fkpICOzs7+Pv7o3PnzujYsSNevnyJrl27YtOmTfjggw9gaWmJvLw8JCUloWXLlhW6Bm9vb6xevRrXr19XjUNVMBlxSfz8/LBhwwbMnTtXdYutcAuOtnTt2lV1G87IyAj/+9//kJWVhYYNGyI8PByNGzfG4sWL8emnn6JVq1Zo2LAhAODy5cu4desWmjZtiu+//x7vvPMOW4+IiKoYBqRKJpPJEHMgRvSBIhUKBfr164fs7GzMmjULjo6OsLOzQ3R0NLp37w5LS0t4eXkhNTUVAHD+/Hls3rxZ1dozdepU1KpVC3369EFWVhY+/fRT1XEDAwMrHJAKwsa8efOQnZ2NvLw8tGzZstQWpZkzZyIkJAS9e/eGkZER3N3dsXDhwgqdvzQzZsxAeHg4+vXrB4lEAiMjI/z73/9GcnIyfvrpJ3z//fcwNzfH9OnT8a9//Qu7du0C8Kr1benSpbh37x4sLS2xePFirddGRESVi+MgVVBZx0Eiw1L46b3S8L1CRCSOso6DJNpcbERERET6irfYSC+dOXMGy5YtK7J81KhRpQ5yJvZ5AgICVE/4ERFR1cWAVAl41/LN+fj4wMfHp9qcRxPfI0RE+o232LTI2NgYAPDy5UuRKyF9J5fLAYBPtxER6Sm2IGmRTCZTGxenRo0aHJGUilAqlUhLS0ONGjVeO9EwERGJg7+dteytt94CAA4eSKWSSqVo0KABAzQRkZ5iQNIyiUQCe3t71KtXD3l5eWKXQ3rKxMRENVUKERHpHwakSiKTydi/hIiIqIrin7BEREREGtiCVEEFj2m/bsJTIiIi0h8Fn9uvG26FAamClEolACAxMVHkSoiIiKi8Cj7HS8K52CpIqVQiPz8fUqmUTyIRERFVEYIgQKlUwsjIqNSHZRiQiIiIiDSwkzYRERGRBgYkIiIiIg0MSEREREQaGJCIiIiINDAgEREREWlgQCIiIiLSwIBEREREpIEBiYiIiEgDAxIRERGRBgYkIqJS5OTkiF0CEYmAAYl06vnz58VOEKhQKPD8+XMRKiIqnlwux8aNG9GlSxexSyED5Ofnh9WrV+Phw4dil2KwGJBIZ44dO4bAwEDk5uYWWZebm4vAwECcPHlShMrIUMnlcoSHhyMgIAAfffQRjh8/DgCIioqCn58ftmzZgs8++0zkKskQffrppzh27Bi6du2KYcOG4dChQ5DL5WKXZVA4WS3pzOeff44ePXrgww8/LHb9nj17cPjwYWzYsEHHlZGh+vrrr7F79254eXnh4sWLyMzMREBAAC5fvozRo0eje/fukMlkYpdJBuzq1avYt28fDh48CKVSiV69eiEwMBCtWrUSu7RqjwGJdMbb2xvbt29Hw4YNi11/9+5dDB48GD///LOOKyND1aVLF8ycORNdunTBzZs30adPH/Tv3x8hISGQSCRil0ekkpeXhx07dmDp0qXIz8+Hs7MzhgwZgsDAQL5XK4mR2AWQ4Xj69Cny8/NLXJ+fn4+nT5/qsCIydKmpqXBzcwMAODs7w8TEBEOHDuUHDumNvLw8HDt2DHv37kVcXBxat26NAQMG4K+//sLy5csRHx+P8PBwscuslhiQSGfq16+P33//HU2bNi12fWJiIhwcHHRcFRkyhUIBY2Nj1fcymQw1atQQsSKiV65evYq9e/fi4MGDkEql6NevH2bMmKH2+/P999/HgAEDRKyyemNAIp3p1q0bVqxYgU6dOqFu3bpq69LS0rBy5Ur06dNHpOrIEAmCgOnTp8PExATAq07b8+fPh7m5udp2q1evFqM8MmADBgyAl5cX5s+fj65du6oF+QKOjo7o2bOnCNUZBvZBIp15/vw5PvroIzx8+BB9+vRB48aNAQDJycmIiYmBvb09du/eDQsLC5ErJUMxY8aMMm0XGhpayZUQqXvw4AHq168vdhkGjQGJdOrZs2cIDw/H4cOH8b///Q8AULt2bfj7+2PSpEmoU6eOyBUSEYkvISEBgiCgdevWasuvXLkCqVQKd3d3kSozHAxIJApBEJCZmQlBEGBtbc1OsSSa+/fvIy4uDnl5eejQoQOaN28udklEGDBgAEaMGIHu3burLT969Ci+/fZbfP/99yJVZjjYB4lEcePGDdy5cwcA0LhxY7i4uIhbEBmks2fPYvTo0arpRIyMjLBo0SL07dtX5MrI0N26davYsY5atGiBP//8U4SKDA8DEulUQkICZs2ahT///BMFjZcSiQTNmjXDokWL4OHhIXKFZEhWrlyp6ghramqKFStW4Ouvv2ZAItGZmJjgyZMncHJyUluelpYGIyN+dOsCpxohnfnzzz/x2WefwdTUFF9//TX27duHffv2YcmSJarxZ/iXEelSUlISvvzyS9SrVw916tTB1KlTkZGRgczMTLFLIwPXqVMnLFu2DM+ePVMte/r0KZYvXw4vLy8RKzMc7INEOvPFF19AoVAgIiKiSJ8jQRAwfvx4GBkZYeXKlSJVSIbG1dUVv/zyC2xsbFTLPD09ER0dXeQvdyJdSk1NxeDBg5GVlYUWLVoAAK5fvw4bGxts2rQJ9vb2IldY/bGdjnTm3Llz+Pbbb4vtkC2RSDBq1CiMHDlShMrIkP3000+oVauW6ntBEBAfH4+bN2+qlnXp0kWM0siA2dnZITo6GjExMbh+/TrMzMwQGBiInj17FjsmEmkfW5BIZ9zd3XH06NES//J59OgRunXrhsTERB1XRobK1dX1tdtIJBJcu3ZNB9UQkT5hCxLpjIODAxISEkoMSFeuXOFUI6RT169fF7sEolL9+eefePjwIfLy8tSWs1Wz8jEgkc707NkTYWFhaNy4MZydndXW3bhxA0uWLOHTQ0REAFJSUjBu3DjcvHkTEolE7alfAGzV1AHeYiOdyc3NxWeffYaEhAR4eXmhadOmEAQBt27dQnx8PDw8PLBlyxaYmpqKXSoZiO+++67Y5bVq1UKjRo3g6emp44qIXhk9ejSkUikWLlyILl26YM+ePcjMzMTixYsxbdo0tGvXTuwSqz0GJNIpuVyOzZs349ChQ6qBIhs1aoSePXti6NChqklDiXTBz8+v2OXPnj3Ds2fP4Onpif/85z+wtLTUbWFk8N555x1s2bIFrq6uePvtt/H999+jSZMmiI+Px+LFi7F//36xS6z2eIuNdMrExAQjR47k02qkF06ePFniupSUFPz73//GihUrMH/+fN0VRQRAqVSiZs2aAAArKys8fvwYTZo0Qf369XH79m2RqzMMHCiS9Mbjx4+xYMECscsgAgA4OTlh8uTJ+OWXX8QuhQxQ8+bNcePGDQBA69atsX79evz2229Ys2YNx+jSEbYgkU4lJSXh3LlzMDY2Ro8ePVC7dm1kZGTgP//5D3bv3s0ffNIr9vb2ePLkidhlkAEaM2YMsrOzAQATJ07EqFGjMHjwYFhaWmL58uUiV2cY2AeJdObEiRP44osvkJ+fD+DVX+hfffUV/vWvf6FVq1b47LPP0LlzZ5GrJPrbyZMnER4ejkOHDoldChGysrJQp06dYgfbJe1jQCKdGTBgANq2bYsvvvgC33//PcLCwtC8eXNOUkuief78ebHLnz17hqtXryIsLAz9+vXD+PHjdVwZGbK8vDy0bt0a+/fvLzIkCukOb7GRzty+fRvh4eGoWbMmhgwZgiVLlmDGjBkMRySadu3alfjXuEQiwYABA/hAAemcsbEx7O3toVQqxS7FoDEgkc68ePECFhYWAACZTAZTU1P2OSJRlTQOkoWFBRo2bIiaNWvi5s2b/CuedG706NFYtmwZlixZwmEmRMKARDpVeGLQ4iYFBTiEPulOhw4dil3+/PlzHDx4EHv27MHvv//OUYtJ57Zv3467d+/i3XffhYODA2rUqKG2ft++fSJVZjjYB4l0hhODkr67cOEC9uzZg6NHj6JevXp4//330a1bN94GJp1bvXp1qevZL67yMSARkUFLS0vDvn37sGfPHjx//hw9evTArl27cODAATRr1kzs8ohIJLzFRkQGa/To0bhw4QLee+89zJw5E++++y5kMhl27doldmlEJDIGJNIZTgxK+ubHH3/EkCFD8PHHH6NRo0Zil0Ok4urqWup4R+yKUPkYkEhnNm/eXOxyTgxKYtmxYwf27NmDgIAANG3aFH379oW/v7/YZREV6YOUn5+Pa9euYd++fZgwYYJIVRkW9kEivVAwMairqysnBiWde/nyJWJjYxEVFYXExEQoFApMnz4dgYGBqqEpiPRBTEwMYmNj8Z///EfsUqo9BiTSGxcuXMDMmTNx7NgxsUshA5acnIw9e/YgOjoaT58+hZeXF9atWyd2WUQAXv0x2adPH1y6dEnsUqo9qdgFEBXgxKCkD5o0aYKpU6fizJkzWLZsmdjlEKnk5OTgu+++Q7169cQuxSCwDxLpjZs3b8LBwUHsMogAvBrtvWvXrujatavYpZABat++vVonbUEQ8OLFC5iZmeHrr78WsTLDwYBEOlPWiUGJiAzdjBkz1AKSRCKBtbU1WrdujTp16ohYmeFgHyTSmdIeWy2YGHT27NkwMTHRcWVERETqGJBIZ86fP1/sck4MSkSkLioqCjVq1ECPHj3Ulh8+fBg5OTno37+/SJUZDgYkEt3z589x6NAhTgxKRPT/PvjgAwQHB+Mf//iH2vLz589jzpw5+OGHH0SqzHCwDxKJpriJQefMmSN2WUREonv48CEcHR2LLHdwcMCjR49EqMjwMCCRThU3MahcLseaNWs4MSgR0f+zsbHBjRs3ioSk69evc7YBHWFAIp3hxKBERGXTs2dPLFq0CDVr1kT79u0BvLq9FhISgp49e4pcnWFgQCKd4cSgRERl88UXX+DBgwcYOnQojIxefVQrlUr07dsXkyZNErk6w8CARDrDiUGJiMrGxMQEK1aswJ07d3Dt2jWYmZnB2dkZ9evXF7s0g8Gn2EjnODEoERHpOwYkEhUnBiUiKmrChAlwd3fHyJEj1ZZ/++23SExMxKpVq0SqzHBwsloSFScGJSIq6sKFC/Dx8SmyvHPnzvj1119FqMjwsA8S6QVODEpE9LeXL1/C2Ni4yHIjI6MS57Uk7WILEhERkZ5xdnZGbGxskeWxsbEcM05H2IJERESkZ8aOHYsJEyYgJSVFNd1IfHw8Dh48yP5HOsJO2kRERHro9OnTWLduHa5fvw5TU1O4urpi/PjxqFOnDif11gEGJCIiIj33/PlzHDx4EHv27MHVq1c5qbcOMCARERHpqeIm9e7WrRs8PDzELq3aYx8kIiIiPcJJvfUDAxIREZGe4KTe+oMBiYiISE9wUm/9wXGQiIiI9MSOHTvw4sULBAQE4MMPP8S2bduQkZEhdlkGiZ20iYiI9Awn9RYfAxIREZEe46Te4mBAIiIiqgIUCgVOnTqFPXv2MCDpAAMSERERkQZ20iYiIiLSwIBEREREpIEBiYiIiEgDAxIRERGRBgYkIqJycnFxwfHjx8Uug4gqEQMSEVVJ06dPh4uLC+bOnVtkXXBwMFxcXDB9+vQyHevcuXNwcXHB06dPy7T9zz//jM6dO5erXiKqWhiQiKjKsre3R2xsLHJyclTLcnNzcfDgQTg4OGj9fHK5HABga2sLExMTrR+fiPQHAxIRVVktW7aEvb09jh49qlp29OhR2Nvbo0WLFqplSqUSkZGR8PPzg4eHB/r06YMjR44AAO7fv49PP/0UANC+fXu1lqchQ4ZgwYIFWLRoEd555x0MHz4cQNFbbH/99Re+/PJLdOjQAW3atEFAQACuXLkCALh+/TqGDBkCT09PtG3bFgEBAUhMTKzcF4aI3piR2AUQEb2JwMBA7N27F3369AEAREVFISAgAOfPn1dtExkZiejoaAQHB6NRo0a4cOEC/v3vf8Pa2hpvv/02IiIiMGHCBBw5cgQWFhYwMzNT7btv3z58/PHH2LlzZ7Hnf/HiBYKCgmBnZ4e1a9fC1tYWV69ehVKpBABMmTIFLVq0wPz58yGTyXDt2jUYGxtX4itCRNrAgEREVVqfPn0QHh6OBw8eAAAuXryIZcuWqQKSXC5HZGQkNm3aBE9PTwCAk5MTfvvtN+zevRsdOnRAnTp1AAA2NjaoXbu22vEbNWqEqVOnlnj+gwcPIiMjA3v27IGlpSUAoGHDhqr1Dx8+xPDhw9G0aVPV8YhI/zEgEVGVZm1tjffeew/79u2DIAh47733YG1trVp/9+5dZGdn4/PPP1fbLy8vT+02XElatWpV6vpr166hZcuWqnCkadiwYZg9ezYOHDgALy8vdO/eHQ0aNHj9hRGRqBiQiKjKCwwMxIIFCwAA8+bNU1v38uVLAK9us9nZ2amtK0tHa3Nz81LXF74dV5wJEyagV69eOHPmDH788UesWrUKy5cvx/vvv//acxOReNhJm4iqvHfffRd5eXnIz8+Ht7e32rqmTZvCxMQEDx8+RMOGDdX+2dvbA4CqT5BCoSj3uV1cXHDt2jVkZWWVuE3jxo0xdOhQbNy4Ed26dUNUVFS5z0NEusUWJCKq8mQyGQ4fPqz6ujALCwt8/vnnCA0NhSAIePvtt/Hs2TNcvHgRFhYW6N+/P+rXrw+JRILTp0/Dx8cHpqamqFmzZpnO3bNnT6xbtw7jxo3Dl19+iXr16uGPP/5AvXr10KJFCyxZsgQffPABHB0d8ddffyExMRHdunXT+mtARNrFgERE1YKFhUWJ6/71r3/B2toakZGRuH//PmrVqoWWLVti9OjRAAA7OztMmDAB4eHhmDFjBvr164ewsLAyndfExAQbN27E4sWLMXLkSCgUCjRt2hTz5s2DVCpFVlYWpk2bhidPnsDKygrdunXDxIkTtXLNRFR5JIIgCGIXQURERKRP2AeJiIiISAMDEhEREZEGBiQiIiIiDQxIRERERBoYkIiIiIg0MCARERERaWBAIiIiItLAgERERESkgQGJiIiISAMDEhEREZEGBiQiIiIiDf8HtDLVNx+Ze6oAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load data from CSV\n",
    "df = pd.read_csv('perf_data_10rbps.csv', index_col=0)\n",
    "\n",
    "# Reshape the DataFrame to have a single column for variable names\n",
    "df_melted = df.melt(id_vars='Model', value_vars=['AUROC', 'AUPR', 'Accuracy'], var_name='Metric')\n",
    "\n",
    "# Create a bar plot with Seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.boxplot(x='Metric', y='value', hue='Model', data=df_melted, palette='viridis')\n",
    "\n",
    "# Customize the plot by setting labels and a title\n",
    "ax.set(xlabel='Metrics', ylabel='Values')\n",
    "ax.set_title('Metrics for each Model')\n",
    "\n",
    "# Display the legend\n",
    "ax.legend(title='Models', title_fontsize='9', fontsize='8')\n",
    "\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better visibility\n",
    "\n",
    "plt.savefig(\"metrics_plot.svg\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, callbacks, activations, optimizers\n",
    "\n",
    "directory_path = \"/home/pgarcia/rbp_project/models_deepbind2\"\n",
    "sal_maps = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for file_path in os.listdir(directory_path):\n",
    "    data_path = os.path.join(directory_path, file_path)\n",
    "\n",
    "    # Check if the item is a file (not a subdirectory)\n",
    "    if os.path.isfile(data_path):\n",
    "\n",
    "        # Process the file here\n",
    "        print(\"Processing:\", file_path)\n",
    "\n",
    "        # Load models\n",
    "        model = model.load_model(file_path)\n",
    "\n",
    "        '''Generate Saliency maps'''\n",
    "\n",
    "        # get the pre-activated outputs\n",
    "        layer = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-2].output) \n",
    "\n",
    "        #get model predictions for test sequences\n",
    "        predictions = model.predict(x_test)\n",
    "\n",
    "        # Get the top num_plots predictions\n",
    "        num_plots = 10\n",
    "\n",
    "        # Get the sorted indices\n",
    "        sorted_indices = np.argsort(predictions[:, 0])[::-1]\n",
    "\n",
    "        # Extract the top num_plots sequences\n",
    "        X = x_test[sorted_indices[:num_plots]]\n",
    "\n",
    "        # Reshape X to (num_plots, 200, 4)\n",
    "        X = X.reshape((num_plots, 200, 4))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #########################################################\n",
    "        import tensorflow as tf\n",
    "\n",
    "        @tf.function\n",
    "        def calculate_saliency_map(X, model, class_index=0):\n",
    "            '''fast function to generate saliency maps'''\n",
    "            if not tf.is_tensor(X):\n",
    "                X = tf.Variable(X)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch(X)\n",
    "                output = model(X)[:,class_index]\n",
    "            return tape.gradient(output, X)\n",
    "\n",
    "        # calculate saliency maps\n",
    "        saliency_map = calculate_saliency_map(X, layer)\n",
    "        saliency_map = saliency_map.numpy()\n",
    "        # gradient correction\n",
    "        saliency_map -= np.mean(saliency_map, axis=2, keepdims=True)\n",
    "\n",
    "        #########################################################\n",
    "        import pandas as pd\n",
    "        import logomaker\n",
    "\n",
    "        def plot_saliency_map(scores, alphabet, ax=None):\n",
    "            L,A = scores.shape\n",
    "            counts_df = pd.DataFrame(data=0.0, columns=list(alphabet), index=list(range(L)))\n",
    "            for a in range(A):\n",
    "                for l in range(L):\n",
    "                    counts_df.iloc[l,a] = scores[l,a]\n",
    "\n",
    "            if not ax:\n",
    "                ax = plt.subplot(1,1,1)\n",
    "            logomaker.Logo(counts_df, ax=ax)\n",
    "\n",
    "\n",
    "        saliency_scores = saliency_map * X\n",
    "        for scores in saliency_scores:\n",
    "            fig = plt.figure(figsize=(20,1))\n",
    "            ax = plt.subplot(1,1,1)\n",
    "            plot_saliency_map(scores, alphabet, ax)\n",
    "\n",
    "            sal_maps_dict = {\n",
    "                \"Exp\": [file_path],\n",
    "                \"Model\": [m_func.__name__],\n",
    "                \"sal_maps\": plot_saliency_map(scores, alphabet, ax)\n",
    "            }\n",
    "\n",
    "            # Convert dictionary to DataFrame\n",
    "            sal_maps_dict = pd.DataFrame(performance_data)\n",
    "\n",
    "            # Add new rows to DataFrame\n",
    "            sal_maps = pd.concat([sal_maps, sal_maps_dict], ignore_index=True)\n",
    "\n",
    "            plt.savefig(\"myimg2.svg\", dpi=300)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, callbacks, activations, optimizers\n",
    "\n",
    "directory_path = \"/home/pgarcia/rbp_project/models_deepbind2\"\n",
    "sal_plots = []\n",
    "\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for file_path in os.listdir(directory_path):\n",
    "    data_path = os.path.join(directory_path, file_path)\n",
    "\n",
    "    # Check if the item is a file (not a subdirectory)\n",
    "    if os.path.isfile(data_path):\n",
    "\n",
    "        # Process the file here\n",
    "        print(\"Processing:\", file_path)\n",
    "\n",
    "        # Load models\n",
    "        model = model.load_model(file_path)\n",
    "\n",
    "        '''Generate Saliency maps'''\n",
    "\n",
    "        # get the pre-activated outputs\n",
    "        layer = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-2].output) \n",
    "\n",
    "        #get model predictions for test sequences\n",
    "        predictions = model.predict(x_test)\n",
    "\n",
    "        # Get the top num_plots predictions\n",
    "        num_plots = 10\n",
    "\n",
    "        # Get the sorted indices\n",
    "        sorted_indices = np.argsort(predictions[:, 0])[::-1]\n",
    "\n",
    "        # Extract the top num_plots sequences\n",
    "        X = x_test[sorted_indices[:num_plots]]\n",
    "\n",
    "        # Reshape X to (num_plots, 200, 4)\n",
    "        X = X.reshape((num_plots, 200, 4))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #########################################################\n",
    "        import tensorflow as tf\n",
    "\n",
    "        @tf.function\n",
    "        def calculate_saliency_map(X, model, class_index=0):\n",
    "            '''fast function to generate saliency maps'''\n",
    "            if not tf.is_tensor(X):\n",
    "                X = tf.Variable(X)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch(X)\n",
    "                output = model(X)[:,class_index]\n",
    "            return tape.gradient(output, X)\n",
    "\n",
    "        # calculate saliency maps\n",
    "        saliency_map = calculate_saliency_map(X, layer)\n",
    "        saliency_map = saliency_map.numpy()\n",
    "        # gradient correction\n",
    "        saliency_map -= np.mean(saliency_map, axis=2, keepdims=True)\n",
    "\n",
    "        #########################################################\n",
    "        import pandas as pd\n",
    "        import logomaker\n",
    "\n",
    "        def plot_saliency_map(scores, alphabet, ax=None):\n",
    "            L,A = scores.shape\n",
    "            counts_df = pd.DataFrame(data=0.0, columns=list(alphabet), index=list(range(L)))\n",
    "            for a in range(A):\n",
    "                for l in range(L):\n",
    "                    counts_df.iloc[l,a] = scores[l,a]\n",
    "\n",
    "            if not ax:\n",
    "                ax = plt.subplot(1,1,1)\n",
    "            logomaker.Logo(counts_df, ax=ax)\n",
    "\n",
    "\n",
    "        saliency_scores = saliency_map * X\n",
    "        for scores in saliency_scores:\n",
    "            fig = plt.figure(figsize=(20,1))\n",
    "            ax = plt.subplot(1,1,1)\n",
    "            plot_saliency_map(scores, alphabet, ax)\n",
    "\n",
    "            sal_plots.append(fig) \n",
    "            fig.savefig(\"myimg_test.pdf\", format='pdf', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rbp_models import deepbind_test\n",
    "\n",
    "\n",
    "def deepbind_test():\n",
    "    #Build the model\n",
    "    model = models.Sequential()\n",
    "    #layer1\n",
    "    model.add(layers.InputLayer(input_shape=(200, 4))) # 4 channel input\n",
    "    #layer2\n",
    "    model.add(layers.Conv1D(filters=16, kernel_size=24, padding='same'))\n",
    "    model.add(layers.Activation(activations.relu))\n",
    "    #layer3\n",
    "    model.add(layers.MaxPooling1D(pool_size=25))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(units=32, activation='relu')) #model says \"one hidden layer with 32 ReLu units\"?\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Dense(units=1, activation='linear'))\n",
    "    model.add(layers.Activation('sigmoid'))\n",
    "    \n",
    "    \n",
    "    #print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "model = deepbind_test()\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from rbp_models import deepbind_test, deepbind_exp_test, repre_test, repre_exp_test\n",
    "#rbp_models_list = [deepbind_test, deepbind_exp_test, repre_test, repre_exp_test]\n",
    "rbp_model_paths_list = [\n",
    "    \"/home/pgarcia/rbp_project/models_deepbind2/HNRNPK_K562_200.h5 + deepbind_exp_test\",\n",
    "    \"/home/pgarcia/rbp_project/models_deepbind2/HNRNPK_K562_200.h5 + deepbind_test\"\n",
    "]\n",
    "for i, path in enumerate(rbp_model_paths_list):\n",
    "    # model = m_func() # call function to create model\n",
    "    # load model weights\n",
    "    # model_path = rbp_model_paths_list[i]\n",
    "    # model.load_weights(model_path)\n",
    "    model = tf.keras.models.load_model(path)\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate saliency map for the same sequence across all 4 models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 14:55:29.287972: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-30 14:55:29.314886: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-30 14:55:29.315403: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-30 14:55:29.918164: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 200, 16)           1552      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 200, 16)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 8, 16)             0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5713 (22.32 KB)\n",
      "Trainable params: 5713 (22.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 200, 16)           1552      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 200, 16)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 8, 16)             0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5713 (22.32 KB)\n",
      "Trainable params: 5713 (22.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rbp_model_paths_list = [\n",
    "    \"/home/pgarcia/rbp_project/models_deepbind2/HNRNPK_K562_200.h5 + deepbind_exp_test\",\n",
    "    \"/home/pgarcia/rbp_project/models_deepbind2/HNRNPK_K562_200.h5 + deepbind_test\",\n",
    "    \n",
    " ]\n",
    "for path in rbp_model_paths_list:\n",
    "    model = tf.keras.models.load_model(path)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 09:20:32.591424: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-31 09:20:32.618759: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-31 09:20:32.619267: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-31 09:20:33.174298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, callbacks, activations, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 09:20:42.808705: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('/home/pgarcia/rbp_project/models_deepbind2/HNRNPK_K562_200.h5 + deepbind_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/pgarcia/rbp_project/test_loop.ipynb Cell 17\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgalaxy1/home/pgarcia/rbp_project/test_loop.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m layer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mModel(inputs\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39minputs, outputs\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mlayers[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39moutput) \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgalaxy1/home/pgarcia/rbp_project/test_loop.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#get model predictions for test sequences\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgalaxy1/home/pgarcia/rbp_project/test_loop.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgalaxy1/home/pgarcia/rbp_project/test_loop.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Get the top num_plots predictions\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgalaxy1/home/pgarcia/rbp_project/test_loop.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m num_plots \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "sal_plots = []\n",
    "# get the pre-activated outputs\n",
    "layer = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-2].output) \n",
    "\n",
    "#get model predictions for test sequences\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Get the top num_plots predictions\n",
    "num_plots = 10\n",
    "\n",
    "# Get the sorted indices\n",
    "sorted_indices = np.argsort(predictions[:, 0])[::-1]\n",
    "\n",
    "# Extract the top num_plots sequences\n",
    "X = x_test[sorted_indices[:num_plots]]\n",
    "\n",
    "# Reshape X to (num_plots, 200, 4)\n",
    "X = X.reshape((num_plots, 200, 4))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################\n",
    "import tensorflow as tf\n",
    "\n",
    "@tf.function\n",
    "def calculate_saliency_map(X, model, class_index=0):\n",
    "  \"\"\"fast function to generate saliency maps\"\"\"\n",
    "  if not tf.is_tensor(X):\n",
    "    X = tf.Variable(X)\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(X)\n",
    "    output = model(X)[:,class_index]\n",
    "  return tape.gradient(output, X)\n",
    "\n",
    "# calculate saliency maps\n",
    "saliency_map = calculate_saliency_map(X, layer)\n",
    "saliency_map = saliency_map.numpy()\n",
    "# gradient correction\n",
    "saliency_map -= np.mean(saliency_map, axis=2, keepdims=True)\n",
    "\n",
    "#########################################################\n",
    "import pandas as pd\n",
    "import logomaker\n",
    "\n",
    "def plot_saliency_map(scores, alphabet, ax=None):\n",
    "  L,A = scores.shape\n",
    "  counts_df = pd.DataFrame(data=0.0, columns=list(alphabet), index=list(range(L)))\n",
    "  for a in range(A):\n",
    "    for l in range(L):\n",
    "      counts_df.iloc[l,a] = scores[l,a]\n",
    "\n",
    "  if not ax:\n",
    "    ax = plt.subplot(1,1,1)\n",
    "  logomaker.Logo(counts_df, ax=ax)\n",
    "\n",
    "\n",
    "saliency_scores = saliency_map * X\n",
    "for scores in saliency_scores:\n",
    "  fig = plt.figure(figsize=(20,1))\n",
    "  ax = plt.subplot(1,1,1)\n",
    "  plot_saliency_map(scores, alphabet, ax)\n",
    "  #plt.savefig(\"myimg.svg\", dpi=300)\n",
    "  sal_plots.append(fig) \n",
    "  \n",
    "#for fig in sal_plots:\n",
    "  #fig.savefig(\"myimg_test2.pdf\", format='pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 14:51:47.530167: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('/home/pgarcia/rbp_project/models_deepbind2/HNRNPK_K562_200.h5 + deepbind_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 200, 16)           1552      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 200, 16)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 8, 16)             0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5713 (22.32 KB)\n",
      "Trainable params: 5713 (22.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
